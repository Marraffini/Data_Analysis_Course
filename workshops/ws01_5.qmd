---
title: "Tidy data"
---


# Introduction to the tidyverse

We will be largely using the `tidyverse` suite of packages for data organisation, summarising, and plotting; see <https://www.tidyverse.org/>.

Let's load that package now:

```{r}
#| message: false
library(tidyverse)
```

# Datset
For this workshop we will use some tidyverse built in datasets. Each dataset shows the same values of four variables: country, year, population, and number of documented cases of TB (tuberculosis), but each dataset organizes the values in a different way.

```{r}
table1


table2


table3

```

# Exercise 1.1 {-}

For each of the sample tables, describe what each observation and each column represents.

```{r}

```

## Piping

::: {.callout-tip}

**The piping operation is a fundamental aspect of computer programming. The semantics of pipes is taking the output from the left-hand side and passing it as input to the right-hand side.**

:::

The `R` package `magrittr` introduced the pipe operator `%>%` and can be pronounced as "then". In RStudio windows/Linux versions, press `Ctrl+Shift+M` to insert the pipe operator. On a Mac, use `Cmd+Shift+M`. 

`R` also has its own pipe, `|>`, which is an alternative to `%>%`. You will see both used in this course. If you want to change the pipe inserted automatically with `Ctrl+Shift+M`, find on the menu **Tools > Global Options**, then click on **Code** and check the box that says "**Use Native Pipe Operator**". 

Try the following examples after loading the `rangitikei` dataset.

`select()`

Consider the study guide dataset `rangitikei.txt` (Recreational Use of
the Rangitikei river) again. The first 10 rows of this dataset are shown
below:

```{r, echo=FALSE}
my.data <- read.csv(
  "https://www.massey.ac.nz/~anhsmith/data/rangitikei.csv", 
  header=TRUE
  )

head(my.data, 10) # shows the first ten rows
```


```{r}
library(tidyverse)

new.data <- my.data |> 
  select(people, vehicle)

names(new.data)
```


```{r}
my.data |> 
  select(people, vehicle) |> 
  ggplot() + 
  aes(x=people, y=vehicle) +
  geom_point()
```

We select two columns and create a scatter plot with the above commands.


`filter()`

```{r}
my.data |> 
  filter(wind==1) |> 
  select(people, vehicle) |> 
  ggplot() +
  aes(x=people, y=vehicle) +
  geom_point()
```

The above commands filter the data for the low wind days and plots
vehicle against people.

`arrange()`

```{r}
my.data |> 
  filter(wind==1) |> 
  arrange(w.e) |> 
  select(w.e, people, vehicle)
```

`mutate()`

Assume that a \$10 levy is collected for each vehicle. We can create
this new `levy` column as follows.

```{r}
my.data |> 
  mutate(levy = vehicle*10) |> 
  select(people, levy) |> 
  ggplot() +
  aes(x = people, y=levy) +
  geom_point()
```

Note that the pipe operation was used to create a scatter plot using the
newly created column.

`summarise()`

```{r}
my.data |> 
  summarise(total = n(), 
            avg = mean(people)
            )
```

We obtain the selected summary measures namely the total and the mean
number of people. Try-

```{r}
my.data |> 
  filter(wind == 1) |> 
  summarise(total = n(), 
            avg = mean(people)
            )
```

`group_by()`

We obtain the wind group-wise summaries below:

```{r}
my.data |> 
  group_by(wind) |> 
  summarise(total=n(), 
            avg=mean(people))
```

There are many more commands such as the `transmute` function which
conserves the only the needed columns. Try

```{r}
my.data |> 
  group_by(wind, w.e) |> 
  transmute(total=n(), 
            avg=mean(people))
```

A simple frequency table is found using `count()`. Try-

```{r}
my.data |> 
  group_by(wind, w.e) |> 
  count(temp)

my.data |> 
  group_by(wind, w.e) |> 
  count(temp, river)
```

The `count()` is useful to check the balanced nature of the data when
many subgroups are involved.

# Exercise 1.2 {-}

Using `table1`, compute rate of TB cases per 10,000 and the total cases per year

```{r}
table1 |>
  mutate(rate = cases / population * 10000)
```

```{r}
table1 |> 
  group_by(year) |> 
  summarize(total_cases = sum(cases))
```

# Exercise 1.3 {-}

For `table2`, write pseudo-code for how you would perform the following actions. Sketch/describe how you would do these. You haven’t yet learned all the functions you’d need to actually perform these operations, but you should still be able to think through the transformations you’d need.

a) Extract the number of TB cases per country per year.

b) Extract the matching population per country per year.

c) Divide cases by population, and multiply by 10000.

d) Store back in the appropriate place.


# Dataset *diamonds*
We will use the built in dataset on diamond price and measurements. See`?diamonds` more information.

# Exercise 1.4 {-}

Outliers are observations that are unusual; data points that don’t seem to fit the pattern. Sometimes outliers are data entry errors, sometimes they are simply values at the extremes that happened to be observed in this data collection, and other times they suggest important new discoveries. 

Describe the distribution of the `y` variable from the diamonds dataset.

```{r}
ggplot(diamonds, aes(x = y)) + 
  geom_histogram(binwidth = 0.5)
```

The only evidence of outliers is the unusually wide limits on the x-axis.

There are so many observations in the common bins that the rare bins are very short, making it very difficult to see them (although maybe if you stare intently at 0 you’ll spot something). We can change the `binwidth=` to help with this. We can also zoom in on the y axis using `coord_cartesian()`.

```{r}
ggplot(diamonds, aes(x = y)) + 
  geom_histogram(binwidth = 0.5) +
  coord_cartesian(ylim = c(0, 50)) # also has an xlim() option
```

# Exercise 1.5 {-}

Make a new dataset that includes these unusual values using dplyr.

```{r}
unusual <- diamonds |> 
  filter(y < 3 | y > 20) |> 
  select(price, x, y, z) |>
  arrange(y)
unusual
```

# Exercise 1.6 {-}

How many diamonds are 0.99 carat? How many are 1 carat? What do you think is the cause of the difference?

```{r}
# your code goes here
```

# Exercise 1.7 {-}
What does `na.rm = TRUE` do in mean() and sum()?

```{r}
# your code goes here
```

# Tidying data

Most real analyses will require at least a little tidying. You’ll begin by figuring out what the underlying variables and observations are. Sometimes this is easy; other times you’ll need to consult with the people who originally generated the data. Next, you’ll pivot your data into a tidy form, with variables in the columns and observations in the rows.

The `billboard` dataset records the billboard rank of songs in the year 2000:

```{r}
billboard
```

In this dataset, each observation is a song. The first three columns (artist, track and date.entered) are variables that describe the song. Then we have 76 columns (wk1-wk76) that describe the rank of the song in each week. Here, the column names are one variable (the week) and the cell values are another (the rank).

# Exercise 1.8 {-}
Use `pivot_longer()` to tidy this data

```{r}
# your code goes here
```



## Combining datasets

There are four types of joins, we will illustrate them using a simple example:

```{r}
df1 <- tibble(x = c(1, 2), y = 2:1)
df2 <- tibble(x = c(3, 1), a = 10, b = "a")
```

```{r}
df1 %>% inner_join(df2) 
```

```{r}
df1 %>% left_join(df2)
```

```{r}
df1 %>% right_join(df2)
df2 %>% left_join(df1)
```

```{r}
df1 %>% full_join(df2)
```

