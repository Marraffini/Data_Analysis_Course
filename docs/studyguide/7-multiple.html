<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>161250 Data Analysis - Chapter 7: Models with Multiple Continuous Predictors</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../studyguide/8-anova.html" rel="next">
<link href="../studyguide/6-single.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

<script src="../site_libs/kePrint-0.0.1/kePrint.js"></script>
<link href="../site_libs/lightable-0.0.1/lightable.css" rel="stylesheet">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">161250 Data Analysis</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../slides.html" rel="" target="">
 <span class="menu-text">Slides</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="../studyguide/index.html" rel="" target="" aria-current="page">
 <span class="menu-text">Study Guide</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../workshops/ws01.html" rel="" target="">
 <span class="menu-text">Workshops</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-extra-code" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Extra Code</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-extra-code">    
        <li>
    <a class="dropdown-item" href="../exercises/Chap2more.R" rel="" target="">
 <span class="dropdown-text">Ex2</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../exercises/Chap3more.R" rel="" target="">
 <span class="dropdown-text">Ex3</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../exercises/Chap4more.R" rel="" target="">
 <span class="dropdown-text">Ex4</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../exercises/Chap5more.R" rel="" target="">
 <span class="dropdown-text">Ex5</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../exercises/Chap6more.R" rel="" target="">
 <span class="dropdown-text">Ex6</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../exercises/Chap7more.R" rel="" target="">
 <span class="dropdown-text">Ex7</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../exercises/Chap8more.R" rel="" target="">
 <span class="dropdown-text">Ex8</span></a>
  </li>  
    </ul>
  </li>
</ul>
            <div class="quarto-navbar-tools ms-auto">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../studyguide/index.html">Study Guide</a></li><li class="breadcrumb-item"><a href="../studyguide/7-multiple.html">Chapter 7: Models with Multiple Continuous Predictors</a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../studyguide/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Study Guide</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../studyguide/1-data-collection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 1: Data Collection and Quality Issues</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../studyguide/2-eda.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 2: Exploratory Data Analysis (EDA)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../studyguide/3-probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 3: Probability Concepts and Distributions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../studyguide/4-inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 4: Statistical Inference</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../studyguide/5-tabulated.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 5: Tabulated Counts</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../studyguide/6-single.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 6: Models with a Single Continuous Predictor</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../studyguide/7-multiple.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Chapter 7: Models with Multiple Continuous Predictors</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../studyguide/8-anova.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 8: Analysis of Variance (ANOVA) and Covariance (ANCOVA)</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#full-regression" id="toc-full-regression" class="nav-link active" data-scroll-target="#full-regression">Full Regression</a></li>
  <li><a href="#measuring-variation-explained-by-predictors" id="toc-measuring-variation-explained-by-predictors" class="nav-link" data-scroll-target="#measuring-variation-explained-by-predictors">Measuring Variation Explained by Predictors</a>
  <ul class="collapse">
  <li><a href="#significance-testing-of-type-i-ss" id="toc-significance-testing-of-type-i-ss" class="nav-link" data-scroll-target="#significance-testing-of-type-i-ss">Significance testing of Type I SS</a></li>
  <li><a href="#other-ss-types" id="toc-other-ss-types" class="nav-link" data-scroll-target="#other-ss-types">Other SS types</a></li>
  </ul></li>
  <li><a href="#regression-fitting-with-fewer-predictors" id="toc-regression-fitting-with-fewer-predictors" class="nav-link" data-scroll-target="#regression-fitting-with-fewer-predictors">Regression Fitting with Fewer Predictors</a>
  <ul class="collapse">
  <li><a href="#best-subsets-selection" id="toc-best-subsets-selection" class="nav-link" data-scroll-target="#best-subsets-selection">Best Subsets Selection</a></li>
  </ul></li>
  <li><a href="#polynomial-models" id="toc-polynomial-models" class="nav-link" data-scroll-target="#polynomial-models">Polynomial Models</a></li>
  <li><a href="#model-structure-and-other-issues" id="toc-model-structure-and-other-issues" class="nav-link" data-scroll-target="#model-structure-and-other-issues">Model structure and other issues</a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary">Summary</a></li>
  <li><a href="#what-you-should-know" id="toc-what-you-should-know" class="nav-link" data-scroll-target="#what-you-should-know">What you should know</a></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="7-multiple.pdf"><i class="bi bi-file-pdf"></i>PDF</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Chapter 7: Models with Multiple Continuous Predictors</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>In this chapter, we consider <strong>multiple regression</strong> and other models in which there are more than one predictor (or <span class="math inline">\(X\)</span>) variable. This extends what we covered in the last chapter where we examined one predictor to multiple predictors. Once again our focus is on finding the estimates of coefficients or parameters in multiple linear regression models by the method of <strong>least squares</strong>. For this we assume that</p>
<ol type="1">
<li><p>The predictor (or explanatory or controlled or covariate) variables <span class="math inline">\(X_i\)</span> <span class="math inline">\((i=1,2,...,p)\)</span> are known without error.</p></li>
<li><p>The mean or expected value of the dependent (or response) variable <span class="math inline">\(Y\)</span> is related to the <span class="math inline">\(X_i\)</span> <span class="math inline">\((i=1,2,...,p)\)</span> according to a linear expression</p>
<p><span class="math inline">\(E(y\mid x)=a+ b_1 x_l + b_2 x_2 + ....+ b_p x_p\)</span></p>
<p>i.e.&nbsp;a straight line (for one <span class="math inline">\(X\)</span> variable), a plane (for two <span class="math inline">\(X\)</span> variables) or a hyperplane (for more than two <span class="math inline">\(X\)</span> variables). This means that the fitted model can be written as</p>
<p><em>fit</em> = <span class="math inline">\(a+ b_1 x_l + b_2 x_2 + ....+ b_p x_p\)</span>.</p></li>
<li><p>There is random (unpredictable, unexplained) variability of <span class="math inline">\(Y\)</span> about the fitted model. That is,</p>
<p><span class="math inline">\(y\)</span> = fit + residual.</p></li>
<li><p>In order to apply statistical inferences to a model, a number of assumptions need to be made. To be able to form <span class="math inline">\(t\)</span> and <span class="math inline">\(F\)</span> statistics, we assume that</p></li>
<li><p>The variability in <span class="math inline">\(Y\)</span> about the line (plane etc) is constant and independent of the <span class="math inline">\(X\)</span> variables.</p></li>
<li><p>The variability of <span class="math inline">\(Y\)</span> follows a Normal distribution. That is, the distribution of <span class="math inline">\(Y\)</span> (given certain values of the <span class="math inline">\(X_i\)</span> variables) is Normal.</p></li>
<li><p>Given (different) outcomes of the <span class="math inline">\(X\)</span> variables, the corresponding <span class="math inline">\(Y\)</span> variables are independent of one another.</p></li>
</ol>
<p>We will continue to use the data set <strong>horsehearts</strong> of the weights of horses’ hearts and other related measurements.</p>
<section id="full-regression" class="level1">
<h1>Full Regression</h1>
<p>With one explanatory variable scatterplots and correlation coefficients provided good starting points for exploring relationships between the explanatory and response variables. This is even more relevant with two or more explanatory variables. For the horses’ hearts data, there are six potential explanatory variables; namely <code>EXTDIA</code>, <code>EXTSYS</code>, <code>INNERDIA</code>, <code>INNERSYS</code>, <code>OUTERDIA</code> and <code>OUTERSYS</code>. These measurements of heart width are made of the exterior width, inner wall and outer wall at two different phases, the diastole phase and the systole phase. So a matrix of scatter plots (or matrix plot) of these variables will be useful for exploratory analysis.</p>
<p>It is also a good idea to form the simple correlation coefficients between each pair of explanatory variables and between each explanatory variable and the response variable <span class="math inline">\(Y\)</span>, the weight of the horse’s heart. These correlation coefficients can be displayed in a <strong>correlation matrix</strong> as shown in <a href="#fig-multggally">Figure&nbsp;1</a>.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidymodels)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(kableExtra)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">theme_set</span>(<span class="fu">theme_minimal</span>())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">download.file</span>(</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">url =</span> <span class="st">"http://www.massey.ac.nz/~anhsmith/data/horsehearts.RData"</span>,</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">destfile =</span> <span class="st">"horsehearts.RData"</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="st">"horsehearts.RData"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-mesasge="false">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(GGally)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>Registered S3 method overwritten by 'GGally':
  method from   
  +.gg   ggplot2</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggpairs</span>(horsehearts)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-multggally" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="7-multiple_files/figure-html/fig-multggally-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;1: Scatter plot and correlation matrix</figcaption>
</figure>
</div>
</div>
</div>
<p>It is also possible to obtain the <span class="math inline">\(p\)</span>-values for all the simple correlation coefficients displayed above and test whether these are significantly different from zero.</p>
<p>A number of facts about the data emerge from our EDA. All of the correlation coefficients are positive and reasonably large which indicates that with large hearts all the lengths increase in a fairly uniform manner. The predictor variables are also highly inter-correlated. <strong>This suggests that not all of these variables are needed but only a subset of them</strong>.</p>
<p>The usual <code>tidy()</code> function output of multiple regression weight on all of the available (six) predictors is shown in <a href="#tbl-fullregtidy">Table&nbsp;1</a>.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>full.reg <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT<span class="sc">~</span> ., <span class="at">data=</span>horsehearts)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(full.reg) <span class="co"># or summary(full.reg) </span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="tbl-fullregtidy" class="anchored">
<table class="table table-sm table-striped small">
<caption>Table&nbsp;1: Full Regression tidy() output</caption>
<thead>
<tr class="header">
<th style="text-align: left;">term</th>
<th style="text-align: right;">estimate</th>
<th style="text-align: right;">std.error</th>
<th style="text-align: right;">statistic</th>
<th style="text-align: right;">p.value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">(Intercept)</td>
<td style="text-align: right;">-1.631</td>
<td style="text-align: right;">0.488</td>
<td style="text-align: right;">-3.343</td>
<td style="text-align: right;">0.002</td>
</tr>
<tr class="even">
<td style="text-align: left;">INNERSYS</td>
<td style="text-align: right;">0.232</td>
<td style="text-align: right;">0.308</td>
<td style="text-align: right;">0.753</td>
<td style="text-align: right;">0.456</td>
</tr>
<tr class="odd">
<td style="text-align: left;">INNERDIA</td>
<td style="text-align: right;">0.520</td>
<td style="text-align: right;">0.395</td>
<td style="text-align: right;">1.314</td>
<td style="text-align: right;">0.197</td>
</tr>
<tr class="even">
<td style="text-align: left;">OUTERSYS</td>
<td style="text-align: right;">0.711</td>
<td style="text-align: right;">0.329</td>
<td style="text-align: right;">2.164</td>
<td style="text-align: right;">0.037</td>
</tr>
<tr class="odd">
<td style="text-align: left;">OUTERDIA</td>
<td style="text-align: right;">-0.557</td>
<td style="text-align: right;">0.451</td>
<td style="text-align: right;">-1.236</td>
<td style="text-align: right;">0.224</td>
</tr>
<tr class="even">
<td style="text-align: left;">EXTSYS</td>
<td style="text-align: right;">-0.300</td>
<td style="text-align: right;">0.135</td>
<td style="text-align: right;">-2.227</td>
<td style="text-align: right;">0.032</td>
</tr>
<tr class="odd">
<td style="text-align: left;">EXTDIA</td>
<td style="text-align: right;">0.339</td>
<td style="text-align: right;">0.148</td>
<td style="text-align: right;">2.296</td>
<td style="text-align: right;">0.027</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>This regression model is known as the <strong>full regression</strong> because we have included all the predictors in our model. The <code>R</code> syntax <code>~.</code> means that we are placing all variables in the dataframe except the one selected as the response variable. We note that the slope coefficients of the predictors <code>INNERDIA</code>, <code>INNERSYS</code>, and <code>OUTERDIA</code> are not significant at 5% level. This confirms that we do not need to place all six predictors in the model but only a subset of them.</p>
<p>The highly correlated predictor <code>INNERDIA</code> (see <a href="#fig-multggally">Figure&nbsp;1</a>) is also found to have a insignificant coefficient in <a href="#tbl-fullregtidy">Table&nbsp;1</a>. This is somewhat surprising and casts doubts on the suitability of the full regression fit. If two or more explanatory variables are very highly correlated (i.e.&nbsp;almost collinear), then we deal with <strong>multicollinearity</strong>. The estimated standard errors of the regression coefficients will be inflated in the presence of multicollinearity. As result, the <span class="math inline">\(t\)</span>-value will become small leading to a model with many insignificant coefficients. Multicollinearity does not affect the residual standard error much. The obvious remedy for multicollinearity is that one or more of the highly correlated variables can be dropped. Measures such as the Variance Inflation factor (<strong>VIF</strong>) are available to study the effect of multicollinearity. A VIF factor of more than 5 for a coefficient means that its variance is artificially inflated by the high correlation among the predictors. For the full regression model, the VIF factors are obtained using the <code>car</code> package function <code>vif()</code> and shown as <a href="#tbl-fullregvif">Table&nbsp;2</a>.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>car<span class="sc">::</span><span class="fu">vif</span>(full.reg)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="tbl-fullregvif" class="anchored">
<table class="table table-sm table-striped small">
<caption>Table&nbsp;2: Variance Inflation Factors</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: right;">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">INNERSYS</td>
<td style="text-align: right;">8.77</td>
</tr>
<tr class="even">
<td style="text-align: left;">INNERDIA</td>
<td style="text-align: right;">8.60</td>
</tr>
<tr class="odd">
<td style="text-align: left;">OUTERSYS</td>
<td style="text-align: right;">7.71</td>
</tr>
<tr class="even">
<td style="text-align: left;">OUTERDIA</td>
<td style="text-align: right;">6.66</td>
</tr>
<tr class="odd">
<td style="text-align: left;">EXTSYS</td>
<td style="text-align: right;">16.05</td>
</tr>
<tr class="even">
<td style="text-align: left;">EXTDIA</td>
<td style="text-align: right;">22.00</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>All the VIF values are over 5, and hence the full regression model must be simplified dropping one or more predictors.</p>
<p>Let us now compare the fit and summary measures of the simple regression <code>lm(WEIGHT ~ INNERDIA, data=horsehearts)</code> with the full regression <code>lm(WEIGHT ~ ., data=horsehearts)</code>. <a href="#fig-modcomp">Figure&nbsp;2</a> compares the actual and fitted <span class="math inline">\(Y\)</span> values for these two models.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(modelr)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>full.reg <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT <span class="sc">~</span> ., <span class="at">data=</span>horsehearts)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>simple.reg <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT <span class="sc">~</span> INNERDIA, <span class="at">data=</span>horsehearts)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>hhpred <span class="ot">&lt;-</span> horsehearts <span class="sc">|&gt;</span> </span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gather_predictions</span>(full.reg, simple.reg) <span class="sc">|&gt;</span> </span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">residuals=</span>WEIGHT<span class="sc">-</span>pred)</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>hhpred <span class="sc">|&gt;</span> </span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aes</span>(<span class="at">x=</span>WEIGHT, <span class="at">y=</span>pred, <span class="at">colour=</span>model) <span class="sc">+</span> </span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">slope=</span><span class="dv">1</span>, <span class="at">intercept =</span> <span class="dv">0</span>, <span class="at">alpha=</span>.<span class="dv">5</span>) <span class="sc">+</span> </span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">aspect.ratio =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Predicted WEIGHT"</span>) <span class="sc">+</span> </span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Comparison of model predictions"</span>) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-modcomp" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="7-multiple_files/figure-html/fig-modcomp-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;2: Comparison of Multiple Regression and Simple Regression</figcaption>
</figure>
</div>
</div>
</div>
<p>Both the simple and full regression models give similar predictions when the horses heart weight is below 2.5 kg, but the simple regression residuals are bit bigger for larger hearts.</p>
<p>We are rather hesitant to make unique claims about any particular subset of predictors based on the correlation matrix or based on the significance of the coefficients from the multiple regression output. In forthcoming sections, methods to decide on a subset of these variables will be explained, but first we look at the issues involved when predictor variables are correlated to each other.</p>
</section>
<section id="measuring-variation-explained-by-predictors" class="level1">
<h1>Measuring Variation Explained by Predictors</h1>
<p>The variation in a variable can be measured by its sum of squares. In this section, we illustrate this variation by the area of a circle. For brevity, we denote the <strong>T</strong>otal <strong>S</strong>um of <strong>S</strong>quares, the <strong>R</strong>egression <strong>S</strong>um of <strong>S</strong>quares and the <strong>E</strong>rror or residual <strong>S</strong>um of <strong>S</strong>quares by <strong>SST</strong>, <strong>SSR</strong> and <strong>SSE</strong> respectively. In <a href="#fig-f5-3">Figure&nbsp;3</a>, the circle is labelled <span class="math inline">\(y\)</span> and represents the Sum of Squares for all the <span class="math inline">\(y\)</span> observations, that is, SST.</p>
<div id="fig-f5-3" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/5-3.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;3: Effect of predictor correlation with the response</figcaption>
</figure>
</div>
<p>For the full regression of horse heart weight, we obtain the ANOVA output using the command</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(full.reg)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Let’s take a look at the sums of squares table.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>SS <span class="ot">&lt;-</span> <span class="fu">anova</span>(full.reg) <span class="sc">|&gt;</span> </span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>() <span class="sc">|&gt;</span> </span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(term<span class="sc">:</span>sumsq) <span class="sc">|&gt;</span> </span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>  janitor<span class="sc">::</span><span class="fu">adorn_totals</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="tbl-SS" class="anchored">
<table class="table table-sm table-striped small">
<caption>Table&nbsp;3: Sums of squares for the full regression of horsehearts data</caption>
<thead>
<tr class="header">
<th style="text-align: left;">term</th>
<th style="text-align: right;">df</th>
<th style="text-align: right;">sumsq</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">INNERSYS</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">34.40</td>
</tr>
<tr class="even">
<td style="text-align: left;">INNERDIA</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">3.53</td>
</tr>
<tr class="odd">
<td style="text-align: left;">OUTERSYS</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">2.76</td>
</tr>
<tr class="even">
<td style="text-align: left;">OUTERDIA</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">0.13</td>
</tr>
<tr class="odd">
<td style="text-align: left;">EXTSYS</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">0.06</td>
</tr>
<tr class="even">
<td style="text-align: left;">EXTDIA</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">1.90</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Residuals</td>
<td style="text-align: right;">39</td>
<td style="text-align: right;">14.07</td>
</tr>
<tr class="even">
<td style="text-align: left;">Total</td>
<td style="text-align: right;">45</td>
<td style="text-align: right;">56.85</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>Now let’s calculate the Sums of Squares Total (SST), Error (SSE), and Regression (SSR).</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">SST =</span> SS <span class="sc">|&gt;</span> <span class="fu">filter</span>(term<span class="sc">==</span><span class="st">"Total"</span>) <span class="sc">|&gt;</span> <span class="fu">pull</span>(sumsq),</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">SSE =</span> SS <span class="sc">|&gt;</span> <span class="fu">filter</span>(term<span class="sc">==</span><span class="st">"Residuals"</span>) <span class="sc">|&gt;</span> <span class="fu">pull</span>(sumsq),</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">SSR =</span> SST <span class="sc">-</span> SSE</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 3
    SST   SSE   SSR
  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
1  56.8  14.1  42.8</code></pre>
</div>
</div>
<p>In <a href="#fig-f5-3">Figure&nbsp;3</a>(a), SST = SSR + SSE = 32.731 + 24.115 = 56.845. Consider now the straight line relationship between <span class="math inline">\(y\)</span> and one response variable <span class="math inline">\(x\)</span>. This situation is illustrated in <a href="#fig-f5-3">Figure&nbsp;3</a>(b). The shaded overlap of the two circles illustrates the variation in <span class="math inline">\(y\)</span> about the mean explained by the variable <span class="math inline">\(x\)</span>, and this shaded area represents the regression sum of squares SSR. The remaining area of the circle for <span class="math inline">\(y\)</span> represents the unexplained variation in <span class="math inline">\(y\)</span> or the residual sum of squares SSE. Note that the circle or Venn diagrams represent SS only qualitatively (not to scale). The variation in <span class="math inline">\(y\)</span> is thus separated into two parts, namely <strong>SST = SSR + SSE</strong>.</p>
<p>Notice that we are not very interested in the unshaded area of the circle representing the explanatory variable, <span class="math inline">\(x\)</span>; <em>it is the variation in the response variable,</em> <span class="math inline">\(y\)</span>, which is important. Also notice that the overlapping circles indicate that the two variables are correlated, that is the correlation coefficient, <span class="math inline">\(r_{xy}\)</span>, is not zero. The shaded area is related to</p>
<p><span class="math inline">\(R^2\)</span> = proportion of the variation of <span class="math inline">\(y\)</span> explained by <span class="math inline">\(x\)</span> = SSR/SST = 32.731/56.845 = 0.576 = <span class="math inline">\(r_{xy}^2\)</span>.</p>
<p>Note from <a href="#fig-multggally">Figure&nbsp;1</a> that the correlation between <code>WEIGHT</code> and <code>EXTDIA</code> is 0.759 and 0.759 squared equals 0.576.</p>
<p>The situation becomes more interesting when a second explanatory variable is added to the model as illustrated by <a href="#fig-f5-4">Figure&nbsp;4</a>.</p>
<div id="fig-f5-4" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/5-4.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;4: Effect of adding two predictors</figcaption>
</figure>
</div>
<p>In the following discussion, the variable <code>EXTDIA</code> is denoted by <span class="math inline">\(x_1\)</span> and <code>OUTERDIA</code> as <span class="math inline">\(x_2\)</span>. The total overlap of (<span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span>) and <span class="math inline">\(y\)</span> will depend on the relationship of <span class="math inline">\(y\)</span> with <span class="math inline">\(x_1\)</span>, <span class="math inline">\(y\)</span> with <span class="math inline">\(x_2\)</span>, and the correlation of <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2.\)</span></p>
<p>In <a href="#fig-f5-4">Figure&nbsp;4</a>(a), as the circles for <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> do not overlap, this represents a correlation coefficient between these two variables of zero. In this special case, <span class="math display">\[R^{2} =\frac{\text {SSR}(x_1)+\text {SSR} (x_2)}{\text {SST}} =r_{x_{1} y}^{2} +r_{x_{2} y}^{2}.\]</span></p>
<p>Here, SSR(<span class="math inline">\(x_1\)</span>) represents the Regression SS when <span class="math inline">\(y\)</span> is regressed on <span class="math inline">\(x_1\)</span> only. SSR(<span class="math inline">\(x_2\)</span>) represents the Regression SS when <span class="math inline">\(y\)</span> is regressed on <span class="math inline">\(x_2\)</span> only. The unshaded area of <span class="math inline">\(y\)</span> represents SSE, the residual sum of squares, which is the sum of squares of <span class="math inline">\(y\)</span> <strong>unexplained</strong> by <span class="math inline">\(x_1\)</span> or <span class="math inline">\(x_2\)</span>. The <strong>special case</strong> of <strong>uncorrelated</strong> explanatory variables is in many ways ideal but it usually only occurs when <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> are constructed to have zero correlation (which means that the situation, known as orthogonality, is usually confined to experimental designs). There is an added bonus when <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> have zero correlation. In this situation the fitted model is</p>
<p><span class="math display">\[\hat{y} = a + b_1 x_1 + b_2x_2\]</span></p>
<p>where <span class="math inline">\(b_1\)</span> and <span class="math inline">\(b_2\)</span> take the same values as in the separate straight line models <span class="math inline">\(\hat{y} = a + b_1x_1\)</span> and <span class="math inline">\(\hat{y} =a + b_2x_2.\)</span></p>
<p>However in observational studies the correlations between predictor variables will usually be nonzero. The circle diagram shown in <a href="#fig-f5-4">Figure&nbsp;4</a>(b) illustrates the case when <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> are correlated. In this case <span class="math display">\[R^{2} &lt;\frac{\text {SSR}(x_1) + \text {SSR}(x_2) } {\text {SST}}\]</span> and the slope coefficients for both <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> change when both these variables are included in the regression model.</p>
<p><a href="#fig-f5-4">Figure&nbsp;4</a>(c) gives the extreme case when <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> have nearly perfect correlation. If the correlation between <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> is perfect, then the two variables will be said to be collinear. If two or more explanatory variables are very highly correlated (i.e.&nbsp;almost collinear), then we deal with <strong>multicollinearity</strong>.</p>
<p>From <a href="#fig-f5-3">Figure&nbsp;3</a> and <a href="#fig-f5-4">Figure&nbsp;4</a>, it is clear that for correlated variables, the variation (SS) explained by a particular predictor cannot be independently extracted (due to the commonly shared variation). Hence, we consider how much a predictor explains <strong>additionally</strong> given that there are already certain predictors are in the model. The additional overlap due to <span class="math inline">\(x_{2}\)</span> with <span class="math inline">\(y\)</span> <strong>after</strong> <span class="math inline">\(x_{1}\)</span>, known as the <strong>additional SSR</strong> or <strong>Sequential SS</strong> is an important idea in model building. The additional SSR is known as <strong>Type I sums of squares</strong> in the statistical literature.</p>
<p>Note that we can also define the additional variation in <span class="math inline">\(y\)</span> explained by <span class="math inline">\(x_{1}\)</span> after <span class="math inline">\(x_{2}\)</span>. It is important to note that in general the additional SSR depends on the <strong>order</strong> of placing the predictors. <strong>This order does not have any effect on the coefficient estimation, standard errors etc.</strong></p>
<section id="significance-testing-of-type-i-ss" class="level2">
<h2 class="anchored" data-anchor-id="significance-testing-of-type-i-ss">Significance testing of Type I SS</h2>
<p>The significance of the additional variation explained by a predictor can be tested using a <span class="math inline">\(t\)</span> or <span class="math inline">\(F\)</span> statistic. Consider the simple regression model of <code>WEIGHT</code> on <code>EXTDIA</code>. Suppose we decided to add the explanatory variable <code>OUTERDIA</code> to the model, i.e.&nbsp;regress <code>WEIGHT</code> on two explanatory variables <code>EXTDIA</code> and <code>OUTERDIA</code>. Is this new model a significant improvement on the existing one? For testing the null hypothesis that the true slope coefficient of <code>OUTERDIA</code> in this model is zero, the <span class="math inline">\(t\)</span>-statistic is 1.531 (see output below).</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>twovar.model <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT<span class="sc">~</span> EXTDIA<span class="sc">+</span>OUTERDIA, <span class="at">data=</span>horsehearts)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>twovar.model <span class="sc">|&gt;</span> <span class="fu">tidy</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 3 × 5
  term        estimate std.error statistic  p.value
  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
1 (Intercept)   -1.97     0.551      -3.57 0.000885
2 EXTDIA         0.226    0.0614      3.68 0.000637
3 OUTERDIA       0.522    0.341       1.53 0.133   </code></pre>
</div>
</div>
<p>The <span class="math inline">\(t\)</span> and <span class="math inline">\(F\)</span> distributions are related by the equation <span class="math inline">\(t^{2} =F\)</span> when the numerator df is just one for the <span class="math inline">\(F\)</span> statistic. Hence 1.532 = 2.34 is the <span class="math inline">\(F\)</span> value for testing the significance of the additional SSR due to <code>OUTERDIA</code>. In other words, the addition of <code>OUTERDIA</code> to the simple regression model does not result in a significant improvement in the sense that the reduction in residual SS (= 1.247) as measured by the <span class="math inline">\(F\)</span> value of 2.34 is not significant (<span class="math inline">\(p\)</span>-value being 0.133).</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>onevar.model <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT<span class="sc">~</span> EXTDIA, <span class="at">data=</span>horsehearts)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>twovar.model <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT<span class="sc">~</span> EXTDIA<span class="sc">+</span>OUTERDIA, <span class="at">data=</span>horsehearts)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(onevar.model, twovar.model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Variance Table

Model 1: WEIGHT ~ EXTDIA
Model 2: WEIGHT ~ EXTDIA + OUTERDIA
  Res.Df    RSS Df Sum of Sq      F Pr(&gt;F)
1     44 24.115                           
2     43 22.867  1    1.2472 2.3453  0.133</code></pre>
</div>
</div>
<p>Although <code>OUTERDIA</code> is correlated with <code>WEIGHT</code>, it also has high correlation with <code>EXTDIA</code>. In other words, the correlation matrix gives us some indication of how many variables might be needed in a multiple regression model, although by itself it cannot tell us what combination of predictor variables is good or best.</p>
<div id="fig-f5-5" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/5-5.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;5: Issues with multiple predictors</figcaption>
</figure>
</div>
<div id="fig-f5-7" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/5-7.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;6: Effect of multiple predictors on model summaries</figcaption>
</figure>
</div>
<p><a href="#fig-f5-5">Figure&nbsp;5</a> and <a href="#fig-f5-7">Figure&nbsp;6</a> summarise the following facts:</p>
<ol type="1">
<li><p>When there is only <strong>one</strong> explanatory variable, <span class="math inline">\(R^2\)</span> = SSR/SST equals the square of the correlation coefficient between that variable and the dependent variable. Therefore if only one variable is to be chosen, it should have the highest correlation with the response variable, <span class="math inline">\(Y\)</span>.</p></li>
<li><p>When variables are added to a model, the regression sum of squares SSR will increase and the residual or error sum of squares SSE will reduce. The opposite is true if variables are dropped from the model. This fact follows from <a href="#fig-f5-7">Figure&nbsp;6</a>.</p></li>
<li><p>The other side of the coin to the above remark is that as additional variables are added, the Sums of Squares for residuals, SSE, will decrease towards zero as also shown in <a href="#fig-f5-7">Figure&nbsp;6</a>(c).</p></li>
<li><p>The overlap of circles in suggests that these changes in both SSR and SST will lessen as more variables are added, see <a href="#fig-f5-5">Figure&nbsp;5</a>(b).</p></li>
<li><p>Following on from the last two notes, as <span class="math inline">\(R^2\)</span> = SSR/SST, <span class="math inline">\(R^2\)</span> will increase monotonically towards 1 as additional variables are added to the model. (monotonically increasing means that it never decreases although it could remain the same). This is indicated by <a href="#fig-f5-7">Figure&nbsp;6</a>(a). If variables are dropped, then <span class="math inline">\(R^2\)</span> will monotonically decrease.</p></li>
<li><p>Against the above trends, the graph of residual mean square in <a href="#fig-f5-7">Figure&nbsp;6</a>(b) reduces to a <em>minimum</em> but may eventually start to increase if enough variables are added. The residual sum of squares SSE decreases as variables are added to the model (see <a href="#fig-f5-5">Figure&nbsp;5</a>(b)). However, the associated df values also decrease so that the residual standard deviation decreases at first and then starts to increase as shown in <a href="#fig-f5-7">Figure&nbsp;6</a>(b). (Note that the residual standard error <span class="math inline">\(s_{e}\)</span> is the square root of the residual mean square</p>
<p><span class="math display">\[s_{e}^{2} =\frac{{\text {SSE}}}{{\text {error degrees of freedom}}},\]</span></p>
<p>denoted as MSE in <a href="#fig-f5-5">Figure&nbsp;5</a>(b)). After a number of variables have been entered, the additional amount of variation explained by them slows down but the degrees of freedom continues to change by 1 for every variable added, resulting in the eventual increase in residual mean square. Note that the graphs in <a href="#fig-f5-5">Figure&nbsp;5</a> are idealised ones. For some data sets, the behaviour of residual mean square may not be monotone.</p></li>
<li><p>Notice that the above trends will occur even if the variables added are <strong>garbage</strong>. For example, you could generate a column of random data or a column of birthdays of your friends, and this would improve the <span class="math inline">\(R^2\)</span> <strong>but not the adjusted</strong> <span class="math inline">\(R^2\)</span>. The adjusted <span class="math inline">\(R^2\)</span> makes adjustment for the degrees of freedom for the SSR and SSE, and hence reliable when compared to the unadjusted or multiple <span class="math inline">\(R^2\)</span>. The residual mean square error also partly adjusts for the drop in the degrees of freedom for the SSE and hence becomes an important measure. The addition of unimportant variables will not improve the adjusted <span class="math inline">\(R^2\)</span> and the mean square error <span class="math inline">\(s_{e}^{2}\)</span>.</p></li>
</ol>
</section>
<section id="other-ss-types" class="level2">
<h2 class="anchored" data-anchor-id="other-ss-types">Other SS types</h2>
<p>The <code>R</code> anova function anova() calculates sequential or Type-I SS values.</p>
<p>Type-II sums of squares is based on the principle of marginality. Type II SS correspond to the <code>R</code> convention in which each variable effect is adjusted for all other <em>appropriate</em> effects.</p>
<p>Type-III sums of squares is the SS added to the regression SS after ALL other predictors including an intercept term. This SS however creates theoretical issues such as violation of marginality principle and we should avoid using this SS type for hypothesis tests.</p>
<p>The <code>R</code> package <code>car</code> has the function <code>Anova()</code> to compute the Type II and III sums of squares. Try-</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>full.model <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT<span class="sc">~</span> ., <span class="at">data=</span>horsehearts)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(full.model)</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(car)</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="fu">Anova</span>(full.model, <span class="at">type=</span><span class="dv">2</span>)</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="fu">Anova</span>(full.model, <span class="at">type=</span><span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>For the <strong>horsehearts</strong> data, a comparison of the Type I and II sums squares is given below:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>full.model <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT<span class="sc">~</span> ., <span class="at">data=</span>horsehearts)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>anova1 <span class="ot">&lt;-</span> full.model <span class="sc">|&gt;</span> </span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">anova</span>() <span class="sc">|&gt;</span> </span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>() <span class="sc">|&gt;</span> </span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(term, <span class="st">"Type I SS"</span> <span class="ot">=</span> sumsq)  </span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>anova2 <span class="ot">&lt;-</span> full.model <span class="sc">|&gt;</span> </span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">Anova</span>(<span class="at">type=</span><span class="dv">2</span>) <span class="sc">|&gt;</span> </span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>() <span class="sc">|&gt;</span> </span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(term, <span class="st">"Type II SS"</span> <span class="ot">=</span> sumsq) </span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>type1and2 <span class="ot">&lt;-</span> <span class="fu">full_join</span>(anova1, anova2, <span class="at">by=</span><span class="st">"term"</span>)</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>type1and2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<div class="cell-output-display">
<table class="table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: left;">term</th>
<th style="text-align: right;">Type I SS</th>
<th style="text-align: right;">Type II SS</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">INNERSYS</td>
<td style="text-align: right;">34.40</td>
<td style="text-align: right;">0.20</td>
</tr>
<tr class="even">
<td style="text-align: left;">INNERDIA</td>
<td style="text-align: right;">3.53</td>
<td style="text-align: right;">0.62</td>
</tr>
<tr class="odd">
<td style="text-align: left;">OUTERSYS</td>
<td style="text-align: right;">2.76</td>
<td style="text-align: right;">1.69</td>
</tr>
<tr class="even">
<td style="text-align: left;">OUTERDIA</td>
<td style="text-align: right;">0.13</td>
<td style="text-align: right;">0.55</td>
</tr>
<tr class="odd">
<td style="text-align: left;">EXTSYS</td>
<td style="text-align: right;">0.06</td>
<td style="text-align: right;">1.79</td>
</tr>
<tr class="even">
<td style="text-align: left;">EXTDIA</td>
<td style="text-align: right;">1.90</td>
<td style="text-align: right;">1.90</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Residuals</td>
<td style="text-align: right;">14.07</td>
<td style="text-align: right;">14.07</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>When predictor variables are correlated, it is difficult to assess their absolute importance and the importance of a variable can be assessed only relatively. This is not an issue with the most highly correlated predictor in general.</p>
</section>
</section>
<section id="regression-fitting-with-fewer-predictors" class="level1">
<h1>Regression Fitting with Fewer Predictors</h1>
<p>The first step before selection of the best subset of predictors is to study the correlation matrix. For horses’ heart data, the explanatory variable which is most highly correlated with <span class="math inline">\(y\)</span> (<code>WEIGHT</code>) is <span class="math inline">\(x_2\)</span> (<code>INNERDIA</code>) having a correlation coefficient of 0.811 (see <a href="#fig-multggally">Figure&nbsp;1</a>). This means that <code>INNERDIA</code> should be the single best predictor. We may guess that the next best variable to join <code>INNERDIA</code>. This would be <span class="math inline">\(x_3\)</span> (<code>OUTERSYS</code>) but the correlations between <span class="math inline">\(x_3\)</span> and the other explanatory variables clouds the issue. In other words, the significance or otherwise of a variable in a multiple regression model depends on the other variables in the model.</p>
<p>Consider the regression of horses’ heart <code>WEIGHT</code> on <code>INNERDIA</code>, <code>OUTERSYS</code>, and <code>EXTSYS</code>.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>threevar.model <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT <span class="sc">~</span> INNERDIA <span class="sc">+</span> OUTERSYS <span class="sc">+</span> EXTSYS,</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>                     <span class="at">data=</span>horsehearts)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>threevar.model <span class="sc">|&gt;</span> <span class="fu">tidy</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<div class="cell-output-display">
<table class="table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: left;">term</th>
<th style="text-align: right;">estimate</th>
<th style="text-align: right;">std.error</th>
<th style="text-align: right;">statistic</th>
<th style="text-align: right;">p.value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">(Intercept)</td>
<td style="text-align: right;">-1.341</td>
<td style="text-align: right;">0.474</td>
<td style="text-align: right;">-2.828</td>
<td style="text-align: right;">0.007</td>
</tr>
<tr class="even">
<td style="text-align: left;">INNERDIA</td>
<td style="text-align: right;">0.958</td>
<td style="text-align: right;">0.262</td>
<td style="text-align: right;">3.649</td>
<td style="text-align: right;">0.001</td>
</tr>
<tr class="odd">
<td style="text-align: left;">OUTERSYS</td>
<td style="text-align: right;">0.597</td>
<td style="text-align: right;">0.203</td>
<td style="text-align: right;">2.940</td>
<td style="text-align: right;">0.005</td>
</tr>
<tr class="even">
<td style="text-align: left;">EXTSYS</td>
<td style="text-align: right;">-0.034</td>
<td style="text-align: right;">0.063</td>
<td style="text-align: right;">-0.534</td>
<td style="text-align: right;">0.596</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>The coefficient of <code>EXTSYS</code> is not significant at 5% level. However coefficient of <code>EXTSYS</code> was found to be significant in the full regression. The significance of <code>INNERDIA</code> coefficient has also changed. This example shows that <em>we cannot fully rely on the</em> <span class="math inline">\(t\)</span>-test and discard a variable because its coefficient is insignificant.</p>
<p>There are various search methods for finding the best subset of explanatory variables. We will consider <strong>stepwise procedures</strong>, namely algorithms that follow a series of steps to find a good set of predictors. At each step, the current regression model is compared with competing models in which one variable has either been added (<em>forward selection</em> procedures) or removed (<em>backward elimination</em> procedures). Some measure of goodness is required so that the variable selection procedure can decide whether to switch to one of the competing models or to stop at the current best model. Of the two procedures, backward elimination has two advantages. One is computational: step 2 of the forward selection requires calculation of a large number of competing models whereas step 2 of the backward elimination only requires one. The other is statistical and more subtle. Consider two predictor variables <span class="math inline">\(x_{i}\)</span> and <span class="math inline">\(x_{j}\)</span> and suppose that the forward selection procedure does not add either because their individual importance is low. It may be that their joint influence is important, but the forwards procedure has not been able to detect this. In contrast, the backward elimination procedure starts with all variables included and so is able to delete one and keep the other.</p>
<p>A stepwise regression algorithm can also combine <em>both</em> the backward elimination and forward selection procedures. The procedure is the same as forward selection, but immediately after each step of the forward selection algorithm, a step of backward elimination is carried out.</p>
<p>Variable selection solely based <span class="math inline">\(p\)</span> values is preferred only for certain applications such as analysis of factorial type experimental data where response surfaces are fitted. The base <code>R</code> does model selection based on <span class="math inline">\(AIC\)</span> which has to be as minimum as possible for a good model. We shall now discuss the concept of <span class="math inline">\(AIC\)</span> and other model selection criteria.</p>
<p>One way to balance model fit with model complexity (number of parameters) is to choose the model with the <strong>minimal</strong> value of Akaike Information Criterion (<strong>AIC</strong> for short, derived by Prof.&nbsp;Hirotugu Akaike as the minimum information theoretic criterion):</p>
<p><span class="math display">\[AIC = n\log \left( \frac{SSE}{n} \right) + 2p\]</span></p>
<p>Here <span class="math inline">\(n\)</span> is the size of the data set and <span class="math inline">\(p\)</span> is the number of variables in the model. A model with more variables (larger value of <span class="math inline">\(p\)</span>) will produce a smaller residual sum of squares SSE but is penalised by the second term.</p>
<p>Bayesian Information Criterion (BIC) (or also called Schwarz’s Bayesian criterion, SBC) places a higher penalty that depends on <span class="math inline">\(n\)</span>, the number of observations. As a result <span class="math inline">\(BIC\)</span> fares well for selecting a model that explains the relationships well while <span class="math inline">\(AIC\)</span> fares well when selecting a model for prediction purposes.</p>
<p>A number of corrections to <span class="math inline">\(AIC\)</span> and <span class="math inline">\(BIC\)</span> have been proposed in the literature depending on the type of model fitted. We will not study them in this course.</p>
<p>An alternative measure called Mallow’s <span class="math inline">\(C_{p}\)</span> index is also available using which we may judge whether the variables at the current step (smaller model) are excessive or short. If unimportant variables are added to the model, then the variance of the fitted values will increase. Similarly if important variables are added, then the bias of the fitted values will decrease. The <span class="math inline">\(C_{p}\)</span> index, which balances the variance and bias, is given by the formula <span class="math display">\[C_{p} = \frac{{\text  {SS Error for Smaller Model}}}{{\text {Mean Square Error for full regression}}} -(n-2p)\]</span> where <span class="math inline">\(p\)</span> = no. of estimated coefficients (including the intercept) in the smaller model and <span class="math inline">\(n\)</span> = total number of observations. The most desired value for the <span class="math inline">\(C_{p}\)</span> index is the number of parameters (including the <span class="math inline">\(y\)</span>-intercept) or just smaller. If <span class="math inline">\(C_p&gt;&gt;p\)</span>, the model is biased. On the other hand, if <span class="math inline">\(C_p&lt;&lt;p\)</span>, the model associated variability is too large. The trade-off between bias and variance is best when <span class="math inline">\(C_{p}=p\)</span>. But the <span class="math inline">\(C_{p}\)</span> index is not useful in judging the adequacy of the full regression model because it requires an assumption on what constitutes the full regression. This is not an issue with the <span class="math inline">\(AIC\)</span> or <span class="math inline">\(BIC\)</span> criterion.</p>
<p>For prediction modelling, the following three measures are popular and the <code>modelr</code> package will extract these prediction accuracy measures and many more.</p>
<p><em>Mean Squared Deviation</em> (MSD):</p>
<p>MSD is the mean of the squared errors (i.e., deviations).</p>
<p><span class="math display">\[MSD = \frac{\sum \left({\text {observation-fit}}\right)^2 }{{\text {number of observations}}},\]</span></p>
<p>MSD is also sometimes called the Mean Squared Error (MSE). Note that while computing the MSE, the divisor will be the degrees of freedom and not the number of observations. The square-root of MSE is abbreviated as <em>RMSE</em>, and commonly employed as a measure of prediction accuracy.</p>
<p><em>Mean Absolute Percentage Error</em> (MAPE):</p>
<p>MAPE is the average percentage relative error per observation. MAPE is defined as</p>
<p><span class="math display">\[MAPE =\frac{\sum \frac{\left|{\text {observation-fit}}\right|}{{\text {observation}}} }{{\text {number of observations}}} {\times100}.\]</span></p>
<p>Note that MAPE is unitless.</p>
<p><em>Mean Absolute Deviation</em> (MAD):</p>
<p>MAD is the average absolute error per observation and also known as MAE (mean absolute error). MAD is defined as</p>
<p><span class="math display">\[MAD =\frac{\sum \left|{\text {observation-fit}}\right| }{{\text {number of observations}}}.\]</span></p>
<p>For the horsehearts data, stepwise selection can be implemented using many R packages including <code>MASS</code>, <code>car</code>, <code>leaps</code> <code>HH</code> <code>caret</code>, and <code>SignifReg</code>. Examples given below are based on the horses hearts data.</p>
<ol type="1">
<li>The <code>step()</code> function performs a combination of both forward and backward regression. This method favours a model with four variables: <code>WEIGHT ~ INNERDIA + OUTERSYS + EXTSYS + EXTDIA</code></li>
</ol>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>full.model <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT <span class="sc">~</span> ., <span class="at">data =</span> horsehearts)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>stats<span class="sc">::</span><span class="fu">step</span>(full.model) </span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="co"># or MASS::stepAIC(full.model)</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="co"># or step(full.model, trace = FALSE) </span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<ol start="2" type="1">
<li>The <code>stepAIC()</code> function from the MASS package can also be used instead of the <code>step()</code> function. Try-</li>
</ol>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS, <span class="at">exclude=</span><span class="st">"select"</span>)</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="fu">stepAIC</span>(full.reg, <span class="at">direction=</span><span class="st">"backward"</span>, <span class="at">trace =</span> <span class="cn">FALSE</span>)</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="fu">stepAIC</span>(full.reg, <span class="at">direction=</span><span class="st">"both"</span>, <span class="at">trace =</span> <span class="cn">FALSE</span>)</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>null.model <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT<span class="sc">~</span> <span class="dv">1</span>, <span class="at">data=</span>horsehearts)</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>stats<span class="sc">::</span><span class="fu">step</span>(</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>  full.reg, </span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">scope =</span> <span class="fu">list</span>(</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">lower =</span> null.model,</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">upper =</span> <span class="sc">~</span>INNERSYS<span class="sc">+</span>INNERDIA<span class="sc">+</span>OUTERSYS<span class="sc">+</span>OUTERDIA<span class="sc">+</span>EXTSYS<span class="sc">+</span>EXTDIA</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>    ), </span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">direction =</span> <span class="st">"forward"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<ol start="3" type="1">
<li>The <code>SignifReg</code> package allows variable selection under various criteria. Try-</li>
</ol>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(SignifReg)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="fu">SignifReg</span>(full.reg, </span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>          <span class="at">direction =</span> <span class="st">"backward"</span>, </span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>          <span class="at">criterion =</span> <span class="st">"BIC"</span>,</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>          <span class="at">adjust.method =</span> <span class="st">"none"</span>)</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a><span class="fu">SignifReg</span>(full.reg, </span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>          <span class="at">direction =</span> <span class="st">"backward"</span>, </span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>          <span class="at">criterion =</span> <span class="st">"r-adj"</span>, </span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>          <span class="at">adjust.method =</span> <span class="st">"none"</span>)</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a><span class="fu">SignifReg</span>(full.reg, </span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>          <span class="at">direction =</span> <span class="st">"backward"</span>,</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>          <span class="at">criterion =</span> <span class="st">"p-value"</span>, </span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>          <span class="at">adjust.method =</span> <span class="st">"none"</span>)</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a><span class="fu">SignifReg</span>(full.reg, </span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>          <span class="at">direction =</span> <span class="st">"both"</span>,</span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a>          <span class="at">criterion =</span> <span class="st">"BIC"</span>,</span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a>          <span class="at">adjust.method =</span> <span class="st">"none"</span>)</span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a><span class="fu">SignifReg</span>(full.reg, </span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true" tabindex="-1"></a>          <span class="at">direction =</span> <span class="st">"both"</span>,</span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true" tabindex="-1"></a>          <span class="at">criterion =</span> <span class="st">"r-adj"</span>,</span>
<span id="cb22-26"><a href="#cb22-26" aria-hidden="true" tabindex="-1"></a>          <span class="at">adjust.method =</span> <span class="st">"none"</span>)</span>
<span id="cb22-27"><a href="#cb22-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-28"><a href="#cb22-28" aria-hidden="true" tabindex="-1"></a><span class="fu">SignifReg</span>(full.reg, </span>
<span id="cb22-29"><a href="#cb22-29" aria-hidden="true" tabindex="-1"></a>          <span class="at">direction =</span> <span class="st">"both"</span>, </span>
<span id="cb22-30"><a href="#cb22-30" aria-hidden="true" tabindex="-1"></a>          <span class="at">criterion =</span> <span class="st">"p-value"</span>,</span>
<span id="cb22-31"><a href="#cb22-31" aria-hidden="true" tabindex="-1"></a>          <span class="at">adjust.method =</span> <span class="st">"none"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The forward selection procedure also picks only just two variables as seen from the following output:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>full.model <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT <span class="sc">~</span> ., <span class="at">data=</span>horsehearts)</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>stmdl <span class="ot">&lt;-</span> <span class="fu">SignifReg</span>(full.reg, </span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>                   <span class="at">direction =</span> <span class="st">"both"</span>,</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>                   <span class="at">criterion =</span> <span class="st">"AIC"</span>,</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>                   <span class="at">adjust.method =</span> <span class="st">"none"</span>)</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>stmdl <span class="sc">|&gt;</span> <span class="fu">tidy</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<div class="cell-output-display">
<table class="table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: left;">term</th>
<th style="text-align: right;">estimate</th>
<th style="text-align: right;">std.error</th>
<th style="text-align: right;">statistic</th>
<th style="text-align: right;">p.value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">(Intercept)</td>
<td style="text-align: right;">-1.512</td>
<td style="text-align: right;">0.468</td>
<td style="text-align: right;">-3.230</td>
<td style="text-align: right;">0.002</td>
</tr>
<tr class="even">
<td style="text-align: left;">INNERDIA</td>
<td style="text-align: right;">0.799</td>
<td style="text-align: right;">0.267</td>
<td style="text-align: right;">2.987</td>
<td style="text-align: right;">0.005</td>
</tr>
<tr class="odd">
<td style="text-align: left;">OUTERSYS</td>
<td style="text-align: right;">0.493</td>
<td style="text-align: right;">0.204</td>
<td style="text-align: right;">2.415</td>
<td style="text-align: right;">0.020</td>
</tr>
<tr class="even">
<td style="text-align: left;">EXTSYS</td>
<td style="text-align: right;">-0.236</td>
<td style="text-align: right;">0.122</td>
<td style="text-align: right;">-1.938</td>
<td style="text-align: right;">0.059</td>
</tr>
<tr class="odd">
<td style="text-align: left;">EXTDIA</td>
<td style="text-align: right;">0.250</td>
<td style="text-align: right;">0.130</td>
<td style="text-align: right;">1.920</td>
<td style="text-align: right;">0.062</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>For the full regression model, the <span class="math inline">\(AIC\)</span> is -40.5 and it drops to -42.35 for the four variable model. That is, according to the AIC criterion, a further reduction in model size does not compensate for the decline in model fit as measured by the AIC. The <span class="math inline">\(C_{p}\)</span> index also recommends the four variable model because for the <span class="math inline">\(C_{p}\)</span> value of 4.9 is closer to 5, the number of model coefficients.</p>
<ol start="4" type="1">
<li>Step-wise selection of predictors can also be done along with cross validation in each step. The <code>R</code> package <em>caret</em> enables this. For the horses heart data, the following codes perform the backward regression.</li>
</ol>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(leaps)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>fitControl <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">"repeatedcv"</span>, </span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">number =</span> <span class="dv">5</span>, </span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">repeats =</span> <span class="dv">100</span></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>leapBackwardfit <span class="ot">&lt;-</span> <span class="fu">train</span>(</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>  WEIGHT <span class="sc">~</span> ., </span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> horsehearts,</span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">trControl =</span> fitControl, </span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">"leapBackward"</span></span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(leapBackwardfit)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Note that an asterisk in the row means that a particular variable is included in the step. The model in the last step excludes <code>INNERSYS</code> and <code>OUTERDIA.</code> On the other hand, the forward regression includes only two variables namely <code>INNERDIA</code> and <code>OUTERSYS</code>. We can also directly use the <code>leaps</code> package without cross validation.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>fitControl <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">"repeatedcv"</span>, </span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">number =</span> <span class="dv">5</span>, </span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">repeats =</span> <span class="dv">100</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>leapForwardfit <span class="ot">&lt;-</span> <span class="fu">train</span>(</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>  WEIGHT <span class="sc">~</span> ., </span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> horsehearts,</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">trControl =</span> fitControl, </span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">"leapForward"</span></span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(leapForwardfit)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Subset selection object
6 Variables  (and intercept)
         Forced in Forced out
INNERSYS     FALSE      FALSE
INNERDIA     FALSE      FALSE
OUTERSYS     FALSE      FALSE
OUTERDIA     FALSE      FALSE
EXTSYS       FALSE      FALSE
EXTDIA       FALSE      FALSE
1 subsets of each size up to 2
Selection Algorithm: forward
         INNERSYS INNERDIA OUTERSYS OUTERDIA EXTSYS EXTDIA
1  ( 1 ) " "      "*"      " "      " "      " "    " "   
2  ( 1 ) " "      "*"      "*"      " "      " "    " "   </code></pre>
</div>
</div>
<section id="best-subsets-selection" class="level2">
<h2 class="anchored" data-anchor-id="best-subsets-selection">Best Subsets Selection</h2>
<p>An exhaustive screening of all possible regression models (and hence the name <strong>best subsets</strong> regression) can also be done using software. For example, there are 6 predictor variables in the horses’ hearts data. If we fix the number of predictors as 3, then <span class="math inline">\(\small {\left(\begin{array}{c} {6} \\ {3} \end{array}\right)} = 20\)</span> regression models are possible. One may select the ‘best’ 3-variable model based on criteria such as AIC, <span class="math inline">\(C_{p}\)</span>, <span class="math inline">\(R_{adj}^{2}\)</span> etc. Software must be employed to perform the conventional stepwise regression procedures. Software algorithms give one or more best candidate models fixing the number of variables in each step.</p>
<p>On the basis of our analysis on the horses’ hear data, we might decide to recommend the model with predictor variables <code>EXTDIA</code>, <code>EXTSYS</code>, <code>INNERDIA</code> and <code>OUTERSYS</code>. In particular if the model is to be used for describing relationships then we would tend to include more variables. For prediction purposes, however, a simpler feasible model is preferred and in this case we may opt for the smaller model with only <code>INNERDIA</code> and <code>OUTERSYS</code>. See <a href="#tbl-subset11">Table&nbsp;4</a> produced using the following <code>R</code> codes:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(leaps)</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(HH)</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(kableExtra)</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>b.model <span class="ot">&lt;-</span> <span class="fu">regsubsets</span>(WEIGHT <span class="sc">~</span> ., <span class="at">data =</span> horsehearts) <span class="sc">|&gt;</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summaryHH</span>() </span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>b.model <span class="sc">|&gt;</span> </span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">3</span>) <span class="sc">|&gt;</span> </span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_styling</span>(<span class="at">bootstrap_options =</span> <span class="st">"basic"</span>, <span class="at">full_width =</span> F)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="tbl-subset11" class="anchored">
<table class="table table-sm table-striped small" data-quarto-postprocess="true">
<caption>Table&nbsp;4: Subset selection</caption>
<thead>
<tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th">model</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">p</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">rsq</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">rss</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">adjr2</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">cp</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">bic</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">stderr</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">INNERD</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">0.658</td>
<td style="text-align: right;">19.450</td>
<td style="text-align: right;">0.650</td>
<td style="text-align: right;">11.923</td>
<td style="text-align: right;">-41.677</td>
<td style="text-align: right;">0.665</td>
</tr>
<tr class="even">
<td style="text-align: left;">INNERD-OUTERS</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">0.715</td>
<td style="text-align: right;">16.173</td>
<td style="text-align: right;">0.702</td>
<td style="text-align: right;">4.838</td>
<td style="text-align: right;">-46.335</td>
<td style="text-align: right;">0.613</td>
</tr>
<tr class="odd">
<td style="text-align: left;">INNERD-OUTERS-OUTERD</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">0.718</td>
<td style="text-align: right;">16.043</td>
<td style="text-align: right;">0.698</td>
<td style="text-align: right;">6.477</td>
<td style="text-align: right;">-42.878</td>
<td style="text-align: right;">0.618</td>
</tr>
<tr class="even">
<td style="text-align: left;">INNERD-OUTERS-EXTS-EXTD</td>
<td style="text-align: right;">5</td>
<td style="text-align: right;">0.741</td>
<td style="text-align: right;">14.739</td>
<td style="text-align: right;">0.715</td>
<td style="text-align: right;">4.862</td>
<td style="text-align: right;">-42.949</td>
<td style="text-align: right;">0.600</td>
</tr>
<tr class="odd">
<td style="text-align: left;">INNERD-OUTERS-OUTERD-EXTS-EXTD</td>
<td style="text-align: right;">6</td>
<td style="text-align: right;">0.749</td>
<td style="text-align: right;">14.272</td>
<td style="text-align: right;">0.718</td>
<td style="text-align: right;">5.566</td>
<td style="text-align: right;">-40.602</td>
<td style="text-align: right;">0.597</td>
</tr>
<tr class="even">
<td style="text-align: left;">INNERS-INNERD-OUTERS-OUTERD-EXTS-EXTD</td>
<td style="text-align: right;">7</td>
<td style="text-align: right;">0.753</td>
<td style="text-align: right;">14.067</td>
<td style="text-align: right;">0.714</td>
<td style="text-align: right;">7.000</td>
<td style="text-align: right;">-37.437</td>
<td style="text-align: right;">0.601</td>
</tr>
</tbody>
</table>
</div>


</div>
</div>
<p>Sometimes theory may indicate that a certain explanatory variable should be included in the model (e.g.&nbsp;due to small sample size). If this variable is found to make an insignificant contribution to the model, then one should exclude the variable when the model is to be used for prediction but if the model is to be used for explanation purposes only then the variable should be included. Other considerations such as cost and time may also be taken into account. For every method or algorithm, one could find peculiar data sets where it fouls up. The moral – be alert and don’t automatically accept models thrown up by a program. Note there is <strong>never one right answer</strong> as different methods and different criteria lead to different models.</p>
<p>Variable selection procedures can be a valuable tool in data analysis, particularly in the early stages of building a model. At the same time, they present certain dangers. There are several reasons for this:</p>
<ol type="1">
<li><p>These procedures automatically snoop though many models and may select ones which, by chance, happen to fit well.</p></li>
<li><p>These forward or backward stepwise procedures are <em>heuristic</em> (i.e., shortcut) algorithms, which often work very well but which may not always select the best model for a given number of predictors (here best may refer to adjusted <span class="math inline">\(R^2\)</span>-values, or AIC or some other criterion).</p></li>
<li><p>Automatic procedures cannot take into account special knowledge the analyst may have about the data. Therefore, the model selected may not be the best (or make sense) from a practical point of view.</p></li>
<li><p>Methods are available that <em>shrink</em> coefficients towards zero. The least squares approach minimises the residual sums of squares or RSS without placing any constraint on the coefficients. The shrinkage methods, which place a constraint on the coefficients, work well when there are large numbers of predictors. A <em>ridge regression</em> shrinks the coefficients towards zero but in relation each other. On the other hand, (Least Absolute Selection and Shrinkage Operator) <em>lasso</em> regression shrinks some of coefficients to zero which means these predictors can be dropped. Note that the ridge regression does not completely remove predictors. By shrinking large coefficients, we obtain a model with higher bias but lower variance. This process is known as <em>regularisation</em> in the literature (not covered in this course).</p></li>
</ol>
</section>
</section>
<section id="polynomial-models" class="level1">
<h1>Polynomial Models</h1>
<p>Consider the <strong>pinetree</strong> data set which contains the circumference measurements of pine trees at four positions. The simple regression of the top circumference on the first (bottom) circumference, the fit is <span class="math inline">\({\text {Top = -6.33 + 0.763 First}}\)</span>. This fit is satisfactory on many counts (highly significant <span class="math inline">\(t\)</span> and <span class="math inline">\(F\)</span> values, high <span class="math inline">\(R^{2}\)</span> etc); see <a href="#tbl-poly1tidy">Table&nbsp;5</a> and <a href="#tbl-poly1glance">Table&nbsp;6</a>.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="fu">download.file</span>(</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">url =</span> <span class="st">"http://www.massey.ac.nz/~anhsmith/data/pinetree.RData"</span>, </span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">destfile =</span> <span class="st">"pinetree.RData"</span>)</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="st">"pinetree.RData"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>pine1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(Top <span class="sc">~</span> First, <span class="at">data =</span> pinetree) </span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>pine1 <span class="sc">|&gt;</span> <span class="fu">tidy</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 5
  term        estimate std.error statistic  p.value
  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
1 (Intercept)   -6.33     0.765      -8.28 2.10e-11
2 First          0.763    0.0240     31.8  2.20e-38</code></pre>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="tbl-poly1tidy" class="anchored">
<table class="table table-sm table-striped small">
<caption>Table&nbsp;5: tidy() output of lm(Top~First, data=pinetree)</caption>
<thead>
<tr class="header">
<th style="text-align: left;">term</th>
<th style="text-align: right;">estimate</th>
<th style="text-align: right;">std.error</th>
<th style="text-align: right;">statistic</th>
<th style="text-align: right;">p.value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">(Intercept)</td>
<td style="text-align: right;">-6.334</td>
<td style="text-align: right;">0.765</td>
<td style="text-align: right;">-8.278</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">First</td>
<td style="text-align: right;">0.763</td>
<td style="text-align: right;">0.024</td>
<td style="text-align: right;">31.779</td>
<td style="text-align: right;">0</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>pine1 <span class="sc">|&gt;</span> </span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">glance</span>() <span class="sc">|&gt;</span> </span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(adj.r.squared, sigma, statistic, p.value, AIC, BIC)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="tbl-poly1glance" class="anchored">
<table class="table table-sm table-striped small">
<caption>Table&nbsp;6: glance() output of lm(Top~First, data=pinetree)</caption>
<thead>
<tr class="header">
<th style="text-align: right;">adj.r.squared</th>
<th style="text-align: right;">sigma</th>
<th style="text-align: right;">statistic</th>
<th style="text-align: right;">p.value</th>
<th style="text-align: right;">AIC</th>
<th style="text-align: right;">BIC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">0.945</td>
<td style="text-align: right;">1.291</td>
<td style="text-align: right;">1009.896</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">204.85</td>
<td style="text-align: right;">211.133</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>The residual plot, shown as <a href="#fig-pine1">Figure&nbsp;7</a>, still provides an important clue that we should try a polynomial (cubic) model.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggfortify)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>Registered S3 method overwritten by 'ggfortify':
  method          from   
  autoplot.glmnet parsnip</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(pine1, <span class="at">which=</span><span class="dv">1</span>, <span class="at">ncol=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-pine1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="7-multiple_files/figure-html/fig-pine1-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;7: Residuals vs fits plot</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>pine3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(Top <span class="sc">~</span> <span class="fu">poly</span>(First, <span class="dv">3</span>, <span class="at">raw=</span><span class="cn">TRUE</span>), </span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>            <span class="at">data =</span> pinetree)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><a href="#tbl-poly3tidy">Table&nbsp;7</a> shows the significance results for the polynomial model <span class="math inline">\({\text Top=44.1 - 3.97First+0.142}\left({\text First}\right)^{2} - 0.00135\left(\text {First}\right)^{3}\)</span>. This model has achieved a good reduction in the residual standard error and improved AIC and BIC (see <a href="#tbl-poly3glance">Table&nbsp;8</a>). The residual diagnostic plots are somewhat satisfactory. The Scale-Location plot suggests that there may be a subgrouping variable. The fitted model can be further improved using the Area categorical factor. This topic, known as the analysis of covariance will be covered later on. Note that both models are satisfactory in terms of Cook’s distance. A few leverage or <span class="math inline">\(h_{ii}\)</span> values cause concern seen in <a href="#fig-pinelev">Figure&nbsp;8</a> but we will ignore them given the size of the data set.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>pine3 <span class="sc">|&gt;</span> <span class="fu">tidy</span>() </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="tbl-poly3tidy" class="anchored">
<table class="table table-sm table-striped small">
<caption>Table&nbsp;7: tidy() output of lm(Top~poly(First, 3, raw=TRUE), data=pinetree)</caption>
<thead>
<tr class="header">
<th style="text-align: left;">term</th>
<th style="text-align: right;">estimate</th>
<th style="text-align: right;">std.error</th>
<th style="text-align: right;">statistic</th>
<th style="text-align: right;">p.value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">(Intercept)</td>
<td style="text-align: right;">44.1213</td>
<td style="text-align: right;">7.0391</td>
<td style="text-align: right;">6.2680</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">poly(First, 3, raw = TRUE)1</td>
<td style="text-align: right;">-3.9716</td>
<td style="text-align: right;">0.6951</td>
<td style="text-align: right;">-5.7141</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">poly(First, 3, raw = TRUE)2</td>
<td style="text-align: right;">0.1416</td>
<td style="text-align: right;">0.0221</td>
<td style="text-align: right;">6.3939</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">poly(First, 3, raw = TRUE)3</td>
<td style="text-align: right;">-0.0014</td>
<td style="text-align: right;">0.0002</td>
<td style="text-align: right;">-5.9510</td>
<td style="text-align: right;">0</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>pine3 <span class="sc">|&gt;</span> </span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">glance</span>() <span class="sc">|&gt;</span> </span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(adj.r.squared, sigma, statistic, p.value, AIC, BIC) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="tbl-poly3glance" class="anchored">
<table class="table table-sm table-striped small">
<caption>Table&nbsp;8: glance() output of lm(Top~poly(First,3, raw=TRUE), data=pinetree)</caption>
<thead>
<tr class="header">
<th style="text-align: right;">adj.r.squared</th>
<th style="text-align: right;">sigma</th>
<th style="text-align: right;">statistic</th>
<th style="text-align: right;">p.value</th>
<th style="text-align: right;">AIC</th>
<th style="text-align: right;">BIC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">0.97</td>
<td style="text-align: right;">0.89</td>
<td style="text-align: right;">725.98</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">162.46</td>
<td style="text-align: right;">172.93</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(pine3, <span class="at">which=</span><span class="dv">5</span>, <span class="at">ncol=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-pinelev" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="7-multiple_files/figure-html/fig-pinelev-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;8: Residual vs Leverage plot</figcaption>
</figure>
</div>
</div>
</div>
<p>How quadratic and quartic models fare compared to the cubic fit is also of interest. Try the <code>R</code> code given below and compare the outputs:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(WEIGHT <span class="sc">~</span> OUTERDIA, <span class="at">data =</span> horsehearts))</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(WEIGHT <span class="sc">~</span> <span class="fu">poly</span>(OUTERDIA,<span class="dv">2</span>, <span class="at">raw=</span>T), <span class="at">data =</span> horsehearts))</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(WEIGHT <span class="sc">~</span> <span class="fu">poly</span>(OUTERDIA,<span class="dv">3</span>, <span class="at">raw=</span>T), <span class="at">data =</span> horsehearts))</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(WEIGHT <span class="sc">~</span> <span class="fu">poly</span>(OUTERDIA,<span class="dv">4</span>, <span class="at">raw=</span>T), <span class="at">data =</span> horsehearts))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The key model summary measures of the four polynomial models are shown in <a href="#tbl-polysummary">Table&nbsp;9</a>. As expected, the <span class="math inline">\(R^2\)</span> value increases, although not by much in this case, as polynomial terms are added. Note that the multicollinearity among the polynomial terms renders all the coefficients of the quadratic regression insignificant at 5% level. For the cubic regression model, all the coefficients are significant. It is usual to keep adding the higher order terms until there is no significant increase in the additional variation explained (measured by the <span class="math inline">\(t\)</span> or <span class="math inline">\(F\)</span> statistic). Alternatively we may use the AIC criterion. In the above example, when the quartic term <code>OUTERDIA</code><span class="math inline">\(^4\)</span> is added, the AIC slightly increases to 114.99 (from 114.65) suggesting that we may stop with the cubic regression.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>modstats <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">straight.line =</span> <span class="fu">lm</span>(WEIGHT <span class="sc">~</span> OUTERDIA, </span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>                     <span class="at">data =</span> horsehearts), </span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">quadratic =</span> <span class="fu">lm</span>(WEIGHT <span class="sc">~</span> <span class="fu">poly</span>(OUTERDIA,<span class="dv">2</span>,<span class="at">raw=</span>T),</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>                 <span class="at">data=</span>horsehearts), </span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">cubic =</span> <span class="fu">lm</span>(WEIGHT<span class="sc">~</span> <span class="fu">poly</span>(OUTERDIA,<span class="dv">3</span>, <span class="at">raw=</span>T), </span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>             <span class="at">data=</span>horsehearts), </span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">quartic =</span> <span class="fu">lm</span>(WEIGHT<span class="sc">~</span> <span class="fu">poly</span>(OUTERDIA,<span class="dv">4</span>, <span class="at">raw=</span>T),</span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a>               <span class="at">data=</span>horsehearts)</span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">|&gt;</span> </span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">enframe</span>(</span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">name =</span> <span class="st">"model"</span>,</span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">value =</span> <span class="st">"fit"</span></span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">|&gt;</span> </span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">glanced =</span> <span class="fu">map</span>(fit, glance)) <span class="sc">|&gt;</span> </span>
<span id="cb40-16"><a href="#cb40-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unnest</span>(glanced) <span class="sc">|&gt;</span> </span>
<span id="cb40-17"><a href="#cb40-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(model, r.squared, adj.r.squared, sigma, </span>
<span id="cb40-18"><a href="#cb40-18" aria-hidden="true" tabindex="-1"></a>         statistic, AIC, BIC)</span>
<span id="cb40-19"><a href="#cb40-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-20"><a href="#cb40-20" aria-hidden="true" tabindex="-1"></a>modstats</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="tbl-polysummary" class="anchored">
<table class="table table-sm table-striped small">
<caption>Table&nbsp;9: Glancing Polynomial models</caption>
<colgroup>
<col style="width: 20%">
<col style="width: 14%">
<col style="width: 20%">
<col style="width: 8%">
<col style="width: 14%">
<col style="width: 10%">
<col style="width: 10%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">model</th>
<th style="text-align: right;">r.squared</th>
<th style="text-align: right;">adj.r.squared</th>
<th style="text-align: right;">sigma</th>
<th style="text-align: right;">statistic</th>
<th style="text-align: right;">AIC</th>
<th style="text-align: right;">BIC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">straight.line</td>
<td style="text-align: right;">0.47</td>
<td style="text-align: right;">0.46</td>
<td style="text-align: right;">0.83</td>
<td style="text-align: right;">39.13</td>
<td style="text-align: right;">117.01</td>
<td style="text-align: right;">122.50</td>
</tr>
<tr class="even">
<td style="text-align: left;">quadratic</td>
<td style="text-align: right;">0.48</td>
<td style="text-align: right;">0.46</td>
<td style="text-align: right;">0.83</td>
<td style="text-align: right;">19.87</td>
<td style="text-align: right;">118.17</td>
<td style="text-align: right;">125.49</td>
</tr>
<tr class="odd">
<td style="text-align: left;">cubic</td>
<td style="text-align: right;">0.54</td>
<td style="text-align: right;">0.51</td>
<td style="text-align: right;">0.79</td>
<td style="text-align: right;">16.38</td>
<td style="text-align: right;">114.65</td>
<td style="text-align: right;">123.79</td>
</tr>
<tr class="even">
<td style="text-align: left;">quartic</td>
<td style="text-align: right;">0.56</td>
<td style="text-align: right;">0.51</td>
<td style="text-align: right;">0.79</td>
<td style="text-align: right;">12.81</td>
<td style="text-align: right;">114.99</td>
<td style="text-align: right;">125.96</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>It is desirable to keep the coefficients the same when higher order polynomial terms are added. This can be done using orthogonal polynomial coefficients (we will skip the theory) for which we will avoid the argument <code>raw</code> within the function <code>poly()</code>. Try-</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(Top <span class="sc">~</span> <span class="fu">poly</span>(First,<span class="dv">1</span>), <span class="at">data=</span>pinetree)</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(Top <span class="sc">~</span> <span class="fu">poly</span>(First,<span class="dv">2</span>), <span class="at">data=</span>pinetree)</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(Top <span class="sc">~</span> <span class="fu">poly</span>(First,<span class="dv">3</span>), <span class="at">data=</span>pinetree)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Stepwise methods are not employed for developing polynomial models as it would not be appropriate (say) to have the linear and cubic terms but drop the quadratic one. The coefficient terms for the higher order terms become very small. It is also possible that the coefficient estimation may be incorrect due to ill conditioning of the data matrix which is used obtain the model coefficients. Some authors recommend appropriate rescaling of the polynomial terms (such as subtracting the mean etc) to avoid such problems.</p>
<p>The use of polynomials greater than second-order is discouraged. Higher-order polynomials are known to be extremely volatile; they have high variance, and make bad predictions. If you need a more flexible model, then it is generally better to use some sort of smoother than a high-order polynomial.</p>
<p>In fact, a popular method of smoothing is known as “local polynomial fitting”, or <strong>spline smoothing</strong>. Local polynomials are sometimes preferred to a single polynomial regression model for the whole data set. An example based on the <code>pinetree</code> data is shown in <a href="#fig-spline">Figure&nbsp;9</a> which uses the <code>bs()</code> function from the <em>splines</em> package.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>pinetree <span class="sc">|&gt;</span> </span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aes</span>(First, Top) <span class="sc">+</span></span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> lm, </span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>              <span class="at">formula =</span> y <span class="sc">~</span> splines<span class="sc">::</span><span class="fu">bs</span>(x, <span class="dv">3</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-spline" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="7-multiple_files/figure-html/fig-spline-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;9: Polynomial Spline smoothing</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="model-structure-and-other-issues" class="level1">
<h1>Model structure and other issues</h1>
<p>The difficult task in statistical modelling is the assessment of the underlying model structure or alternatively knowing the true form of the relationship. For example, the true relationship between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span> variables may be nonlinear. If we incorrectly assume a multiple linear relationship instead, a good model may not result. The interaction between the explanatory variables is also important and this topic is covered in a different section. We may also fit a robust linear model in order to validate the ordinary least squares fit. For the horses heart data, OUTERSYS and EXTDIA were short-listed as the predictors of WEIGHT using the AIC criterion. This least squares regression model can be compared to the robust versions as shown in <a href="#fig-mcompare1">Figure&nbsp;10</a>.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>hh_lm <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT <span class="sc">~</span> OUTERSYS <span class="sc">+</span> EXTDIA, <span class="at">data=</span>horsehearts)</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>hh_rlm <span class="ot">&lt;-</span> MASS<span class="sc">::</span><span class="fu">rlm</span>(WEIGHT <span class="sc">~</span> OUTERSYS <span class="sc">+</span> EXTDIA, <span class="at">data=</span>horsehearts)</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>hh_lmrob <span class="ot">&lt;-</span> robustbase<span class="sc">::</span><span class="fu">lmrob</span>(WEIGHT <span class="sc">~</span> OUTERSYS <span class="sc">+</span> EXTDIA, <span class="at">data=</span>horsehearts)</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>horsehearts <span class="sc">|&gt;</span> </span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gather_predictions</span>(hh_lm, hh_rlm, hh_lmrob) <span class="sc">%&gt;%</span> </span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>WEIGHT, <span class="at">y=</span>pred, <span class="at">colour=</span>model)) <span class="sc">+</span> </span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">slope=</span><span class="dv">1</span>, <span class="at">intercept =</span> <span class="dv">0</span>) <span class="sc">+</span> </span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Predicted WEIGHT"</span>) <span class="sc">+</span> <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Comparison of model predictions"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-mcompare1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="7-multiple_files/figure-html/fig-mcompare1-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;10: Comparison of predictions</figcaption>
</figure>
</div>
</div>
</div>
<p><a href="#fig-mcompare1">Figure&nbsp;10</a> shows that the scatter plot of predicted versus actual <span class="math inline">\(Y\)</span> values for the three fitted models which confirms that these models perform very similarly. We may also extract measures such as mean absolute percentage error (MAPE) or residual SD or root mean square error (RMSE) for the three models using <code>modelr</code> package; see the code shown below:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="fu">list</span>(<span class="at">hh_lm =</span> hh_lm, </span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>     <span class="at">hh_rlm =</span> hh_rlm, </span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">hh_lmrob =</span> hh_lmrob) <span class="sc">|&gt;</span> </span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">enframe</span>(<span class="st">"method"</span>, <span class="st">"fit"</span>) <span class="sc">|&gt;</span> </span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">MAPE =</span> <span class="fu">map_dbl</span>(fit, \(x){<span class="fu">mape</span>(x, horsehearts)}),</span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">RMSE =</span> <span class="fu">map_dbl</span>(fit, \(x){<span class="fu">rmse</span>(x, horsehearts)})</span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a>    )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 3 × 4
  method   fit      MAPE  RMSE
  &lt;chr&gt;    &lt;list&gt;  &lt;dbl&gt; &lt;dbl&gt;
1 hh_lm    &lt;lm&gt;    0.255 0.648
2 hh_rlm   &lt;rlm&gt;   0.247 0.651
3 hh_lmrob &lt;lmrob&gt; 0.243 0.655</code></pre>
</div>
</div>
<p>Measures such as AIC or BIC need corrections when the normality assumption does not hold but the above summary measures do not require such a distributional assumption to hold.</p>
<p>If a large dataset is in hand, a part of the data (training data) can be used to fit the model and then we can see how well the fitted model works for the remaining data.</p>
</section>
<section id="summary" class="level1">
<h1>Summary</h1>
<p>Regression methods are the most commonly used of statistics techniques. The main aim is to fit a model by least squares to explain the variation in the response variable <span class="math inline">\(Y\)</span> by using one or more explanatory variables <span class="math inline">\(X_1\)</span>, <span class="math inline">\(X_2\)</span>, … , <span class="math inline">\(X_k\)</span>. The correlation coefficient <span class="math inline">\(r_{xy}\)</span> measures the strength of the linear relationship between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span>; <span class="math inline">\(R^{2}\)</span> measures the strength of the linear relationship between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X_1\)</span>, <span class="math inline">\(X_2\)</span>, … , <span class="math inline">\(X_k\)</span>. When <span class="math inline">\(k\)</span>=1, then <span class="math inline">\(r_{xy}^{2} =R^{2}\)</span>. Scatter plots and correlation coefficients provide important clues to the inter-relationships between the variables.</p>
<p>In building up a model by adding new variables, the correlation (or overlap) with <span class="math inline">\(y\)</span> is important but the correlations between a new explanatory variable and each of the existing explanatory variables also determine how effective the addition of the variable will be.</p>
<p>Stepwise regression procedures identify potentially good regression models by repeatedly comparing an existing model with other models in which an explanatory variable has been either deleted or added, using some criterion such as significance of the deleted or added term (as measured by the <span class="math inline">\(p\)</span>-value of the relevant <span class="math inline">\(t\)</span> or <span class="math inline">\(F\)</span> statistic) or the AIC of the model. Polynomial regression models employ the square, cube etc terms of the original variables as additional predictors.</p>
<p>When at least two explanatory variables are highly correlated, we have multicollinear data. The effect is that the variance of least square estimators will be inflated rendering the coefficients insignificant and hence we may need to discard one or more of the highly correlated variables.</p>
<p>EDA plots of residuals help to answer the question as to whether the fit is good or whether a transformation may help or whether other variables (including square, cubic etc) should be added. If residuals are plotted against fitted <span class="math inline">\(Y\)</span> or <span class="math inline">\(X\)</span> variables no discernible pattern should be observed. Estimated regression coefficients may be affected by leverage points, and hence influence diagnostics are performed.</p>
</section>
<section id="what-you-should-know" class="level1">
<h1>What you should know</h1>
<p>By the end of this chapter you should be able to:</p>
<ul>
<li>Fit and display a multiple regression (2 or more predictor variables).</li>
<li>Check the assumptions of a multiple regression using residual diagnostic plots, tests for assumptions, and examine multicollinearity.</li>
<li>Measure variability explained by the model and predictors.</li>
<li>Use a fitted regression to predict new data.</li>
<li>Explain the significance of your model and interpret findings in context of the data and hypotheses.</li>
<li>Describe model comparison/selection and polynomial terms.</li>
</ul>


<!-- -->

</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../studyguide/6-single.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Chapter 6: Models with a Single Continuous Predictor</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../studyguide/8-anova.html" class="pagination-link">
        <span class="nav-page-text">Chapter 8: Analysis of Variance (ANOVA) and Covariance (ANCOVA)</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb46" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Chapter 7: Models with Multiple Continuous Predictors"</span></span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a>In this chapter, we consider **multiple regression** and other models in which there are more than one predictor (or $X$) variable. This extends what we covered in the last chapter where we examined one predictor to multiple predictors. Once again our focus is on finding the estimates of coefficients or parameters in multiple linear regression models by the method of **least squares**. For this we assume that</span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>The predictor (or explanatory or controlled or covariate) variables $X_i$ $(i=1,2,...,p)$ are known without error.</span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>The mean or expected value of the dependent (or response) variable $Y$ is related to the $X_i$ $(i=1,2,...,p)$ according to a linear expression</span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a>    $E(y\mid x)=a+ b_1 x_l + b_2 x_2 + ....+ b_p x_p$</span>
<span id="cb46-13"><a href="#cb46-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-14"><a href="#cb46-14" aria-hidden="true" tabindex="-1"></a>    i.e. a straight line (for one $X$ variable), a plane (for two $X$ variables) or a hyperplane (for more than two $X$ variables). This means that the fitted model can be written as</span>
<span id="cb46-15"><a href="#cb46-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-16"><a href="#cb46-16" aria-hidden="true" tabindex="-1"></a>    *fit* = $a+ b_1 x_l + b_2 x_2 + ....+ b_p x_p$.</span>
<span id="cb46-17"><a href="#cb46-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-18"><a href="#cb46-18" aria-hidden="true" tabindex="-1"></a><span class="ss">3.  </span>There is random (unpredictable, unexplained) variability of $Y$ about the fitted model. That is,</span>
<span id="cb46-19"><a href="#cb46-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-20"><a href="#cb46-20" aria-hidden="true" tabindex="-1"></a>    $y$ = fit + residual.</span>
<span id="cb46-21"><a href="#cb46-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-22"><a href="#cb46-22" aria-hidden="true" tabindex="-1"></a><span class="ss">4.  </span>In order to apply statistical inferences to a model, a number of assumptions need to be made. To be able to form $t$ and $F$ statistics, we assume that</span>
<span id="cb46-23"><a href="#cb46-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-24"><a href="#cb46-24" aria-hidden="true" tabindex="-1"></a><span class="ss">5.  </span>The variability in $Y$ about the line (plane etc) is constant and independent of the $X$ variables.</span>
<span id="cb46-25"><a href="#cb46-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-26"><a href="#cb46-26" aria-hidden="true" tabindex="-1"></a><span class="ss">6.  </span>The variability of $Y$ follows a Normal distribution. That is, the distribution of $Y$ (given certain values of the $X_i$ variables) is Normal.</span>
<span id="cb46-27"><a href="#cb46-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-28"><a href="#cb46-28" aria-hidden="true" tabindex="-1"></a><span class="ss">7.  </span>Given (different) outcomes of the $X$ variables, the corresponding $Y$ variables are independent of one another.</span>
<span id="cb46-29"><a href="#cb46-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-30"><a href="#cb46-30" aria-hidden="true" tabindex="-1"></a>We will continue to use the data set **horsehearts** of the weights of horses' hearts and other related measurements.</span>
<span id="cb46-31"><a href="#cb46-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-32"><a href="#cb46-32" aria-hidden="true" tabindex="-1"></a><span class="fu"># Full Regression</span></span>
<span id="cb46-33"><a href="#cb46-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-34"><a href="#cb46-34" aria-hidden="true" tabindex="-1"></a>With one explanatory variable scatterplots and correlation coefficients provided good starting points for exploring relationships between the explanatory and response variables. This is even more relevant with two or more explanatory variables. For the horses' hearts data, there are six potential explanatory variables; namely <span class="in">`EXTDIA`</span>, <span class="in">`EXTSYS`</span>, <span class="in">`INNERDIA`</span>, <span class="in">`INNERSYS`</span>, <span class="in">`OUTERDIA`</span> and <span class="in">`OUTERSYS`</span>. These measurements of heart width are made of the exterior width, inner wall and outer wall at two different phases, the diastole phase and the systole phase. So a matrix of scatter plots (or matrix plot) of these variables will be useful for exploratory analysis.</span>
<span id="cb46-35"><a href="#cb46-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-36"><a href="#cb46-36" aria-hidden="true" tabindex="-1"></a>It is also a good idea to form the simple correlation coefficients between each pair of explanatory variables and between each explanatory variable and the response variable $Y$, the weight of the horse's heart. These correlation coefficients can be displayed in a **correlation matrix** as shown in @fig-multggally.</span>
<span id="cb46-37"><a href="#cb46-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-40"><a href="#cb46-40" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-41"><a href="#cb46-41" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb46-42"><a href="#cb46-42" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb46-43"><a href="#cb46-43" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidymodels)</span>
<span id="cb46-44"><a href="#cb46-44" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(kableExtra)</span>
<span id="cb46-45"><a href="#cb46-45" aria-hidden="true" tabindex="-1"></a><span class="fu">theme_set</span>(<span class="fu">theme_minimal</span>())</span>
<span id="cb46-46"><a href="#cb46-46" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-47"><a href="#cb46-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-50"><a href="#cb46-50" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-51"><a href="#cb46-51" aria-hidden="true" tabindex="-1"></a><span class="fu">download.file</span>(</span>
<span id="cb46-52"><a href="#cb46-52" aria-hidden="true" tabindex="-1"></a>  <span class="at">url =</span> <span class="st">"http://www.massey.ac.nz/~anhsmith/data/horsehearts.RData"</span>,</span>
<span id="cb46-53"><a href="#cb46-53" aria-hidden="true" tabindex="-1"></a>  <span class="at">destfile =</span> <span class="st">"horsehearts.RData"</span>)</span>
<span id="cb46-54"><a href="#cb46-54" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="st">"horsehearts.RData"</span>)</span>
<span id="cb46-55"><a href="#cb46-55" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-56"><a href="#cb46-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-59"><a href="#cb46-59" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-60"><a href="#cb46-60" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb46-61"><a href="#cb46-61" aria-hidden="true" tabindex="-1"></a><span class="co">#| mesasge: false</span></span>
<span id="cb46-62"><a href="#cb46-62" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-multggally</span></span>
<span id="cb46-63"><a href="#cb46-63" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: 'Scatter plot and correlation matrix'</span></span>
<span id="cb46-64"><a href="#cb46-64" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 7</span></span>
<span id="cb46-65"><a href="#cb46-65" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 7</span></span>
<span id="cb46-66"><a href="#cb46-66" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(GGally)</span>
<span id="cb46-67"><a href="#cb46-67" aria-hidden="true" tabindex="-1"></a><span class="fu">ggpairs</span>(horsehearts)</span>
<span id="cb46-68"><a href="#cb46-68" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-69"><a href="#cb46-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-70"><a href="#cb46-70" aria-hidden="true" tabindex="-1"></a>It is also possible to obtain the $p$-values for all the simple correlation coefficients displayed above and test whether these are significantly different from zero.</span>
<span id="cb46-71"><a href="#cb46-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-72"><a href="#cb46-72" aria-hidden="true" tabindex="-1"></a>A number of facts about the data emerge from our EDA. All of the correlation coefficients are positive and reasonably large which indicates that with large hearts all the lengths increase in a fairly uniform manner. The predictor variables are also highly inter-correlated. **This suggests that not all of these variables are needed but only a subset of them**.</span>
<span id="cb46-73"><a href="#cb46-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-74"><a href="#cb46-74" aria-hidden="true" tabindex="-1"></a>The usual <span class="in">`tidy()`</span> function output of multiple regression weight on all of the available (six) predictors is shown in @tbl-fullregtidy.</span>
<span id="cb46-75"><a href="#cb46-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-76"><a href="#cb46-76" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, echo=TRUE, results='hide'}</span></span>
<span id="cb46-77"><a href="#cb46-77" aria-hidden="true" tabindex="-1"></a>full.reg <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT<span class="sc">~</span> ., <span class="at">data=</span>horsehearts)</span>
<span id="cb46-78"><a href="#cb46-78" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(full.reg) <span class="co"># or summary(full.reg) </span></span>
<span id="cb46-79"><a href="#cb46-79" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-80"><a href="#cb46-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-81"><a href="#cb46-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-84"><a href="#cb46-84" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-85"><a href="#cb46-85" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb46-86"><a href="#cb46-86" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tbl-fullregtidy</span></span>
<span id="cb46-87"><a href="#cb46-87" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: 'Full Regression tidy() output'</span></span>
<span id="cb46-88"><a href="#cb46-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-89"><a href="#cb46-89" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(full.reg) <span class="sc">|&gt;</span> <span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">3</span>)</span>
<span id="cb46-90"><a href="#cb46-90" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb46-91"><a href="#cb46-91" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-92"><a href="#cb46-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-93"><a href="#cb46-93" aria-hidden="true" tabindex="-1"></a>This regression model is known as the **full regression** because we have included all the predictors in our model. The <span class="in">`R`</span> syntax <span class="in">`~.`</span> means that we are placing all variables in the dataframe except the one selected as the response variable. We note that the slope coefficients of the predictors <span class="in">`INNERDIA`</span>, <span class="in">`INNERSYS`</span>, and <span class="in">`OUTERDIA`</span> are not significant at 5% level. This confirms that we do not need to place all six predictors in the model but only a subset of them.</span>
<span id="cb46-94"><a href="#cb46-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-95"><a href="#cb46-95" aria-hidden="true" tabindex="-1"></a>The highly correlated predictor <span class="in">`INNERDIA`</span> (see @fig-multggally) is also found to have a insignificant coefficient in @tbl-fullregtidy. This is somewhat surprising and casts doubts on the suitability of the full regression fit. If two or more explanatory variables are very highly correlated (i.e. almost collinear), then we deal with **multicollinearity**. The estimated standard errors of the regression coefficients will be inflated in the presence of multicollinearity. As result, the $t$-value will become small leading to a model with many insignificant coefficients. Multicollinearity does not affect the residual standard error much. The obvious remedy for multicollinearity is that one or more of the highly correlated variables can be dropped. Measures such as the Variance Inflation factor (**VIF**) are available to study the effect of multicollinearity. A VIF factor of more than 5 for a coefficient means that its variance is artificially inflated by the high correlation among the predictors. For the full regression model, the VIF factors are obtained using the <span class="in">`car`</span> package function <span class="in">`vif()`</span> and shown as @tbl-fullregvif.</span>
<span id="cb46-96"><a href="#cb46-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-97"><a href="#cb46-97" aria-hidden="true" tabindex="-1"></a><span class="in">```{r , echo=TRUE, results='hide'}</span></span>
<span id="cb46-98"><a href="#cb46-98" aria-hidden="true" tabindex="-1"></a>car<span class="sc">::</span><span class="fu">vif</span>(full.reg)</span>
<span id="cb46-99"><a href="#cb46-99" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-100"><a href="#cb46-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-103"><a href="#cb46-103" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-104"><a href="#cb46-104" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb46-105"><a href="#cb46-105" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tbl-fullregvif</span></span>
<span id="cb46-106"><a href="#cb46-106" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: 'Variance Inflation Factors'</span></span>
<span id="cb46-107"><a href="#cb46-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-108"><a href="#cb46-108" aria-hidden="true" tabindex="-1"></a><span class="co"># if(knitr::is_html_output()) {</span></span>
<span id="cb46-109"><a href="#cb46-109" aria-hidden="true" tabindex="-1"></a><span class="co"># </span></span>
<span id="cb46-110"><a href="#cb46-110" aria-hidden="true" tabindex="-1"></a><span class="co">#     car::vif(full.reg) |&gt; </span></span>
<span id="cb46-111"><a href="#cb46-111" aria-hidden="true" tabindex="-1"></a><span class="co">#     kable(digits = 2,</span></span>
<span id="cb46-112"><a href="#cb46-112" aria-hidden="true" tabindex="-1"></a><span class="co">#           table.attr = 'data-quarto-disable-processing="true"'</span></span>
<span id="cb46-113"><a href="#cb46-113" aria-hidden="true" tabindex="-1"></a><span class="co">#           ) |&gt; </span></span>
<span id="cb46-114"><a href="#cb46-114" aria-hidden="true" tabindex="-1"></a><span class="co">#     kable_classic(full_width=F)</span></span>
<span id="cb46-115"><a href="#cb46-115" aria-hidden="true" tabindex="-1"></a><span class="co">#     </span></span>
<span id="cb46-116"><a href="#cb46-116" aria-hidden="true" tabindex="-1"></a><span class="co"># } else {</span></span>
<span id="cb46-117"><a href="#cb46-117" aria-hidden="true" tabindex="-1"></a><span class="co">#   </span></span>
<span id="cb46-118"><a href="#cb46-118" aria-hidden="true" tabindex="-1"></a><span class="co">#     car::vif(full.reg) |&gt; </span></span>
<span id="cb46-119"><a href="#cb46-119" aria-hidden="true" tabindex="-1"></a><span class="co">#     kable(digits = 2) |&gt; </span></span>
<span id="cb46-120"><a href="#cb46-120" aria-hidden="true" tabindex="-1"></a><span class="co">#     kable_classic(full_width=F)</span></span>
<span id="cb46-121"><a href="#cb46-121" aria-hidden="true" tabindex="-1"></a><span class="co">#   </span></span>
<span id="cb46-122"><a href="#cb46-122" aria-hidden="true" tabindex="-1"></a><span class="co"># }</span></span>
<span id="cb46-123"><a href="#cb46-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-124"><a href="#cb46-124" aria-hidden="true" tabindex="-1"></a>car<span class="sc">::</span><span class="fu">vif</span>(full.reg) <span class="sc">|&gt;</span> </span>
<span id="cb46-125"><a href="#cb46-125" aria-hidden="true" tabindex="-1"></a>    <span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">2</span>,</span>
<span id="cb46-126"><a href="#cb46-126" aria-hidden="true" tabindex="-1"></a>          <span class="at">table.attr =</span> <span class="st">'data-quarto-disable-processing="true"'</span></span>
<span id="cb46-127"><a href="#cb46-127" aria-hidden="true" tabindex="-1"></a>          )</span>
<span id="cb46-128"><a href="#cb46-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-129"><a href="#cb46-129" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-130"><a href="#cb46-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-131"><a href="#cb46-131" aria-hidden="true" tabindex="-1"></a>All the VIF values are over 5, and hence the full regression model must be simplified dropping one or more predictors.</span>
<span id="cb46-132"><a href="#cb46-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-133"><a href="#cb46-133" aria-hidden="true" tabindex="-1"></a>Let us now compare the fit and summary measures of the simple regression <span class="in">`lm(WEIGHT ~ INNERDIA, data=horsehearts)`</span> with the full regression <span class="in">`lm(WEIGHT ~ ., data=horsehearts)`</span>. @fig-modcomp compares the actual and fitted $Y$ values for these two models.</span>
<span id="cb46-134"><a href="#cb46-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-137"><a href="#cb46-137" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-138"><a href="#cb46-138" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb46-139"><a href="#cb46-139" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb46-140"><a href="#cb46-140" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-modcomp</span></span>
<span id="cb46-141"><a href="#cb46-141" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: 'Comparison of Multiple Regression and Simple Regression'</span></span>
<span id="cb46-142"><a href="#cb46-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-143"><a href="#cb46-143" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(modelr)</span>
<span id="cb46-144"><a href="#cb46-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-145"><a href="#cb46-145" aria-hidden="true" tabindex="-1"></a>full.reg <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT <span class="sc">~</span> ., <span class="at">data=</span>horsehearts)</span>
<span id="cb46-146"><a href="#cb46-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-147"><a href="#cb46-147" aria-hidden="true" tabindex="-1"></a>simple.reg <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT <span class="sc">~</span> INNERDIA, <span class="at">data=</span>horsehearts)</span>
<span id="cb46-148"><a href="#cb46-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-149"><a href="#cb46-149" aria-hidden="true" tabindex="-1"></a>hhpred <span class="ot">&lt;-</span> horsehearts <span class="sc">|&gt;</span> </span>
<span id="cb46-150"><a href="#cb46-150" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gather_predictions</span>(full.reg, simple.reg) <span class="sc">|&gt;</span> </span>
<span id="cb46-151"><a href="#cb46-151" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">residuals=</span>WEIGHT<span class="sc">-</span>pred)</span>
<span id="cb46-152"><a href="#cb46-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-153"><a href="#cb46-153" aria-hidden="true" tabindex="-1"></a>hhpred <span class="sc">|&gt;</span> </span>
<span id="cb46-154"><a href="#cb46-154" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb46-155"><a href="#cb46-155" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aes</span>(<span class="at">x=</span>WEIGHT, <span class="at">y=</span>pred, <span class="at">colour=</span>model) <span class="sc">+</span> </span>
<span id="cb46-156"><a href="#cb46-156" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb46-157"><a href="#cb46-157" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">slope=</span><span class="dv">1</span>, <span class="at">intercept =</span> <span class="dv">0</span>, <span class="at">alpha=</span>.<span class="dv">5</span>) <span class="sc">+</span> </span>
<span id="cb46-158"><a href="#cb46-158" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">aspect.ratio =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb46-159"><a href="#cb46-159" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Predicted WEIGHT"</span>) <span class="sc">+</span> </span>
<span id="cb46-160"><a href="#cb46-160" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Comparison of model predictions"</span>) </span>
<span id="cb46-161"><a href="#cb46-161" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-162"><a href="#cb46-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-163"><a href="#cb46-163" aria-hidden="true" tabindex="-1"></a>Both the simple and full regression models give similar predictions when the horses heart weight is below 2.5 kg, but the simple regression residuals are bit bigger for larger hearts.</span>
<span id="cb46-164"><a href="#cb46-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-165"><a href="#cb46-165" aria-hidden="true" tabindex="-1"></a>We are rather hesitant to make unique claims about any particular subset of predictors based on the correlation matrix or based on the significance of the coefficients from the multiple regression output. In forthcoming sections, methods to decide on a subset of these variables will be explained, but first we look at the issues involved when predictor variables are correlated to each other.</span>
<span id="cb46-166"><a href="#cb46-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-167"><a href="#cb46-167" aria-hidden="true" tabindex="-1"></a><span class="fu"># Measuring Variation Explained by Predictors</span></span>
<span id="cb46-168"><a href="#cb46-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-169"><a href="#cb46-169" aria-hidden="true" tabindex="-1"></a>The variation in a variable can be measured by its sum of squares. In this section, we illustrate this variation by the area of a circle. For brevity, we denote the **T**otal **S**um of **S**quares, the **R**egression **S**um of **S**quares and the **E**rror or residual **S**um of **S**quares by **SST**, **SSR** and **SSE** respectively. In @fig-f5-3, the circle is labelled $y$ and represents the Sum of Squares for all the $y$ observations, that is, SST.</span>
<span id="cb46-170"><a href="#cb46-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-171"><a href="#cb46-171" aria-hidden="true" tabindex="-1"></a><span class="al">![Effect of predictor correlation with the response](images/5-3.png)</span>{#fig-f5-3}</span>
<span id="cb46-172"><a href="#cb46-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-173"><a href="#cb46-173" aria-hidden="true" tabindex="-1"></a>For the full regression of horse heart weight, we obtain the ANOVA output using the command</span>
<span id="cb46-174"><a href="#cb46-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-175"><a href="#cb46-175" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, echo=T, results=FALSE}</span></span>
<span id="cb46-176"><a href="#cb46-176" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(full.reg)</span>
<span id="cb46-177"><a href="#cb46-177" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-178"><a href="#cb46-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-179"><a href="#cb46-179" aria-hidden="true" tabindex="-1"></a>Let's take a look at the sums of squares table.</span>
<span id="cb46-180"><a href="#cb46-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-181"><a href="#cb46-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-184"><a href="#cb46-184" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-185"><a href="#cb46-185" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb46-186"><a href="#cb46-186" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb46-187"><a href="#cb46-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-188"><a href="#cb46-188" aria-hidden="true" tabindex="-1"></a>SS <span class="ot">&lt;-</span> <span class="fu">anova</span>(full.reg) <span class="sc">|&gt;</span> </span>
<span id="cb46-189"><a href="#cb46-189" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>() <span class="sc">|&gt;</span> </span>
<span id="cb46-190"><a href="#cb46-190" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(term<span class="sc">:</span>sumsq) <span class="sc">|&gt;</span> </span>
<span id="cb46-191"><a href="#cb46-191" aria-hidden="true" tabindex="-1"></a>  janitor<span class="sc">::</span><span class="fu">adorn_totals</span>()</span>
<span id="cb46-192"><a href="#cb46-192" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-193"><a href="#cb46-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-196"><a href="#cb46-196" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-197"><a href="#cb46-197" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb46-198"><a href="#cb46-198" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tbl-SS</span></span>
<span id="cb46-199"><a href="#cb46-199" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: "Sums of squares for the full regression of horsehearts data"</span></span>
<span id="cb46-200"><a href="#cb46-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-201"><a href="#cb46-201" aria-hidden="true" tabindex="-1"></a>SS <span class="ot">&lt;-</span> <span class="fu">anova</span>(full.reg) <span class="sc">|&gt;</span> </span>
<span id="cb46-202"><a href="#cb46-202" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>() <span class="sc">|&gt;</span> </span>
<span id="cb46-203"><a href="#cb46-203" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(term<span class="sc">:</span>sumsq) <span class="sc">|&gt;</span> </span>
<span id="cb46-204"><a href="#cb46-204" aria-hidden="true" tabindex="-1"></a>  janitor<span class="sc">::</span><span class="fu">adorn_totals</span>()</span>
<span id="cb46-205"><a href="#cb46-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-206"><a href="#cb46-206" aria-hidden="true" tabindex="-1"></a>SS <span class="sc">|&gt;</span> <span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">2</span> ) </span>
<span id="cb46-207"><a href="#cb46-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-208"><a href="#cb46-208" aria-hidden="true" tabindex="-1"></a><span class="co"># if(knitr::is_html_output()) {</span></span>
<span id="cb46-209"><a href="#cb46-209" aria-hidden="true" tabindex="-1"></a><span class="co"># </span></span>
<span id="cb46-210"><a href="#cb46-210" aria-hidden="true" tabindex="-1"></a><span class="co">#   SS |&gt; kable(digits = 2,</span></span>
<span id="cb46-211"><a href="#cb46-211" aria-hidden="true" tabindex="-1"></a><span class="co">#         table.attr = 'data-quarto-disable-processing="true"'</span></span>
<span id="cb46-212"><a href="#cb46-212" aria-hidden="true" tabindex="-1"></a><span class="co">#         ) |&gt;  </span></span>
<span id="cb46-213"><a href="#cb46-213" aria-hidden="true" tabindex="-1"></a><span class="co">#   kable_classic(full_width = F) </span></span>
<span id="cb46-214"><a href="#cb46-214" aria-hidden="true" tabindex="-1"></a><span class="co">#     </span></span>
<span id="cb46-215"><a href="#cb46-215" aria-hidden="true" tabindex="-1"></a><span class="co"># } else {</span></span>
<span id="cb46-216"><a href="#cb46-216" aria-hidden="true" tabindex="-1"></a><span class="co">#   </span></span>
<span id="cb46-217"><a href="#cb46-217" aria-hidden="true" tabindex="-1"></a><span class="co">#   SS |&gt; kable(digits = 2 ) |&gt;  </span></span>
<span id="cb46-218"><a href="#cb46-218" aria-hidden="true" tabindex="-1"></a><span class="co">#   kable_classic(full_width = F) </span></span>
<span id="cb46-219"><a href="#cb46-219" aria-hidden="true" tabindex="-1"></a><span class="co">#   </span></span>
<span id="cb46-220"><a href="#cb46-220" aria-hidden="true" tabindex="-1"></a><span class="co"># }</span></span>
<span id="cb46-221"><a href="#cb46-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-222"><a href="#cb46-222" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-223"><a href="#cb46-223" aria-hidden="true" tabindex="-1"></a>Now let's calculate the Sums of Squares Total (SST), Error (SSE), and Regression (SSR). </span>
<span id="cb46-224"><a href="#cb46-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-225"><a href="#cb46-225" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, echo=TRUE}</span></span>
<span id="cb46-226"><a href="#cb46-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-227"><a href="#cb46-227" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(</span>
<span id="cb46-228"><a href="#cb46-228" aria-hidden="true" tabindex="-1"></a>  <span class="at">SST =</span> SS <span class="sc">|&gt;</span> <span class="fu">filter</span>(term<span class="sc">==</span><span class="st">"Total"</span>) <span class="sc">|&gt;</span> <span class="fu">pull</span>(sumsq),</span>
<span id="cb46-229"><a href="#cb46-229" aria-hidden="true" tabindex="-1"></a>  <span class="at">SSE =</span> SS <span class="sc">|&gt;</span> <span class="fu">filter</span>(term<span class="sc">==</span><span class="st">"Residuals"</span>) <span class="sc">|&gt;</span> <span class="fu">pull</span>(sumsq),</span>
<span id="cb46-230"><a href="#cb46-230" aria-hidden="true" tabindex="-1"></a>  <span class="at">SSR =</span> SST <span class="sc">-</span> SSE</span>
<span id="cb46-231"><a href="#cb46-231" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb46-232"><a href="#cb46-232" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-233"><a href="#cb46-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-234"><a href="#cb46-234" aria-hidden="true" tabindex="-1"></a>In @fig-f5-3(a), SST = SSR + SSE = 32.731 + 24.115 = 56.845. Consider now the straight line relationship between $y$ and one response variable $x$. This situation is illustrated in @fig-f5-3(b). The shaded overlap of the two circles illustrates the variation in $y$ about the mean explained by the variable $x$, and this shaded area represents the regression sum of squares SSR. The remaining area of the circle for $y$ represents the unexplained variation in $y$ or the residual sum of squares SSE. Note that the circle or Venn diagrams represent SS only qualitatively (not to scale). The variation in $y$ is thus separated into two parts, namely **SST = SSR + SSE**.</span>
<span id="cb46-235"><a href="#cb46-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-236"><a href="#cb46-236" aria-hidden="true" tabindex="-1"></a>Notice that we are not very interested in the unshaded area of the circle representing the explanatory variable, $x$; *it is the variation in the response variable,* $y$, which is important. Also notice that the overlapping circles indicate that the two variables are correlated, that is the correlation coefficient, $r_{xy}$, is not zero. The shaded area is related to</span>
<span id="cb46-237"><a href="#cb46-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-238"><a href="#cb46-238" aria-hidden="true" tabindex="-1"></a>$R^2$ = proportion of the variation of $y$ explained by $x$ = SSR/SST = 32.731/56.845 = 0.576 = $r_{xy}^2$.</span>
<span id="cb46-239"><a href="#cb46-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-240"><a href="#cb46-240" aria-hidden="true" tabindex="-1"></a>Note from @fig-multggally that the correlation between <span class="in">`WEIGHT`</span> and <span class="in">`EXTDIA`</span> is 0.759 and 0.759 squared equals 0.576.</span>
<span id="cb46-241"><a href="#cb46-241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-242"><a href="#cb46-242" aria-hidden="true" tabindex="-1"></a>The situation becomes more interesting when a second explanatory variable is added to the model as illustrated by @fig-f5-4.</span>
<span id="cb46-243"><a href="#cb46-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-244"><a href="#cb46-244" aria-hidden="true" tabindex="-1"></a><span class="al">![Effect of adding two predictors](images/5-4.png)</span>{#fig-f5-4}</span>
<span id="cb46-245"><a href="#cb46-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-246"><a href="#cb46-246" aria-hidden="true" tabindex="-1"></a>In the following discussion, the variable <span class="in">`EXTDIA`</span> is denoted by $x_1$ and <span class="in">`OUTERDIA`</span> as $x_2$. The total overlap of ($x_1$ and $x_2$) and $y$ will depend on the relationship of $y$ with $x_1$, $y$ with $x_2$, and the correlation of $x_1$ and $x_2.$</span>
<span id="cb46-247"><a href="#cb46-247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-248"><a href="#cb46-248" aria-hidden="true" tabindex="-1"></a>In @fig-f5-4(a), as the circles for $x_1$ and $x_2$ do not overlap, this represents a correlation coefficient between these two variables of zero. In this special case, $$R^{2} =\frac{\text {SSR}(x_1)+\text {SSR} (x_2)}{\text {SST}} =r_{x_{1} y}^{2} +r_{x_{2} y}^{2}.$$</span>
<span id="cb46-249"><a href="#cb46-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-250"><a href="#cb46-250" aria-hidden="true" tabindex="-1"></a>Here, SSR($x_1$) represents the Regression SS when $y$ is regressed on $x_1$ only. SSR($x_2$) represents the Regression SS when $y$ is regressed on $x_2$ only. The unshaded area of $y$ represents SSE, the residual sum of squares, which is the sum of squares of $y$ **unexplained** by $x_1$ or $x_2$. The **special case** of **uncorrelated** explanatory variables is in many ways ideal but it usually only occurs when $x_1$ and $x_2$ are constructed to have zero correlation (which means that the situation, known as orthogonality, is usually confined to experimental designs). There is an added bonus when $x_1$ and $x_2$ have zero correlation. In this situation the fitted model is</span>
<span id="cb46-251"><a href="#cb46-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-252"><a href="#cb46-252" aria-hidden="true" tabindex="-1"></a>$$\hat{y} = a + b_1 x_1 + b_2x_2$$</span>
<span id="cb46-253"><a href="#cb46-253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-254"><a href="#cb46-254" aria-hidden="true" tabindex="-1"></a>where $b_1$ and $b_2$ take the same values as in the separate straight line models $\hat{y} = a + b_1x_1$ and $\hat{y} =a + b_2x_2.$</span>
<span id="cb46-255"><a href="#cb46-255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-256"><a href="#cb46-256" aria-hidden="true" tabindex="-1"></a>However in observational studies the correlations between predictor variables will usually be nonzero. The circle diagram shown in @fig-f5-4(b) illustrates the case when $x_1$ and $x_2$ are correlated. In this case $$R^{2} &lt;\frac{\text {SSR}(x_1) + \text {SSR}(x_2) } {\text {SST}}$$ and the slope coefficients for both $x_1$ and $x_2$ change when both these variables are included in the regression model.</span>
<span id="cb46-257"><a href="#cb46-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-258"><a href="#cb46-258" aria-hidden="true" tabindex="-1"></a>@fig-f5-4(c) gives the extreme case when $x_1$ and $x_2$ have nearly perfect correlation. If the correlation between $x_1$ and $x_2$ is perfect, then the two variables will be said to be collinear. If two or more explanatory variables are very highly correlated (i.e. almost collinear), then we deal with **multicollinearity**.</span>
<span id="cb46-259"><a href="#cb46-259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-260"><a href="#cb46-260" aria-hidden="true" tabindex="-1"></a>From @fig-f5-3 and @fig-f5-4, it is clear that for correlated variables, the variation (SS) explained by a particular predictor cannot be independently extracted (due to the commonly shared variation). Hence, we consider how much a predictor explains **additionally** given that there are already certain predictors are in the model. The additional overlap due to $x_{2}$ with $y$ **after** $x_{1}$, known as the **additional SSR** or **Sequential SS** is an important idea in model building. The additional SSR is known as **Type I sums of squares** in the statistical literature.</span>
<span id="cb46-261"><a href="#cb46-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-262"><a href="#cb46-262" aria-hidden="true" tabindex="-1"></a>Note that we can also define the additional variation in $y$ explained by $x_{1}$ after $x_{2}$. It is important to note that in general the additional SSR depends on the **order** of placing the predictors. **This order does not have any effect on the coefficient estimation, standard errors etc.**</span>
<span id="cb46-263"><a href="#cb46-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-264"><a href="#cb46-264" aria-hidden="true" tabindex="-1"></a><span class="fu">## Significance testing of Type I SS</span></span>
<span id="cb46-265"><a href="#cb46-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-266"><a href="#cb46-266" aria-hidden="true" tabindex="-1"></a>The significance of the additional variation explained by a predictor can be tested using a $t$ or $F$ statistic. Consider the simple regression model of <span class="in">`WEIGHT`</span> on <span class="in">`EXTDIA`</span>. Suppose we decided to add the explanatory variable <span class="in">`OUTERDIA`</span> to the model, i.e. regress <span class="in">`WEIGHT`</span> on two explanatory variables <span class="in">`EXTDIA`</span> and <span class="in">`OUTERDIA`</span>. Is this new model a significant improvement on the existing one? For testing the null hypothesis that the true slope coefficient of <span class="in">`OUTERDIA`</span> in this model is zero, the $t$-statistic is 1.531 (see output below).</span>
<span id="cb46-267"><a href="#cb46-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-270"><a href="#cb46-270" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-271"><a href="#cb46-271" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb46-272"><a href="#cb46-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-273"><a href="#cb46-273" aria-hidden="true" tabindex="-1"></a>twovar.model <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT<span class="sc">~</span> EXTDIA<span class="sc">+</span>OUTERDIA, <span class="at">data=</span>horsehearts)</span>
<span id="cb46-274"><a href="#cb46-274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-275"><a href="#cb46-275" aria-hidden="true" tabindex="-1"></a>twovar.model <span class="sc">|&gt;</span> <span class="fu">tidy</span>()</span>
<span id="cb46-276"><a href="#cb46-276" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-277"><a href="#cb46-277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-278"><a href="#cb46-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-279"><a href="#cb46-279" aria-hidden="true" tabindex="-1"></a>The $t$ and $F$ distributions are related by the equation $t^{2} =F$ when the numerator df is just one for the $F$ statistic. Hence 1.532 = 2.34 is the $F$ value for testing the significance of the additional SSR due to <span class="in">`OUTERDIA`</span>. In other words, the addition of <span class="in">`OUTERDIA`</span> to the simple regression model does not result in a significant improvement in the sense that the reduction in residual SS (= 1.247) as measured by the $F$ value of 2.34 is not significant ($p$-value being 0.133).</span>
<span id="cb46-280"><a href="#cb46-280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-281"><a href="#cb46-281" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, echo=TRUE}</span></span>
<span id="cb46-282"><a href="#cb46-282" aria-hidden="true" tabindex="-1"></a>onevar.model <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT<span class="sc">~</span> EXTDIA, <span class="at">data=</span>horsehearts)</span>
<span id="cb46-283"><a href="#cb46-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-284"><a href="#cb46-284" aria-hidden="true" tabindex="-1"></a>twovar.model <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT<span class="sc">~</span> EXTDIA<span class="sc">+</span>OUTERDIA, <span class="at">data=</span>horsehearts)</span>
<span id="cb46-285"><a href="#cb46-285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-286"><a href="#cb46-286" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(onevar.model, twovar.model)</span>
<span id="cb46-287"><a href="#cb46-287" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-288"><a href="#cb46-288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-289"><a href="#cb46-289" aria-hidden="true" tabindex="-1"></a>Although <span class="in">`OUTERDIA`</span> is correlated with <span class="in">`WEIGHT`</span>, it also has high correlation with <span class="in">`EXTDIA`</span>. In other words, the correlation matrix gives us some indication of how many variables might be needed in a multiple regression model, although by itself it cannot tell us what combination of predictor variables is good or best.</span>
<span id="cb46-290"><a href="#cb46-290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-291"><a href="#cb46-291" aria-hidden="true" tabindex="-1"></a><span class="al">![Issues with multiple predictors](images/5-5.png)</span>{#fig-f5-5}</span>
<span id="cb46-292"><a href="#cb46-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-293"><a href="#cb46-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-294"><a href="#cb46-294" aria-hidden="true" tabindex="-1"></a><span class="al">![Effect of multiple predictors on model summaries](images/5-7.png)</span>{#fig-f5-7}</span>
<span id="cb46-295"><a href="#cb46-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-296"><a href="#cb46-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-297"><a href="#cb46-297" aria-hidden="true" tabindex="-1"></a>@fig-f5-5 and @fig-f5-7 summarise the following facts:</span>
<span id="cb46-298"><a href="#cb46-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-299"><a href="#cb46-299" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>When there is only **one** explanatory variable, $R^2$ = SSR/SST equals the square of the correlation coefficient between that variable and the dependent variable. Therefore if only one variable is to be chosen, it should have the highest correlation with the response variable, $Y$.</span>
<span id="cb46-300"><a href="#cb46-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-301"><a href="#cb46-301" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>When variables are added to a model, the regression sum of squares SSR will increase and the residual or error sum of squares SSE will reduce. The opposite is true if variables are dropped from the model. This fact follows from @fig-f5-7.</span>
<span id="cb46-302"><a href="#cb46-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-303"><a href="#cb46-303" aria-hidden="true" tabindex="-1"></a><span class="ss">3.  </span>The other side of the coin to the above remark is that as additional variables are added, the Sums of Squares for residuals, SSE, will decrease towards zero as also shown in @fig-f5-7(c).</span>
<span id="cb46-304"><a href="#cb46-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-305"><a href="#cb46-305" aria-hidden="true" tabindex="-1"></a><span class="ss">4.  </span>The overlap of circles in suggests that these changes in both SSR and SST will lessen as more variables are added, see @fig-f5-5(b).</span>
<span id="cb46-306"><a href="#cb46-306" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-307"><a href="#cb46-307" aria-hidden="true" tabindex="-1"></a><span class="ss">5.  </span>Following on from the last two notes, as $R^2$ = SSR/SST, $R^2$ will increase monotonically towards 1 as additional variables are added to the model. (monotonically increasing means that it never decreases although it could remain the same). This is indicated by @fig-f5-7(a). If variables are dropped, then $R^2$ will monotonically decrease.</span>
<span id="cb46-308"><a href="#cb46-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-309"><a href="#cb46-309" aria-hidden="true" tabindex="-1"></a><span class="ss">6.  </span>Against the above trends, the graph of residual mean square in @fig-f5-7(b) reduces to a *minimum* but may eventually start to increase if enough variables are added. The residual sum of squares SSE decreases as variables are added to the model (see @fig-f5-5(b)). However, the associated df values also decrease so that the residual standard deviation decreases at first and then starts to increase as shown in @fig-f5-7(b). (Note that the residual standard error $s_{e}$ is the square root of the residual mean square</span>
<span id="cb46-310"><a href="#cb46-310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-311"><a href="#cb46-311" aria-hidden="true" tabindex="-1"></a>    $$s_{e}^{2} =\frac{{\text {SSE}}}{{\text {error degrees of freedom}}},$$</span>
<span id="cb46-312"><a href="#cb46-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-313"><a href="#cb46-313" aria-hidden="true" tabindex="-1"></a>    denoted as MSE in @fig-f5-5(b)). After a number of variables have been entered, the additional amount of variation explained by them slows down but the degrees of freedom continues to change by 1 for every variable added, resulting in the eventual increase in residual mean square. Note that the graphs in @fig-f5-5 are idealised ones. For some data sets, the behaviour of residual mean square may not be monotone.</span>
<span id="cb46-314"><a href="#cb46-314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-315"><a href="#cb46-315" aria-hidden="true" tabindex="-1"></a><span class="ss">7.  </span>Notice that the above trends will occur even if the variables added are **garbage**. For example, you could generate a column of random data or a column of birthdays of your friends, and this would improve the $R^2$ **but not the adjusted** $R^2$. The adjusted $R^2$ makes adjustment for the degrees of freedom for the SSR and SSE, and hence reliable when compared to the unadjusted or multiple $R^2$. The residual mean square error also partly adjusts for the drop in the degrees of freedom for the SSE and hence becomes an important measure. The addition of unimportant variables will not improve the adjusted $R^2$ and the mean square error $s_{e}^{2}$.</span>
<span id="cb46-316"><a href="#cb46-316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-317"><a href="#cb46-317" aria-hidden="true" tabindex="-1"></a><span class="fu">## Other SS types</span></span>
<span id="cb46-318"><a href="#cb46-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-319"><a href="#cb46-319" aria-hidden="true" tabindex="-1"></a>The <span class="in">`R`</span> anova function anova() calculates sequential or Type-I SS values.</span>
<span id="cb46-320"><a href="#cb46-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-321"><a href="#cb46-321" aria-hidden="true" tabindex="-1"></a>Type-II sums of squares is based on the principle of marginality. Type II SS correspond to the <span class="in">`R`</span> convention in which each variable effect is adjusted for all other *appropriate* effects.</span>
<span id="cb46-322"><a href="#cb46-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-323"><a href="#cb46-323" aria-hidden="true" tabindex="-1"></a>Type-III sums of squares is the SS added to the regression SS after ALL other predictors including an intercept term. This SS however creates theoretical issues such as violation of marginality principle and we should avoid using this SS type for hypothesis tests.</span>
<span id="cb46-324"><a href="#cb46-324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-325"><a href="#cb46-325" aria-hidden="true" tabindex="-1"></a>The <span class="in">`R`</span> package <span class="in">`car`</span> has the function <span class="in">`Anova()`</span> to compute the Type II and III sums of squares. Try-</span>
<span id="cb46-326"><a href="#cb46-326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-327"><a href="#cb46-327" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, echo=TRUE, results=FALSE}</span></span>
<span id="cb46-328"><a href="#cb46-328" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb46-329"><a href="#cb46-329" aria-hidden="true" tabindex="-1"></a>full.model <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT<span class="sc">~</span> ., <span class="at">data=</span>horsehearts)</span>
<span id="cb46-330"><a href="#cb46-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-331"><a href="#cb46-331" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(full.model)</span>
<span id="cb46-332"><a href="#cb46-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-333"><a href="#cb46-333" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(car)</span>
<span id="cb46-334"><a href="#cb46-334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-335"><a href="#cb46-335" aria-hidden="true" tabindex="-1"></a><span class="fu">Anova</span>(full.model, <span class="at">type=</span><span class="dv">2</span>)</span>
<span id="cb46-336"><a href="#cb46-336" aria-hidden="true" tabindex="-1"></a><span class="fu">Anova</span>(full.model, <span class="at">type=</span><span class="dv">3</span>)</span>
<span id="cb46-337"><a href="#cb46-337" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-338"><a href="#cb46-338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-339"><a href="#cb46-339" aria-hidden="true" tabindex="-1"></a>For the **horsehearts** data, a comparison of the Type I and II sums squares is given below:</span>
<span id="cb46-340"><a href="#cb46-340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-343"><a href="#cb46-343" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-344"><a href="#cb46-344" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb46-345"><a href="#cb46-345" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb46-346"><a href="#cb46-346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-347"><a href="#cb46-347" aria-hidden="true" tabindex="-1"></a>full.model <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT<span class="sc">~</span> ., <span class="at">data=</span>horsehearts)</span>
<span id="cb46-348"><a href="#cb46-348" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-349"><a href="#cb46-349" aria-hidden="true" tabindex="-1"></a>anova1 <span class="ot">&lt;-</span> full.model <span class="sc">|&gt;</span> </span>
<span id="cb46-350"><a href="#cb46-350" aria-hidden="true" tabindex="-1"></a>  <span class="fu">anova</span>() <span class="sc">|&gt;</span> </span>
<span id="cb46-351"><a href="#cb46-351" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>() <span class="sc">|&gt;</span> </span>
<span id="cb46-352"><a href="#cb46-352" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(term, <span class="st">"Type I SS"</span> <span class="ot">=</span> sumsq)  </span>
<span id="cb46-353"><a href="#cb46-353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-354"><a href="#cb46-354" aria-hidden="true" tabindex="-1"></a>anova2 <span class="ot">&lt;-</span> full.model <span class="sc">|&gt;</span> </span>
<span id="cb46-355"><a href="#cb46-355" aria-hidden="true" tabindex="-1"></a>  <span class="fu">Anova</span>(<span class="at">type=</span><span class="dv">2</span>) <span class="sc">|&gt;</span> </span>
<span id="cb46-356"><a href="#cb46-356" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>() <span class="sc">|&gt;</span> </span>
<span id="cb46-357"><a href="#cb46-357" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(term, <span class="st">"Type II SS"</span> <span class="ot">=</span> sumsq) </span>
<span id="cb46-358"><a href="#cb46-358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-359"><a href="#cb46-359" aria-hidden="true" tabindex="-1"></a>type1and2 <span class="ot">&lt;-</span> <span class="fu">full_join</span>(anova1, anova2, <span class="at">by=</span><span class="st">"term"</span>)</span>
<span id="cb46-360"><a href="#cb46-360" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-361"><a href="#cb46-361" aria-hidden="true" tabindex="-1"></a>type1and2</span>
<span id="cb46-362"><a href="#cb46-362" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-363"><a href="#cb46-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-364"><a href="#cb46-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-367"><a href="#cb46-367" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-368"><a href="#cb46-368" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb46-369"><a href="#cb46-369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-370"><a href="#cb46-370" aria-hidden="true" tabindex="-1"></a><span class="co"># if(knitr::is_html_output()) {</span></span>
<span id="cb46-371"><a href="#cb46-371" aria-hidden="true" tabindex="-1"></a><span class="co"># </span></span>
<span id="cb46-372"><a href="#cb46-372" aria-hidden="true" tabindex="-1"></a><span class="co">#   type1and2 |&gt; </span></span>
<span id="cb46-373"><a href="#cb46-373" aria-hidden="true" tabindex="-1"></a><span class="co">#   kable(digits = 2,</span></span>
<span id="cb46-374"><a href="#cb46-374" aria-hidden="true" tabindex="-1"></a><span class="co">#         table.attr = 'data-quarto-disable-processing="true"'</span></span>
<span id="cb46-375"><a href="#cb46-375" aria-hidden="true" tabindex="-1"></a><span class="co">#         ) |&gt; </span></span>
<span id="cb46-376"><a href="#cb46-376" aria-hidden="true" tabindex="-1"></a><span class="co">#   kable_classic(full_width=F)</span></span>
<span id="cb46-377"><a href="#cb46-377" aria-hidden="true" tabindex="-1"></a><span class="co">#     </span></span>
<span id="cb46-378"><a href="#cb46-378" aria-hidden="true" tabindex="-1"></a><span class="co"># } else {</span></span>
<span id="cb46-379"><a href="#cb46-379" aria-hidden="true" tabindex="-1"></a><span class="co">#   </span></span>
<span id="cb46-380"><a href="#cb46-380" aria-hidden="true" tabindex="-1"></a><span class="co">#   type1and2 |&gt; </span></span>
<span id="cb46-381"><a href="#cb46-381" aria-hidden="true" tabindex="-1"></a><span class="co">#   kable(digits = 2) |&gt; </span></span>
<span id="cb46-382"><a href="#cb46-382" aria-hidden="true" tabindex="-1"></a><span class="co">#   kable_classic(full_width=F)</span></span>
<span id="cb46-383"><a href="#cb46-383" aria-hidden="true" tabindex="-1"></a><span class="co">#   </span></span>
<span id="cb46-384"><a href="#cb46-384" aria-hidden="true" tabindex="-1"></a><span class="co"># }</span></span>
<span id="cb46-385"><a href="#cb46-385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-386"><a href="#cb46-386" aria-hidden="true" tabindex="-1"></a>type1and2 <span class="sc">|&gt;</span> </span>
<span id="cb46-387"><a href="#cb46-387" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">2</span>)</span>
<span id="cb46-388"><a href="#cb46-388" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-389"><a href="#cb46-389" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-390"><a href="#cb46-390" aria-hidden="true" tabindex="-1"></a>When predictor variables are correlated, it is difficult to assess their absolute importance and the importance of a variable can be assessed only relatively. This is not an issue with the most highly correlated predictor in general.</span>
<span id="cb46-391"><a href="#cb46-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-392"><a href="#cb46-392" aria-hidden="true" tabindex="-1"></a><span class="fu"># Regression Fitting with Fewer Predictors</span></span>
<span id="cb46-393"><a href="#cb46-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-394"><a href="#cb46-394" aria-hidden="true" tabindex="-1"></a>The first step before selection of the best subset of predictors is to study the correlation matrix. For horses' heart data, the explanatory variable which is most highly correlated with $y$ (<span class="in">`WEIGHT`</span>) is $x_2$ (<span class="in">`INNERDIA`</span>) having a correlation coefficient of 0.811 (see @fig-multggally). This means that <span class="in">`INNERDIA`</span> should be the single best predictor. We may guess that the next best variable to join <span class="in">`INNERDIA`</span>. This would be $x_3$ (<span class="in">`OUTERSYS`</span>) but the correlations between $x_3$ and the other explanatory variables clouds the issue. In other words, the significance or otherwise of a variable in a multiple regression model depends on the other variables in the model.</span>
<span id="cb46-395"><a href="#cb46-395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-396"><a href="#cb46-396" aria-hidden="true" tabindex="-1"></a>Consider the regression of horses' heart <span class="in">`WEIGHT`</span> on <span class="in">`INNERDIA`</span>, <span class="in">`OUTERSYS`</span>, and <span class="in">`EXTSYS`</span>.</span>
<span id="cb46-397"><a href="#cb46-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-400"><a href="#cb46-400" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-401"><a href="#cb46-401" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb46-402"><a href="#cb46-402" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb46-403"><a href="#cb46-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-404"><a href="#cb46-404" aria-hidden="true" tabindex="-1"></a>threevar.model <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT <span class="sc">~</span> INNERDIA <span class="sc">+</span> OUTERSYS <span class="sc">+</span> EXTSYS,</span>
<span id="cb46-405"><a href="#cb46-405" aria-hidden="true" tabindex="-1"></a>                     <span class="at">data=</span>horsehearts)</span>
<span id="cb46-406"><a href="#cb46-406" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-407"><a href="#cb46-407" aria-hidden="true" tabindex="-1"></a>threevar.model <span class="sc">|&gt;</span> <span class="fu">tidy</span>()</span>
<span id="cb46-408"><a href="#cb46-408" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-409"><a href="#cb46-409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-410"><a href="#cb46-410" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-413"><a href="#cb46-413" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-414"><a href="#cb46-414" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb46-415"><a href="#cb46-415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-416"><a href="#cb46-416" aria-hidden="true" tabindex="-1"></a><span class="co"># if(knitr::is_html_output()) {</span></span>
<span id="cb46-417"><a href="#cb46-417" aria-hidden="true" tabindex="-1"></a><span class="co"># </span></span>
<span id="cb46-418"><a href="#cb46-418" aria-hidden="true" tabindex="-1"></a><span class="co">#   threevar.model |&gt; </span></span>
<span id="cb46-419"><a href="#cb46-419" aria-hidden="true" tabindex="-1"></a><span class="co">#   tidy() |&gt; </span></span>
<span id="cb46-420"><a href="#cb46-420" aria-hidden="true" tabindex="-1"></a><span class="co">#   kable(digits=3,</span></span>
<span id="cb46-421"><a href="#cb46-421" aria-hidden="true" tabindex="-1"></a><span class="co">#         table.attr = 'data-quarto-disable-processing="true"'</span></span>
<span id="cb46-422"><a href="#cb46-422" aria-hidden="true" tabindex="-1"></a><span class="co">#         ) |&gt; </span></span>
<span id="cb46-423"><a href="#cb46-423" aria-hidden="true" tabindex="-1"></a><span class="co">#   kable_classic(full_width=F)</span></span>
<span id="cb46-424"><a href="#cb46-424" aria-hidden="true" tabindex="-1"></a><span class="co">#     </span></span>
<span id="cb46-425"><a href="#cb46-425" aria-hidden="true" tabindex="-1"></a><span class="co"># } else {</span></span>
<span id="cb46-426"><a href="#cb46-426" aria-hidden="true" tabindex="-1"></a><span class="co">#   </span></span>
<span id="cb46-427"><a href="#cb46-427" aria-hidden="true" tabindex="-1"></a><span class="co">#   threevar.model |&gt; </span></span>
<span id="cb46-428"><a href="#cb46-428" aria-hidden="true" tabindex="-1"></a><span class="co">#   tidy() |&gt; </span></span>
<span id="cb46-429"><a href="#cb46-429" aria-hidden="true" tabindex="-1"></a><span class="co">#   kable(digits=3) |&gt; </span></span>
<span id="cb46-430"><a href="#cb46-430" aria-hidden="true" tabindex="-1"></a><span class="co">#   kable_classic(full_width=F)</span></span>
<span id="cb46-431"><a href="#cb46-431" aria-hidden="true" tabindex="-1"></a><span class="co">#   </span></span>
<span id="cb46-432"><a href="#cb46-432" aria-hidden="true" tabindex="-1"></a><span class="co"># }</span></span>
<span id="cb46-433"><a href="#cb46-433" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-434"><a href="#cb46-434" aria-hidden="true" tabindex="-1"></a>threevar.model <span class="sc">|&gt;</span> </span>
<span id="cb46-435"><a href="#cb46-435" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>() <span class="sc">|&gt;</span> </span>
<span id="cb46-436"><a href="#cb46-436" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits=</span><span class="dv">3</span>)</span>
<span id="cb46-437"><a href="#cb46-437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-438"><a href="#cb46-438" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-439"><a href="#cb46-439" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-440"><a href="#cb46-440" aria-hidden="true" tabindex="-1"></a>The coefficient of <span class="in">`EXTSYS`</span> is not significant at 5% level. However coefficient of <span class="in">`EXTSYS`</span> was found to be significant in the full regression. The significance of <span class="in">`INNERDIA`</span> coefficient has also changed. This example shows that *we cannot fully rely on the* $t$-test and discard a variable because its coefficient is insignificant.</span>
<span id="cb46-441"><a href="#cb46-441" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-442"><a href="#cb46-442" aria-hidden="true" tabindex="-1"></a>There are various search methods for finding the best subset of explanatory variables. We will consider **stepwise procedures**, namely algorithms that follow a series of steps to find a good set of predictors. At each step, the current regression model is compared with competing models in which one variable has either been added (*forward selection* procedures) or removed (*backward elimination* procedures). Some measure of goodness is required so that the variable selection procedure can decide whether to switch to one of the competing models or to stop at the current best model. Of the two procedures, backward elimination has two advantages. One is computational: step 2 of the forward selection requires calculation of a large number of competing models whereas step 2 of the backward elimination only requires one. The other is statistical and more subtle. Consider two predictor variables $x_{i}$ and $x_{j}$ and suppose that the forward selection procedure does not add either because their individual importance is low. It may be that their joint influence is important, but the forwards procedure has not been able to detect this. In contrast, the backward elimination procedure starts with all variables included and so is able to delete one and keep the other.</span>
<span id="cb46-443"><a href="#cb46-443" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-444"><a href="#cb46-444" aria-hidden="true" tabindex="-1"></a>A stepwise regression algorithm can also combine *both* the backward elimination and forward selection procedures. The procedure is the same as forward selection, but immediately after each step of the forward selection algorithm, a step of backward elimination is carried out.</span>
<span id="cb46-445"><a href="#cb46-445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-446"><a href="#cb46-446" aria-hidden="true" tabindex="-1"></a>Variable selection solely based $p$ values is preferred only for certain applications such as analysis of factorial type experimental data where response surfaces are fitted. The base <span class="in">`R`</span> does model selection based on $AIC$ which has to be as minimum as possible for a good model. We shall now discuss the concept of $AIC$ and other model selection criteria.</span>
<span id="cb46-447"><a href="#cb46-447" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-448"><a href="#cb46-448" aria-hidden="true" tabindex="-1"></a>One way to balance model fit with model complexity (number of parameters) is to choose the model with the **minimal** value of Akaike Information Criterion (**AIC** for short, derived by Prof. Hirotugu Akaike as the minimum information theoretic criterion):</span>
<span id="cb46-449"><a href="#cb46-449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-450"><a href="#cb46-450" aria-hidden="true" tabindex="-1"></a>$$AIC = n\log \left( \frac{SSE}{n} \right) + 2p$$</span>
<span id="cb46-451"><a href="#cb46-451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-452"><a href="#cb46-452" aria-hidden="true" tabindex="-1"></a>Here $n$ is the size of the data set and $p$ is the number of variables in the model. A model with more variables (larger value of $p$) will produce a smaller residual sum of squares SSE but is penalised by the second term.</span>
<span id="cb46-453"><a href="#cb46-453" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-454"><a href="#cb46-454" aria-hidden="true" tabindex="-1"></a>Bayesian Information Criterion (BIC) (or also called Schwarz's Bayesian criterion, SBC) places a higher penalty that depends on $n$, the number of observations. As a result $BIC$ fares well for selecting a model that explains the relationships well while $AIC$ fares well when selecting a model for prediction purposes.</span>
<span id="cb46-455"><a href="#cb46-455" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-456"><a href="#cb46-456" aria-hidden="true" tabindex="-1"></a>A number of corrections to $AIC$ and $BIC$ have been proposed in the literature depending on the type of model fitted. We will not study them in this course.</span>
<span id="cb46-457"><a href="#cb46-457" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-458"><a href="#cb46-458" aria-hidden="true" tabindex="-1"></a>An alternative measure called Mallow's $C_{p}$ index is also available using which we may judge whether the variables at the current step (smaller model) are excessive or short. If unimportant variables are added to the model, then the variance of the fitted values will increase. Similarly if important variables are added, then the bias of the fitted values will decrease. The $C_{p}$ index, which balances the variance and bias, is given by the formula $$C_{p} = \frac{{\text  {SS Error for Smaller Model}}}{{\text {Mean Square Error for full regression}}} -(n-2p)$$ where $p$ = no. of estimated coefficients (including the intercept) in the smaller model and $n$ = total number of observations. The most desired value for the $C_{p}$ index is the number of parameters (including the $y$-intercept) or just smaller. If $C_p&gt;&gt;p$, the model is biased. On the other hand, if $C_p&lt;&lt;p$, the model associated variability is too large. The trade-off between bias and variance is best when $C_{p}=p$. But the $C_{p}$ index is not useful in judging the adequacy of the full regression model because it requires an assumption on what constitutes the full regression. This is not an issue with the $AIC$ or $BIC$ criterion.</span>
<span id="cb46-459"><a href="#cb46-459" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-460"><a href="#cb46-460" aria-hidden="true" tabindex="-1"></a>For prediction modelling, the following three measures are popular and the <span class="in">`modelr`</span> package will extract these prediction accuracy measures and many more.</span>
<span id="cb46-461"><a href="#cb46-461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-462"><a href="#cb46-462" aria-hidden="true" tabindex="-1"></a>*Mean Squared Deviation* (MSD):</span>
<span id="cb46-463"><a href="#cb46-463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-464"><a href="#cb46-464" aria-hidden="true" tabindex="-1"></a>MSD is the mean of the squared errors (i.e., deviations).</span>
<span id="cb46-465"><a href="#cb46-465" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-466"><a href="#cb46-466" aria-hidden="true" tabindex="-1"></a>$$MSD = \frac{\sum \left({\text {observation-fit}}\right)^2 }{{\text {number of observations}}},$$</span>
<span id="cb46-467"><a href="#cb46-467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-468"><a href="#cb46-468" aria-hidden="true" tabindex="-1"></a>MSD is also sometimes called the Mean Squared Error (MSE). Note that while computing the MSE, the divisor will be the degrees of freedom and not the number of observations. The square-root of MSE is abbreviated as *RMSE*, and commonly employed as a measure of prediction accuracy.</span>
<span id="cb46-469"><a href="#cb46-469" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-470"><a href="#cb46-470" aria-hidden="true" tabindex="-1"></a>*Mean Absolute Percentage Error* (MAPE):</span>
<span id="cb46-471"><a href="#cb46-471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-472"><a href="#cb46-472" aria-hidden="true" tabindex="-1"></a>MAPE is the average percentage relative error per observation. MAPE is defined as</span>
<span id="cb46-473"><a href="#cb46-473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-474"><a href="#cb46-474" aria-hidden="true" tabindex="-1"></a>$$MAPE =\frac{\sum \frac{\left|{\text {observation-fit}}\right|}{{\text {observation}}} }{{\text {number of observations}}} {\times100}.$$</span>
<span id="cb46-475"><a href="#cb46-475" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-476"><a href="#cb46-476" aria-hidden="true" tabindex="-1"></a>Note that MAPE is unitless.</span>
<span id="cb46-477"><a href="#cb46-477" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-478"><a href="#cb46-478" aria-hidden="true" tabindex="-1"></a>*Mean Absolute Deviation* (MAD):</span>
<span id="cb46-479"><a href="#cb46-479" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-480"><a href="#cb46-480" aria-hidden="true" tabindex="-1"></a>MAD is the average absolute error per observation and also known as MAE (mean absolute error). MAD is defined as</span>
<span id="cb46-481"><a href="#cb46-481" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-482"><a href="#cb46-482" aria-hidden="true" tabindex="-1"></a>$$MAD =\frac{\sum \left|{\text {observation-fit}}\right| }{{\text {number of observations}}}.$$</span>
<span id="cb46-483"><a href="#cb46-483" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-484"><a href="#cb46-484" aria-hidden="true" tabindex="-1"></a>For the horsehearts data, stepwise selection can be implemented using many R packages including <span class="in">`MASS`</span>, <span class="in">`car`</span>, <span class="in">`leaps`</span> <span class="in">`HH`</span> <span class="in">`caret`</span>, and <span class="in">`SignifReg`</span>. Examples given below are based on the horses hearts data.</span>
<span id="cb46-485"><a href="#cb46-485" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-486"><a href="#cb46-486" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>The <span class="in">`step()`</span> function performs a combination of both forward and backward regression.  This method favours a model with four variables: <span class="in">`WEIGHT ~ INNERDIA + OUTERSYS + EXTSYS + EXTDIA`</span></span>
<span id="cb46-487"><a href="#cb46-487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-488"><a href="#cb46-488" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, echo=TRUE, results=FALSE}</span></span>
<span id="cb46-489"><a href="#cb46-489" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-490"><a href="#cb46-490" aria-hidden="true" tabindex="-1"></a>full.model <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT <span class="sc">~</span> ., <span class="at">data =</span> horsehearts)</span>
<span id="cb46-491"><a href="#cb46-491" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-492"><a href="#cb46-492" aria-hidden="true" tabindex="-1"></a>stats<span class="sc">::</span><span class="fu">step</span>(full.model) </span>
<span id="cb46-493"><a href="#cb46-493" aria-hidden="true" tabindex="-1"></a><span class="co"># or MASS::stepAIC(full.model)</span></span>
<span id="cb46-494"><a href="#cb46-494" aria-hidden="true" tabindex="-1"></a><span class="co"># or step(full.model, trace = FALSE) </span></span>
<span id="cb46-495"><a href="#cb46-495" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-496"><a href="#cb46-496" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-497"><a href="#cb46-497" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>The <span class="in">`stepAIC()`</span> function from the MASS package can also be used instead of the <span class="in">`step()`</span> function. Try-</span>
<span id="cb46-498"><a href="#cb46-498" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-499"><a href="#cb46-499" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, echo=TRUE, results=FALSE}</span></span>
<span id="cb46-500"><a href="#cb46-500" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS, <span class="at">exclude=</span><span class="st">"select"</span>)</span>
<span id="cb46-501"><a href="#cb46-501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-502"><a href="#cb46-502" aria-hidden="true" tabindex="-1"></a><span class="fu">stepAIC</span>(full.reg, <span class="at">direction=</span><span class="st">"backward"</span>, <span class="at">trace =</span> <span class="cn">FALSE</span>)</span>
<span id="cb46-503"><a href="#cb46-503" aria-hidden="true" tabindex="-1"></a><span class="fu">stepAIC</span>(full.reg, <span class="at">direction=</span><span class="st">"both"</span>, <span class="at">trace =</span> <span class="cn">FALSE</span>)</span>
<span id="cb46-504"><a href="#cb46-504" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-505"><a href="#cb46-505" aria-hidden="true" tabindex="-1"></a>null.model <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT<span class="sc">~</span> <span class="dv">1</span>, <span class="at">data=</span>horsehearts)</span>
<span id="cb46-506"><a href="#cb46-506" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-507"><a href="#cb46-507" aria-hidden="true" tabindex="-1"></a>stats<span class="sc">::</span><span class="fu">step</span>(</span>
<span id="cb46-508"><a href="#cb46-508" aria-hidden="true" tabindex="-1"></a>  full.reg, </span>
<span id="cb46-509"><a href="#cb46-509" aria-hidden="true" tabindex="-1"></a>  <span class="at">scope =</span> <span class="fu">list</span>(</span>
<span id="cb46-510"><a href="#cb46-510" aria-hidden="true" tabindex="-1"></a>    <span class="at">lower =</span> null.model,</span>
<span id="cb46-511"><a href="#cb46-511" aria-hidden="true" tabindex="-1"></a>    <span class="at">upper =</span> <span class="sc">~</span>INNERSYS<span class="sc">+</span>INNERDIA<span class="sc">+</span>OUTERSYS<span class="sc">+</span>OUTERDIA<span class="sc">+</span>EXTSYS<span class="sc">+</span>EXTDIA</span>
<span id="cb46-512"><a href="#cb46-512" aria-hidden="true" tabindex="-1"></a>    ), </span>
<span id="cb46-513"><a href="#cb46-513" aria-hidden="true" tabindex="-1"></a>  <span class="at">direction =</span> <span class="st">"forward"</span>)</span>
<span id="cb46-514"><a href="#cb46-514" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-515"><a href="#cb46-515" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-516"><a href="#cb46-516" aria-hidden="true" tabindex="-1"></a><span class="ss">3.  </span>The <span class="in">`SignifReg`</span> package allows variable selection under various criteria. Try-</span>
<span id="cb46-517"><a href="#cb46-517" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-518"><a href="#cb46-518" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, echo=TRUE, results=FALSE}</span></span>
<span id="cb46-519"><a href="#cb46-519" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(SignifReg)</span>
<span id="cb46-520"><a href="#cb46-520" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-521"><a href="#cb46-521" aria-hidden="true" tabindex="-1"></a><span class="fu">SignifReg</span>(full.reg, </span>
<span id="cb46-522"><a href="#cb46-522" aria-hidden="true" tabindex="-1"></a>          <span class="at">direction =</span> <span class="st">"backward"</span>, </span>
<span id="cb46-523"><a href="#cb46-523" aria-hidden="true" tabindex="-1"></a>          <span class="at">criterion =</span> <span class="st">"BIC"</span>,</span>
<span id="cb46-524"><a href="#cb46-524" aria-hidden="true" tabindex="-1"></a>          <span class="at">adjust.method =</span> <span class="st">"none"</span>)</span>
<span id="cb46-525"><a href="#cb46-525" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-526"><a href="#cb46-526" aria-hidden="true" tabindex="-1"></a><span class="fu">SignifReg</span>(full.reg, </span>
<span id="cb46-527"><a href="#cb46-527" aria-hidden="true" tabindex="-1"></a>          <span class="at">direction =</span> <span class="st">"backward"</span>, </span>
<span id="cb46-528"><a href="#cb46-528" aria-hidden="true" tabindex="-1"></a>          <span class="at">criterion =</span> <span class="st">"r-adj"</span>, </span>
<span id="cb46-529"><a href="#cb46-529" aria-hidden="true" tabindex="-1"></a>          <span class="at">adjust.method =</span> <span class="st">"none"</span>)</span>
<span id="cb46-530"><a href="#cb46-530" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-531"><a href="#cb46-531" aria-hidden="true" tabindex="-1"></a><span class="fu">SignifReg</span>(full.reg, </span>
<span id="cb46-532"><a href="#cb46-532" aria-hidden="true" tabindex="-1"></a>          <span class="at">direction =</span> <span class="st">"backward"</span>,</span>
<span id="cb46-533"><a href="#cb46-533" aria-hidden="true" tabindex="-1"></a>          <span class="at">criterion =</span> <span class="st">"p-value"</span>, </span>
<span id="cb46-534"><a href="#cb46-534" aria-hidden="true" tabindex="-1"></a>          <span class="at">adjust.method =</span> <span class="st">"none"</span>)</span>
<span id="cb46-535"><a href="#cb46-535" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-536"><a href="#cb46-536" aria-hidden="true" tabindex="-1"></a><span class="fu">SignifReg</span>(full.reg, </span>
<span id="cb46-537"><a href="#cb46-537" aria-hidden="true" tabindex="-1"></a>          <span class="at">direction =</span> <span class="st">"both"</span>,</span>
<span id="cb46-538"><a href="#cb46-538" aria-hidden="true" tabindex="-1"></a>          <span class="at">criterion =</span> <span class="st">"BIC"</span>,</span>
<span id="cb46-539"><a href="#cb46-539" aria-hidden="true" tabindex="-1"></a>          <span class="at">adjust.method =</span> <span class="st">"none"</span>)</span>
<span id="cb46-540"><a href="#cb46-540" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-541"><a href="#cb46-541" aria-hidden="true" tabindex="-1"></a><span class="fu">SignifReg</span>(full.reg, </span>
<span id="cb46-542"><a href="#cb46-542" aria-hidden="true" tabindex="-1"></a>          <span class="at">direction =</span> <span class="st">"both"</span>,</span>
<span id="cb46-543"><a href="#cb46-543" aria-hidden="true" tabindex="-1"></a>          <span class="at">criterion =</span> <span class="st">"r-adj"</span>,</span>
<span id="cb46-544"><a href="#cb46-544" aria-hidden="true" tabindex="-1"></a>          <span class="at">adjust.method =</span> <span class="st">"none"</span>)</span>
<span id="cb46-545"><a href="#cb46-545" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-546"><a href="#cb46-546" aria-hidden="true" tabindex="-1"></a><span class="fu">SignifReg</span>(full.reg, </span>
<span id="cb46-547"><a href="#cb46-547" aria-hidden="true" tabindex="-1"></a>          <span class="at">direction =</span> <span class="st">"both"</span>, </span>
<span id="cb46-548"><a href="#cb46-548" aria-hidden="true" tabindex="-1"></a>          <span class="at">criterion =</span> <span class="st">"p-value"</span>,</span>
<span id="cb46-549"><a href="#cb46-549" aria-hidden="true" tabindex="-1"></a>          <span class="at">adjust.method =</span> <span class="st">"none"</span>)</span>
<span id="cb46-550"><a href="#cb46-550" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-551"><a href="#cb46-551" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-552"><a href="#cb46-552" aria-hidden="true" tabindex="-1"></a>The forward selection procedure also picks only just two variables as seen from the following output:</span>
<span id="cb46-553"><a href="#cb46-553" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-556"><a href="#cb46-556" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-557"><a href="#cb46-557" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb46-558"><a href="#cb46-558" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-559"><a href="#cb46-559" aria-hidden="true" tabindex="-1"></a>full.model <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT <span class="sc">~</span> ., <span class="at">data=</span>horsehearts)</span>
<span id="cb46-560"><a href="#cb46-560" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-561"><a href="#cb46-561" aria-hidden="true" tabindex="-1"></a>stmdl <span class="ot">&lt;-</span> <span class="fu">SignifReg</span>(full.reg, </span>
<span id="cb46-562"><a href="#cb46-562" aria-hidden="true" tabindex="-1"></a>                   <span class="at">direction =</span> <span class="st">"both"</span>,</span>
<span id="cb46-563"><a href="#cb46-563" aria-hidden="true" tabindex="-1"></a>                   <span class="at">criterion =</span> <span class="st">"AIC"</span>,</span>
<span id="cb46-564"><a href="#cb46-564" aria-hidden="true" tabindex="-1"></a>                   <span class="at">adjust.method =</span> <span class="st">"none"</span>)</span>
<span id="cb46-565"><a href="#cb46-565" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-566"><a href="#cb46-566" aria-hidden="true" tabindex="-1"></a>stmdl <span class="sc">|&gt;</span> <span class="fu">tidy</span>()</span>
<span id="cb46-567"><a href="#cb46-567" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-568"><a href="#cb46-568" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-569"><a href="#cb46-569" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-572"><a href="#cb46-572" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-573"><a href="#cb46-573" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb46-574"><a href="#cb46-574" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-575"><a href="#cb46-575" aria-hidden="true" tabindex="-1"></a><span class="co"># if(knitr::is_html_output()) {</span></span>
<span id="cb46-576"><a href="#cb46-576" aria-hidden="true" tabindex="-1"></a><span class="co"># </span></span>
<span id="cb46-577"><a href="#cb46-577" aria-hidden="true" tabindex="-1"></a><span class="co">#   stmdl |&gt; </span></span>
<span id="cb46-578"><a href="#cb46-578" aria-hidden="true" tabindex="-1"></a><span class="co">#     tidy() |&gt; </span></span>
<span id="cb46-579"><a href="#cb46-579" aria-hidden="true" tabindex="-1"></a><span class="co">#     kable(digits=3,</span></span>
<span id="cb46-580"><a href="#cb46-580" aria-hidden="true" tabindex="-1"></a><span class="co">#           table.attr = 'data-quarto-disable-processing="true"'</span></span>
<span id="cb46-581"><a href="#cb46-581" aria-hidden="true" tabindex="-1"></a><span class="co">#           ) |&gt; </span></span>
<span id="cb46-582"><a href="#cb46-582" aria-hidden="true" tabindex="-1"></a><span class="co">#     kable_classic(full_width=F)</span></span>
<span id="cb46-583"><a href="#cb46-583" aria-hidden="true" tabindex="-1"></a><span class="co">#     </span></span>
<span id="cb46-584"><a href="#cb46-584" aria-hidden="true" tabindex="-1"></a><span class="co"># } else {</span></span>
<span id="cb46-585"><a href="#cb46-585" aria-hidden="true" tabindex="-1"></a><span class="co">#   </span></span>
<span id="cb46-586"><a href="#cb46-586" aria-hidden="true" tabindex="-1"></a><span class="co">#   stmdl |&gt; </span></span>
<span id="cb46-587"><a href="#cb46-587" aria-hidden="true" tabindex="-1"></a><span class="co">#     tidy() |&gt; </span></span>
<span id="cb46-588"><a href="#cb46-588" aria-hidden="true" tabindex="-1"></a><span class="co">#     kable(digits=3) |&gt; </span></span>
<span id="cb46-589"><a href="#cb46-589" aria-hidden="true" tabindex="-1"></a><span class="co">#     kable_classic(full_width=F)</span></span>
<span id="cb46-590"><a href="#cb46-590" aria-hidden="true" tabindex="-1"></a><span class="co">#   </span></span>
<span id="cb46-591"><a href="#cb46-591" aria-hidden="true" tabindex="-1"></a><span class="co"># }</span></span>
<span id="cb46-592"><a href="#cb46-592" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-593"><a href="#cb46-593" aria-hidden="true" tabindex="-1"></a>stmdl <span class="sc">|&gt;</span> <span class="fu">tidy</span>() <span class="sc">|&gt;</span> </span>
<span id="cb46-594"><a href="#cb46-594" aria-hidden="true" tabindex="-1"></a>    <span class="fu">kable</span>(<span class="at">digits=</span><span class="dv">3</span>,</span>
<span id="cb46-595"><a href="#cb46-595" aria-hidden="true" tabindex="-1"></a>          <span class="at">table.attr =</span> <span class="st">'data-quarto-disable-processing="true"'</span></span>
<span id="cb46-596"><a href="#cb46-596" aria-hidden="true" tabindex="-1"></a>          )</span>
<span id="cb46-597"><a href="#cb46-597" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-598"><a href="#cb46-598" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-599"><a href="#cb46-599" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-600"><a href="#cb46-600" aria-hidden="true" tabindex="-1"></a>For the full regression model, the $AIC$ is -40.5 and it drops to -42.35 for the four variable model. That is, according to the AIC criterion, a further reduction in model size does not compensate for the decline in model fit as measured by the AIC. The $C_{p}$ index also recommends the four variable model because for the $C_{p}$ value of 4.9 is closer to 5, the number of model coefficients.</span>
<span id="cb46-601"><a href="#cb46-601" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-602"><a href="#cb46-602" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, echo=FALSE, results=FALSE}</span></span>
<span id="cb46-603"><a href="#cb46-603" aria-hidden="true" tabindex="-1"></a>b.model <span class="ot">&lt;-</span> <span class="fu">lm</span>(</span>
<span id="cb46-604"><a href="#cb46-604" aria-hidden="true" tabindex="-1"></a>  WEIGHT <span class="sc">~</span> INNERDIA <span class="sc">+</span> OUTERSYS <span class="sc">+</span> EXTSYS <span class="sc">+</span> EXTDIA,</span>
<span id="cb46-605"><a href="#cb46-605" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> horsehearts</span>
<span id="cb46-606"><a href="#cb46-606" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb46-607"><a href="#cb46-607" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-608"><a href="#cb46-608" aria-hidden="true" tabindex="-1"></a>e <span class="ot">&lt;-</span> b.model <span class="sc">|&gt;</span> <span class="fu">anova</span>() <span class="sc">|&gt;</span> <span class="fu">as.matrix</span>()</span>
<span id="cb46-609"><a href="#cb46-609" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-610"><a href="#cb46-610" aria-hidden="true" tabindex="-1"></a>MSQ <span class="ot">&lt;-</span> e[<span class="dv">5</span>,<span class="dv">3</span>]</span>
<span id="cb46-611"><a href="#cb46-611" aria-hidden="true" tabindex="-1"></a>cp <span class="ot">&lt;-</span> (e[<span class="dv">5</span>,<span class="dv">2</span>] <span class="sc">/</span> MSQ) <span class="sc">-</span> (<span class="fu">length</span>(horsehearts<span class="sc">$</span>WEIGHT)<span class="sc">-</span><span class="dv">2</span><span class="sc">*</span><span class="dv">5</span>)</span>
<span id="cb46-612"><a href="#cb46-612" aria-hidden="true" tabindex="-1"></a>cp</span>
<span id="cb46-613"><a href="#cb46-613" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-614"><a href="#cb46-614" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-615"><a href="#cb46-615" aria-hidden="true" tabindex="-1"></a><span class="ss">4.  </span>Step-wise selection of predictors can also be done along with cross validation in each step. The <span class="in">`R`</span> package *caret* enables this. For the horses heart data, the following codes perform the backward regression.</span>
<span id="cb46-616"><a href="#cb46-616" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-617"><a href="#cb46-617" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, results="hide"}</span></span>
<span id="cb46-618"><a href="#cb46-618" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false </span></span>
<span id="cb46-619"><a href="#cb46-619" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-620"><a href="#cb46-620" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb46-621"><a href="#cb46-621" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(leaps)</span>
<span id="cb46-622"><a href="#cb46-622" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-623"><a href="#cb46-623" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb46-624"><a href="#cb46-624" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-625"><a href="#cb46-625" aria-hidden="true" tabindex="-1"></a>fitControl <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(</span>
<span id="cb46-626"><a href="#cb46-626" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">"repeatedcv"</span>, </span>
<span id="cb46-627"><a href="#cb46-627" aria-hidden="true" tabindex="-1"></a>  <span class="at">number =</span> <span class="dv">5</span>, </span>
<span id="cb46-628"><a href="#cb46-628" aria-hidden="true" tabindex="-1"></a>  <span class="at">repeats =</span> <span class="dv">100</span></span>
<span id="cb46-629"><a href="#cb46-629" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb46-630"><a href="#cb46-630" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-631"><a href="#cb46-631" aria-hidden="true" tabindex="-1"></a>leapBackwardfit <span class="ot">&lt;-</span> <span class="fu">train</span>(</span>
<span id="cb46-632"><a href="#cb46-632" aria-hidden="true" tabindex="-1"></a>  WEIGHT <span class="sc">~</span> ., </span>
<span id="cb46-633"><a href="#cb46-633" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> horsehearts,</span>
<span id="cb46-634"><a href="#cb46-634" aria-hidden="true" tabindex="-1"></a>  <span class="at">trControl =</span> fitControl, </span>
<span id="cb46-635"><a href="#cb46-635" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">"leapBackward"</span></span>
<span id="cb46-636"><a href="#cb46-636" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb46-637"><a href="#cb46-637" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-638"><a href="#cb46-638" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(leapBackwardfit)</span>
<span id="cb46-639"><a href="#cb46-639" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-640"><a href="#cb46-640" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-641"><a href="#cb46-641" aria-hidden="true" tabindex="-1"></a>Note that an asterisk in the row means that a particular variable is included in the step. The model in the last step excludes <span class="in">`INNERSYS`</span> and <span class="in">`OUTERDIA.`</span> On the other hand, the forward regression includes only two variables namely <span class="in">`INNERDIA`</span> and <span class="in">`OUTERSYS`</span>. We can also directly use the <span class="in">`leaps`</span> package without cross validation.</span>
<span id="cb46-642"><a href="#cb46-642" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-645"><a href="#cb46-645" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-646"><a href="#cb46-646" aria-hidden="true" tabindex="-1"></a>fitControl <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(</span>
<span id="cb46-647"><a href="#cb46-647" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">"repeatedcv"</span>, </span>
<span id="cb46-648"><a href="#cb46-648" aria-hidden="true" tabindex="-1"></a>  <span class="at">number =</span> <span class="dv">5</span>, </span>
<span id="cb46-649"><a href="#cb46-649" aria-hidden="true" tabindex="-1"></a>  <span class="at">repeats =</span> <span class="dv">100</span></span>
<span id="cb46-650"><a href="#cb46-650" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb46-651"><a href="#cb46-651" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-652"><a href="#cb46-652" aria-hidden="true" tabindex="-1"></a>leapForwardfit <span class="ot">&lt;-</span> <span class="fu">train</span>(</span>
<span id="cb46-653"><a href="#cb46-653" aria-hidden="true" tabindex="-1"></a>  WEIGHT <span class="sc">~</span> ., </span>
<span id="cb46-654"><a href="#cb46-654" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> horsehearts,</span>
<span id="cb46-655"><a href="#cb46-655" aria-hidden="true" tabindex="-1"></a>  <span class="at">trControl =</span> fitControl, </span>
<span id="cb46-656"><a href="#cb46-656" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">"leapForward"</span></span>
<span id="cb46-657"><a href="#cb46-657" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb46-658"><a href="#cb46-658" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-659"><a href="#cb46-659" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(leapForwardfit)</span>
<span id="cb46-660"><a href="#cb46-660" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-661"><a href="#cb46-661" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-662"><a href="#cb46-662" aria-hidden="true" tabindex="-1"></a><span class="fu">## Best Subsets Selection</span></span>
<span id="cb46-663"><a href="#cb46-663" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-664"><a href="#cb46-664" aria-hidden="true" tabindex="-1"></a>An exhaustive screening of all possible regression models (and hence the name **best subsets** regression) can also be done using software. For example, there are 6 predictor variables in the horses' hearts data. If we fix the number of predictors as 3, then $\small {\left(\begin{array}{c} {6} <span class="sc">\\</span> {3} \end{array}\right)} = 20$ regression models are possible. One may select the 'best' 3-variable model based on criteria such as AIC, $C_{p}$, $R_{adj}^{2}$ etc. Software must be employed to perform the conventional stepwise regression procedures. Software algorithms give one or more best candidate models fixing the number of variables in each step.</span>
<span id="cb46-665"><a href="#cb46-665" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-666"><a href="#cb46-666" aria-hidden="true" tabindex="-1"></a>On the basis of our analysis on the horses' hear data, we might decide to recommend the model with predictor variables <span class="in">`EXTDIA`</span>, <span class="in">`EXTSYS`</span>, <span class="in">`INNERDIA`</span> and <span class="in">`OUTERSYS`</span>. In particular if the model is to be used for describing relationships then we would tend to include more variables. For prediction purposes, however, a simpler feasible model is preferred and in this case we may opt for the smaller model with only <span class="in">`INNERDIA`</span> and <span class="in">`OUTERSYS`</span>. See @tbl-subset11 produced using the following <span class="in">`R`</span> codes:</span>
<span id="cb46-667"><a href="#cb46-667" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-670"><a href="#cb46-670" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-671"><a href="#cb46-671" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb46-672"><a href="#cb46-672" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb46-673"><a href="#cb46-673" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tbl-subset11</span></span>
<span id="cb46-674"><a href="#cb46-674" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: "Subset selection"</span></span>
<span id="cb46-675"><a href="#cb46-675" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(leaps)</span>
<span id="cb46-676"><a href="#cb46-676" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(HH)</span>
<span id="cb46-677"><a href="#cb46-677" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(kableExtra)</span>
<span id="cb46-678"><a href="#cb46-678" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-679"><a href="#cb46-679" aria-hidden="true" tabindex="-1"></a>b.model <span class="ot">&lt;-</span> <span class="fu">regsubsets</span>(WEIGHT <span class="sc">~</span> ., <span class="at">data =</span> horsehearts) <span class="sc">|&gt;</span></span>
<span id="cb46-680"><a href="#cb46-680" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summaryHH</span>() </span>
<span id="cb46-681"><a href="#cb46-681" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-682"><a href="#cb46-682" aria-hidden="true" tabindex="-1"></a>b.model <span class="sc">|&gt;</span> </span>
<span id="cb46-683"><a href="#cb46-683" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">3</span>) <span class="sc">|&gt;</span> </span>
<span id="cb46-684"><a href="#cb46-684" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_styling</span>(<span class="at">bootstrap_options =</span> <span class="st">"basic"</span>, <span class="at">full_width =</span> F)</span>
<span id="cb46-685"><a href="#cb46-685" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-686"><a href="#cb46-686" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-687"><a href="#cb46-687" aria-hidden="true" tabindex="-1"></a>Sometimes theory may indicate that a certain explanatory variable should be included in the model (e.g. due to small sample size). If this variable is found to make an insignificant contribution to the model, then one should exclude the variable when the model is to be used for prediction but if the model is to be used for explanation purposes only then the variable should be included. Other considerations such as cost and time may also be taken into account. For every method or algorithm, one could find peculiar data sets where it fouls up. The moral -- be alert and don't automatically accept models thrown up by a program. Note there is **never one right answer** as different methods and different criteria lead to different models.</span>
<span id="cb46-688"><a href="#cb46-688" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-689"><a href="#cb46-689" aria-hidden="true" tabindex="-1"></a>Variable selection procedures can be a valuable tool in data analysis, particularly in the early stages of building a model. At the same time, they present certain dangers. There are several reasons for this:</span>
<span id="cb46-690"><a href="#cb46-690" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-691"><a href="#cb46-691" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>These procedures automatically snoop though many models and may select ones which, by chance, happen to fit well.</span>
<span id="cb46-692"><a href="#cb46-692" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-693"><a href="#cb46-693" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>These forward or backward stepwise procedures are *heuristic* (i.e., shortcut) algorithms, which often work very well but which may not always select the best model for a given number of predictors (here best may refer to adjusted $R^2$-values, or AIC or some other criterion).</span>
<span id="cb46-694"><a href="#cb46-694" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-695"><a href="#cb46-695" aria-hidden="true" tabindex="-1"></a><span class="ss">3.  </span>Automatic procedures cannot take into account special knowledge the analyst may have about the data. Therefore, the model selected may not be the best (or make sense) from a practical point of view.</span>
<span id="cb46-696"><a href="#cb46-696" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-697"><a href="#cb46-697" aria-hidden="true" tabindex="-1"></a><span class="ss">4.  </span>Methods are available that *shrink* coefficients towards zero. The least squares approach minimises the residual sums of squares or RSS without placing any constraint on the coefficients. The shrinkage methods, which place a constraint on the coefficients, work well when there are large numbers of predictors. A *ridge regression* shrinks the coefficients towards zero but in relation each other. On the other hand, (Least Absolute Selection and Shrinkage Operator) *lasso* regression shrinks some of coefficients to zero which means these predictors can be dropped. Note that the ridge regression does not completely remove predictors. By shrinking large coefficients, we obtain a model with higher bias but lower variance. This process is known as *regularisation* in the literature (not covered in this course).</span>
<span id="cb46-698"><a href="#cb46-698" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-699"><a href="#cb46-699" aria-hidden="true" tabindex="-1"></a><span class="fu"># Polynomial Models</span></span>
<span id="cb46-700"><a href="#cb46-700" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-701"><a href="#cb46-701" aria-hidden="true" tabindex="-1"></a>Consider the **pinetree** data set which contains the circumference measurements of pine trees at four positions. The simple regression of the top circumference on the first (bottom) circumference, the fit is ${\text {Top = -6.33 + 0.763 First}}$. This fit is satisfactory on many counts (highly significant $t$ and $F$ values, high $R^{2}$ etc); see @tbl-poly1tidy and @tbl-poly1glance.</span>
<span id="cb46-702"><a href="#cb46-702" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-705"><a href="#cb46-705" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-706"><a href="#cb46-706" aria-hidden="true" tabindex="-1"></a><span class="fu">download.file</span>(</span>
<span id="cb46-707"><a href="#cb46-707" aria-hidden="true" tabindex="-1"></a>  <span class="at">url =</span> <span class="st">"http://www.massey.ac.nz/~anhsmith/data/pinetree.RData"</span>, </span>
<span id="cb46-708"><a href="#cb46-708" aria-hidden="true" tabindex="-1"></a>  <span class="at">destfile =</span> <span class="st">"pinetree.RData"</span>)</span>
<span id="cb46-709"><a href="#cb46-709" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-710"><a href="#cb46-710" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="st">"pinetree.RData"</span>)</span>
<span id="cb46-711"><a href="#cb46-711" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-712"><a href="#cb46-712" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-713"><a href="#cb46-713" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-716"><a href="#cb46-716" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-717"><a href="#cb46-717" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb46-718"><a href="#cb46-718" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb46-719"><a href="#cb46-719" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-720"><a href="#cb46-720" aria-hidden="true" tabindex="-1"></a>pine1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(Top <span class="sc">~</span> First, <span class="at">data =</span> pinetree) </span>
<span id="cb46-721"><a href="#cb46-721" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-722"><a href="#cb46-722" aria-hidden="true" tabindex="-1"></a>pine1 <span class="sc">|&gt;</span> <span class="fu">tidy</span>()</span>
<span id="cb46-723"><a href="#cb46-723" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-724"><a href="#cb46-724" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-725"><a href="#cb46-725" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-728"><a href="#cb46-728" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-729"><a href="#cb46-729" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb46-730"><a href="#cb46-730" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb46-731"><a href="#cb46-731" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tbl-poly1tidy</span></span>
<span id="cb46-732"><a href="#cb46-732" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: "tidy() output of lm(Top~First, data=pinetree)"</span></span>
<span id="cb46-733"><a href="#cb46-733" aria-hidden="true" tabindex="-1"></a><span class="co"># if(knitr::is_html_output()) {</span></span>
<span id="cb46-734"><a href="#cb46-734" aria-hidden="true" tabindex="-1"></a><span class="co"># </span></span>
<span id="cb46-735"><a href="#cb46-735" aria-hidden="true" tabindex="-1"></a><span class="co">#   pine1 |&gt; </span></span>
<span id="cb46-736"><a href="#cb46-736" aria-hidden="true" tabindex="-1"></a><span class="co">#   tidy() |&gt; </span></span>
<span id="cb46-737"><a href="#cb46-737" aria-hidden="true" tabindex="-1"></a><span class="co">#   kable(digits=3,</span></span>
<span id="cb46-738"><a href="#cb46-738" aria-hidden="true" tabindex="-1"></a><span class="co">#         table.attr = 'data-quarto-disable-processing="true"'</span></span>
<span id="cb46-739"><a href="#cb46-739" aria-hidden="true" tabindex="-1"></a><span class="co">#         ) |&gt; </span></span>
<span id="cb46-740"><a href="#cb46-740" aria-hidden="true" tabindex="-1"></a><span class="co">#   kable_classic(full_width=F)</span></span>
<span id="cb46-741"><a href="#cb46-741" aria-hidden="true" tabindex="-1"></a><span class="co">#     </span></span>
<span id="cb46-742"><a href="#cb46-742" aria-hidden="true" tabindex="-1"></a><span class="co"># } else {</span></span>
<span id="cb46-743"><a href="#cb46-743" aria-hidden="true" tabindex="-1"></a><span class="co">#   </span></span>
<span id="cb46-744"><a href="#cb46-744" aria-hidden="true" tabindex="-1"></a><span class="co">#   pine1 |&gt; </span></span>
<span id="cb46-745"><a href="#cb46-745" aria-hidden="true" tabindex="-1"></a><span class="co">#   tidy() |&gt; </span></span>
<span id="cb46-746"><a href="#cb46-746" aria-hidden="true" tabindex="-1"></a><span class="co">#   kable(digits=3 ) |&gt; </span></span>
<span id="cb46-747"><a href="#cb46-747" aria-hidden="true" tabindex="-1"></a><span class="co">#   kable_classic(full_width=F)</span></span>
<span id="cb46-748"><a href="#cb46-748" aria-hidden="true" tabindex="-1"></a><span class="co">#   </span></span>
<span id="cb46-749"><a href="#cb46-749" aria-hidden="true" tabindex="-1"></a><span class="co"># }</span></span>
<span id="cb46-750"><a href="#cb46-750" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-751"><a href="#cb46-751" aria-hidden="true" tabindex="-1"></a>pine1 <span class="sc">|&gt;</span> </span>
<span id="cb46-752"><a href="#cb46-752" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>() <span class="sc">|&gt;</span> </span>
<span id="cb46-753"><a href="#cb46-753" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits=</span><span class="dv">3</span> )</span>
<span id="cb46-754"><a href="#cb46-754" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-755"><a href="#cb46-755" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-756"><a href="#cb46-756" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-759"><a href="#cb46-759" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-760"><a href="#cb46-760" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb46-761"><a href="#cb46-761" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-762"><a href="#cb46-762" aria-hidden="true" tabindex="-1"></a>pine1 <span class="sc">|&gt;</span> </span>
<span id="cb46-763"><a href="#cb46-763" aria-hidden="true" tabindex="-1"></a>  <span class="fu">glance</span>() <span class="sc">|&gt;</span> </span>
<span id="cb46-764"><a href="#cb46-764" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(adj.r.squared, sigma, statistic, p.value, AIC, BIC)</span>
<span id="cb46-765"><a href="#cb46-765" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-766"><a href="#cb46-766" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-767"><a href="#cb46-767" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-770"><a href="#cb46-770" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-771"><a href="#cb46-771" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb46-772"><a href="#cb46-772" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tbl-poly1glance</span></span>
<span id="cb46-773"><a href="#cb46-773" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: "glance() output of lm(Top~First, data=pinetree)"</span></span>
<span id="cb46-774"><a href="#cb46-774" aria-hidden="true" tabindex="-1"></a><span class="co"># if(knitr::is_html_output()) {</span></span>
<span id="cb46-775"><a href="#cb46-775" aria-hidden="true" tabindex="-1"></a><span class="co"># </span></span>
<span id="cb46-776"><a href="#cb46-776" aria-hidden="true" tabindex="-1"></a><span class="co">#   pine1 |&gt; </span></span>
<span id="cb46-777"><a href="#cb46-777" aria-hidden="true" tabindex="-1"></a><span class="co">#   glance() |&gt; </span></span>
<span id="cb46-778"><a href="#cb46-778" aria-hidden="true" tabindex="-1"></a><span class="co">#   select(adj.r.squared, sigma, statistic, p.value, AIC, BIC) |&gt; </span></span>
<span id="cb46-779"><a href="#cb46-779" aria-hidden="true" tabindex="-1"></a><span class="co">#   kable(digits=3,</span></span>
<span id="cb46-780"><a href="#cb46-780" aria-hidden="true" tabindex="-1"></a><span class="co">#         table.attr = 'data-quarto-disable-processing="true"'</span></span>
<span id="cb46-781"><a href="#cb46-781" aria-hidden="true" tabindex="-1"></a><span class="co">#         ) |&gt; </span></span>
<span id="cb46-782"><a href="#cb46-782" aria-hidden="true" tabindex="-1"></a><span class="co">#   kable_classic(full_width=F) </span></span>
<span id="cb46-783"><a href="#cb46-783" aria-hidden="true" tabindex="-1"></a><span class="co">#     </span></span>
<span id="cb46-784"><a href="#cb46-784" aria-hidden="true" tabindex="-1"></a><span class="co"># } else {</span></span>
<span id="cb46-785"><a href="#cb46-785" aria-hidden="true" tabindex="-1"></a><span class="co">#   </span></span>
<span id="cb46-786"><a href="#cb46-786" aria-hidden="true" tabindex="-1"></a><span class="co">#   pine1 |&gt; </span></span>
<span id="cb46-787"><a href="#cb46-787" aria-hidden="true" tabindex="-1"></a><span class="co">#   glance() |&gt; </span></span>
<span id="cb46-788"><a href="#cb46-788" aria-hidden="true" tabindex="-1"></a><span class="co">#   select(adj.r.squared, sigma, statistic, p.value, AIC, BIC) |&gt; </span></span>
<span id="cb46-789"><a href="#cb46-789" aria-hidden="true" tabindex="-1"></a><span class="co">#   kable(digits=3) |&gt; </span></span>
<span id="cb46-790"><a href="#cb46-790" aria-hidden="true" tabindex="-1"></a><span class="co">#   kable_classic(full_width=F) </span></span>
<span id="cb46-791"><a href="#cb46-791" aria-hidden="true" tabindex="-1"></a><span class="co">#   </span></span>
<span id="cb46-792"><a href="#cb46-792" aria-hidden="true" tabindex="-1"></a><span class="co"># }</span></span>
<span id="cb46-793"><a href="#cb46-793" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-794"><a href="#cb46-794" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-795"><a href="#cb46-795" aria-hidden="true" tabindex="-1"></a> pine1 <span class="sc">|&gt;</span> </span>
<span id="cb46-796"><a href="#cb46-796" aria-hidden="true" tabindex="-1"></a>  <span class="fu">glance</span>() <span class="sc">|&gt;</span> </span>
<span id="cb46-797"><a href="#cb46-797" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(adj.r.squared, sigma, statistic, p.value, AIC, BIC) <span class="sc">|&gt;</span> </span>
<span id="cb46-798"><a href="#cb46-798" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits=</span><span class="dv">3</span>)</span>
<span id="cb46-799"><a href="#cb46-799" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-800"><a href="#cb46-800" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-801"><a href="#cb46-801" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-802"><a href="#cb46-802" aria-hidden="true" tabindex="-1"></a>The residual plot, shown as @fig-pine1, still provides an important clue that we should try a polynomial (cubic) model.</span>
<span id="cb46-803"><a href="#cb46-803" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-806"><a href="#cb46-806" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-807"><a href="#cb46-807" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb46-808"><a href="#cb46-808" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-pine1</span></span>
<span id="cb46-809"><a href="#cb46-809" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Residuals vs fits plot"</span></span>
<span id="cb46-810"><a href="#cb46-810" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-811"><a href="#cb46-811" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggfortify)</span>
<span id="cb46-812"><a href="#cb46-812" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-813"><a href="#cb46-813" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(pine1, <span class="at">which=</span><span class="dv">1</span>, <span class="at">ncol=</span><span class="dv">1</span>)</span>
<span id="cb46-814"><a href="#cb46-814" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-815"><a href="#cb46-815" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-818"><a href="#cb46-818" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-819"><a href="#cb46-819" aria-hidden="true" tabindex="-1"></a>pine3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(Top <span class="sc">~</span> <span class="fu">poly</span>(First, <span class="dv">3</span>, <span class="at">raw=</span><span class="cn">TRUE</span>), </span>
<span id="cb46-820"><a href="#cb46-820" aria-hidden="true" tabindex="-1"></a>            <span class="at">data =</span> pinetree)</span>
<span id="cb46-821"><a href="#cb46-821" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-822"><a href="#cb46-822" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-823"><a href="#cb46-823" aria-hidden="true" tabindex="-1"></a>@tbl-poly3tidy shows the significance results for the polynomial model ${\text Top=44.1 - 3.97First+0.142}\left({\text First}\right)^{2} - 0.00135\left(\text {First}\right)^{3}$. This model has achieved a good reduction in the residual standard error and improved AIC and BIC (see @tbl-poly3glance). The residual diagnostic plots are somewhat satisfactory. The Scale-Location plot suggests that there may be a subgrouping variable. The fitted model can be further improved using the Area categorical factor. This topic, known as the analysis of covariance will be covered later on. Note that both models are satisfactory in terms of Cook's distance. A few leverage or $h_{ii}$ values cause concern seen in @fig-pinelev but we will ignore them given the size of the data set.</span>
<span id="cb46-824"><a href="#cb46-824" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-827"><a href="#cb46-827" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-828"><a href="#cb46-828" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb46-829"><a href="#cb46-829" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb46-830"><a href="#cb46-830" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-831"><a href="#cb46-831" aria-hidden="true" tabindex="-1"></a>pine3 <span class="sc">|&gt;</span> <span class="fu">tidy</span>() </span>
<span id="cb46-832"><a href="#cb46-832" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-833"><a href="#cb46-833" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-836"><a href="#cb46-836" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-837"><a href="#cb46-837" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb46-838"><a href="#cb46-838" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb46-839"><a href="#cb46-839" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tbl-poly3tidy</span></span>
<span id="cb46-840"><a href="#cb46-840" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: "tidy() output of lm(Top~poly(First, 3, raw=TRUE), data=pinetree)"</span></span>
<span id="cb46-841"><a href="#cb46-841" aria-hidden="true" tabindex="-1"></a><span class="co"># if(knitr::is_html_output()) {</span></span>
<span id="cb46-842"><a href="#cb46-842" aria-hidden="true" tabindex="-1"></a><span class="co"># </span></span>
<span id="cb46-843"><a href="#cb46-843" aria-hidden="true" tabindex="-1"></a><span class="co">#   pine3 |&gt; </span></span>
<span id="cb46-844"><a href="#cb46-844" aria-hidden="true" tabindex="-1"></a><span class="co">#   tidy() |&gt; </span></span>
<span id="cb46-845"><a href="#cb46-845" aria-hidden="true" tabindex="-1"></a><span class="co">#   kable(digits = 4,</span></span>
<span id="cb46-846"><a href="#cb46-846" aria-hidden="true" tabindex="-1"></a><span class="co">#         table.attr = 'data-quarto-disable-processing="true"'</span></span>
<span id="cb46-847"><a href="#cb46-847" aria-hidden="true" tabindex="-1"></a><span class="co">#         ) |&gt; </span></span>
<span id="cb46-848"><a href="#cb46-848" aria-hidden="true" tabindex="-1"></a><span class="co">#   kable_classic(full_width=F)</span></span>
<span id="cb46-849"><a href="#cb46-849" aria-hidden="true" tabindex="-1"></a><span class="co">#     </span></span>
<span id="cb46-850"><a href="#cb46-850" aria-hidden="true" tabindex="-1"></a><span class="co"># } else {</span></span>
<span id="cb46-851"><a href="#cb46-851" aria-hidden="true" tabindex="-1"></a><span class="co">#   </span></span>
<span id="cb46-852"><a href="#cb46-852" aria-hidden="true" tabindex="-1"></a><span class="co">#   pine3 |&gt; </span></span>
<span id="cb46-853"><a href="#cb46-853" aria-hidden="true" tabindex="-1"></a><span class="co">#   tidy() |&gt; </span></span>
<span id="cb46-854"><a href="#cb46-854" aria-hidden="true" tabindex="-1"></a><span class="co">#   kable(digits = 4) |&gt; </span></span>
<span id="cb46-855"><a href="#cb46-855" aria-hidden="true" tabindex="-1"></a><span class="co">#   kable_classic(full_width=F)</span></span>
<span id="cb46-856"><a href="#cb46-856" aria-hidden="true" tabindex="-1"></a><span class="co">#   </span></span>
<span id="cb46-857"><a href="#cb46-857" aria-hidden="true" tabindex="-1"></a><span class="co"># }</span></span>
<span id="cb46-858"><a href="#cb46-858" aria-hidden="true" tabindex="-1"></a>pine3 <span class="sc">|&gt;</span> </span>
<span id="cb46-859"><a href="#cb46-859" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>() <span class="sc">|&gt;</span> </span>
<span id="cb46-860"><a href="#cb46-860" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">4</span>)</span>
<span id="cb46-861"><a href="#cb46-861" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb46-862"><a href="#cb46-862" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-863"><a href="#cb46-863" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-864"><a href="#cb46-864" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-867"><a href="#cb46-867" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-868"><a href="#cb46-868" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb46-869"><a href="#cb46-869" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb46-870"><a href="#cb46-870" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-871"><a href="#cb46-871" aria-hidden="true" tabindex="-1"></a>pine3 <span class="sc">|&gt;</span> </span>
<span id="cb46-872"><a href="#cb46-872" aria-hidden="true" tabindex="-1"></a>  <span class="fu">glance</span>() <span class="sc">|&gt;</span> </span>
<span id="cb46-873"><a href="#cb46-873" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(adj.r.squared, sigma, statistic, p.value, AIC, BIC) </span>
<span id="cb46-874"><a href="#cb46-874" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-875"><a href="#cb46-875" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-878"><a href="#cb46-878" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-879"><a href="#cb46-879" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb46-880"><a href="#cb46-880" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tbl-poly3glance</span></span>
<span id="cb46-881"><a href="#cb46-881" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: "glance() output of lm(Top~poly(First,3, raw=TRUE), data=pinetree)"</span></span>
<span id="cb46-882"><a href="#cb46-882" aria-hidden="true" tabindex="-1"></a><span class="co"># if(knitr::is_html_output()) {</span></span>
<span id="cb46-883"><a href="#cb46-883" aria-hidden="true" tabindex="-1"></a><span class="co"># </span></span>
<span id="cb46-884"><a href="#cb46-884" aria-hidden="true" tabindex="-1"></a><span class="co">#   pine3 |&gt; </span></span>
<span id="cb46-885"><a href="#cb46-885" aria-hidden="true" tabindex="-1"></a><span class="co">#   glance() |&gt; </span></span>
<span id="cb46-886"><a href="#cb46-886" aria-hidden="true" tabindex="-1"></a><span class="co">#   select(adj.r.squared, sigma, statistic, p.value, AIC, BIC) |&gt; </span></span>
<span id="cb46-887"><a href="#cb46-887" aria-hidden="true" tabindex="-1"></a><span class="co">#   kable(digits = 2,</span></span>
<span id="cb46-888"><a href="#cb46-888" aria-hidden="true" tabindex="-1"></a><span class="co">#         table.attr = 'data-quarto-disable-processing="true"'</span></span>
<span id="cb46-889"><a href="#cb46-889" aria-hidden="true" tabindex="-1"></a><span class="co">#         ) |&gt; </span></span>
<span id="cb46-890"><a href="#cb46-890" aria-hidden="true" tabindex="-1"></a><span class="co">#   kable_classic(full_width=F)</span></span>
<span id="cb46-891"><a href="#cb46-891" aria-hidden="true" tabindex="-1"></a><span class="co">#     </span></span>
<span id="cb46-892"><a href="#cb46-892" aria-hidden="true" tabindex="-1"></a><span class="co"># } else {</span></span>
<span id="cb46-893"><a href="#cb46-893" aria-hidden="true" tabindex="-1"></a><span class="co">#   </span></span>
<span id="cb46-894"><a href="#cb46-894" aria-hidden="true" tabindex="-1"></a><span class="co">#   pine3 |&gt; </span></span>
<span id="cb46-895"><a href="#cb46-895" aria-hidden="true" tabindex="-1"></a><span class="co">#   glance() |&gt; </span></span>
<span id="cb46-896"><a href="#cb46-896" aria-hidden="true" tabindex="-1"></a><span class="co">#   select(adj.r.squared, sigma, statistic, p.value, AIC, BIC) |&gt; </span></span>
<span id="cb46-897"><a href="#cb46-897" aria-hidden="true" tabindex="-1"></a><span class="co">#   kable(digits = 2) |&gt; </span></span>
<span id="cb46-898"><a href="#cb46-898" aria-hidden="true" tabindex="-1"></a><span class="co">#   kable_classic(full_width=F)</span></span>
<span id="cb46-899"><a href="#cb46-899" aria-hidden="true" tabindex="-1"></a><span class="co">#   </span></span>
<span id="cb46-900"><a href="#cb46-900" aria-hidden="true" tabindex="-1"></a><span class="co"># }</span></span>
<span id="cb46-901"><a href="#cb46-901" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-902"><a href="#cb46-902" aria-hidden="true" tabindex="-1"></a>pine3 <span class="sc">|&gt;</span> </span>
<span id="cb46-903"><a href="#cb46-903" aria-hidden="true" tabindex="-1"></a>  <span class="fu">glance</span>() <span class="sc">|&gt;</span> </span>
<span id="cb46-904"><a href="#cb46-904" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(adj.r.squared, sigma, statistic, p.value, AIC, BIC) <span class="sc">|&gt;</span> </span>
<span id="cb46-905"><a href="#cb46-905" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">2</span>)</span>
<span id="cb46-906"><a href="#cb46-906" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-907"><a href="#cb46-907" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-910"><a href="#cb46-910" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-911"><a href="#cb46-911" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb46-912"><a href="#cb46-912" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-pinelev</span></span>
<span id="cb46-913"><a href="#cb46-913" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Residual vs Leverage plot"</span></span>
<span id="cb46-914"><a href="#cb46-914" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-915"><a href="#cb46-915" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(pine3, <span class="at">which=</span><span class="dv">5</span>, <span class="at">ncol=</span><span class="dv">1</span>)</span>
<span id="cb46-916"><a href="#cb46-916" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-917"><a href="#cb46-917" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-918"><a href="#cb46-918" aria-hidden="true" tabindex="-1"></a>How quadratic and quartic models fare compared to the cubic fit is also of interest. Try the <span class="in">`R`</span> code given below and compare the outputs:</span>
<span id="cb46-919"><a href="#cb46-919" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-920"><a href="#cb46-920" aria-hidden="true" tabindex="-1"></a><span class="in">```{r polysum, echo=TRUE, results='hide'}</span></span>
<span id="cb46-921"><a href="#cb46-921" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(WEIGHT <span class="sc">~</span> OUTERDIA, <span class="at">data =</span> horsehearts))</span>
<span id="cb46-922"><a href="#cb46-922" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(WEIGHT <span class="sc">~</span> <span class="fu">poly</span>(OUTERDIA,<span class="dv">2</span>, <span class="at">raw=</span>T), <span class="at">data =</span> horsehearts))</span>
<span id="cb46-923"><a href="#cb46-923" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(WEIGHT <span class="sc">~</span> <span class="fu">poly</span>(OUTERDIA,<span class="dv">3</span>, <span class="at">raw=</span>T), <span class="at">data =</span> horsehearts))</span>
<span id="cb46-924"><a href="#cb46-924" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(WEIGHT <span class="sc">~</span> <span class="fu">poly</span>(OUTERDIA,<span class="dv">4</span>, <span class="at">raw=</span>T), <span class="at">data =</span> horsehearts))</span>
<span id="cb46-925"><a href="#cb46-925" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-926"><a href="#cb46-926" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-927"><a href="#cb46-927" aria-hidden="true" tabindex="-1"></a>The key model summary measures of the four polynomial models are shown in @tbl-polysummary. As expected, the $R^2$ value increases, although not by much in this case, as polynomial terms are added. Note that the multicollinearity among the polynomial terms renders all the coefficients of the quadratic regression insignificant at 5% level. For the cubic regression model, all the coefficients are significant. It is usual to keep adding the higher order terms until there is no significant increase in the additional variation explained (measured by the $t$ or $F$ statistic). Alternatively we may use the AIC criterion. In the above example, when the quartic term <span class="in">`OUTERDIA`</span>$^4$ is added, the AIC slightly increases to 114.99 (from 114.65) suggesting that we may stop with the cubic regression.</span>
<span id="cb46-928"><a href="#cb46-928" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-931"><a href="#cb46-931" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-932"><a href="#cb46-932" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb46-933"><a href="#cb46-933" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb46-934"><a href="#cb46-934" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-935"><a href="#cb46-935" aria-hidden="true" tabindex="-1"></a>modstats <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb46-936"><a href="#cb46-936" aria-hidden="true" tabindex="-1"></a>  <span class="at">straight.line =</span> <span class="fu">lm</span>(WEIGHT <span class="sc">~</span> OUTERDIA, </span>
<span id="cb46-937"><a href="#cb46-937" aria-hidden="true" tabindex="-1"></a>                     <span class="at">data =</span> horsehearts), </span>
<span id="cb46-938"><a href="#cb46-938" aria-hidden="true" tabindex="-1"></a>  <span class="at">quadratic =</span> <span class="fu">lm</span>(WEIGHT <span class="sc">~</span> <span class="fu">poly</span>(OUTERDIA,<span class="dv">2</span>,<span class="at">raw=</span>T),</span>
<span id="cb46-939"><a href="#cb46-939" aria-hidden="true" tabindex="-1"></a>                 <span class="at">data=</span>horsehearts), </span>
<span id="cb46-940"><a href="#cb46-940" aria-hidden="true" tabindex="-1"></a>  <span class="at">cubic =</span> <span class="fu">lm</span>(WEIGHT<span class="sc">~</span> <span class="fu">poly</span>(OUTERDIA,<span class="dv">3</span>, <span class="at">raw=</span>T), </span>
<span id="cb46-941"><a href="#cb46-941" aria-hidden="true" tabindex="-1"></a>             <span class="at">data=</span>horsehearts), </span>
<span id="cb46-942"><a href="#cb46-942" aria-hidden="true" tabindex="-1"></a>  <span class="at">quartic =</span> <span class="fu">lm</span>(WEIGHT<span class="sc">~</span> <span class="fu">poly</span>(OUTERDIA,<span class="dv">4</span>, <span class="at">raw=</span>T),</span>
<span id="cb46-943"><a href="#cb46-943" aria-hidden="true" tabindex="-1"></a>               <span class="at">data=</span>horsehearts)</span>
<span id="cb46-944"><a href="#cb46-944" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">|&gt;</span> </span>
<span id="cb46-945"><a href="#cb46-945" aria-hidden="true" tabindex="-1"></a>  <span class="fu">enframe</span>(</span>
<span id="cb46-946"><a href="#cb46-946" aria-hidden="true" tabindex="-1"></a>    <span class="at">name =</span> <span class="st">"model"</span>,</span>
<span id="cb46-947"><a href="#cb46-947" aria-hidden="true" tabindex="-1"></a>    <span class="at">value =</span> <span class="st">"fit"</span></span>
<span id="cb46-948"><a href="#cb46-948" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">|&gt;</span> </span>
<span id="cb46-949"><a href="#cb46-949" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">glanced =</span> <span class="fu">map</span>(fit, glance)) <span class="sc">|&gt;</span> </span>
<span id="cb46-950"><a href="#cb46-950" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unnest</span>(glanced) <span class="sc">|&gt;</span> </span>
<span id="cb46-951"><a href="#cb46-951" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(model, r.squared, adj.r.squared, sigma, </span>
<span id="cb46-952"><a href="#cb46-952" aria-hidden="true" tabindex="-1"></a>         statistic, AIC, BIC)</span>
<span id="cb46-953"><a href="#cb46-953" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-954"><a href="#cb46-954" aria-hidden="true" tabindex="-1"></a>modstats</span>
<span id="cb46-955"><a href="#cb46-955" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-956"><a href="#cb46-956" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-957"><a href="#cb46-957" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-960"><a href="#cb46-960" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-961"><a href="#cb46-961" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb46-962"><a href="#cb46-962" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tbl-polysummary</span></span>
<span id="cb46-963"><a href="#cb46-963" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: "Glancing Polynomial models"</span></span>
<span id="cb46-964"><a href="#cb46-964" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-965"><a href="#cb46-965" aria-hidden="true" tabindex="-1"></a><span class="co"># if(knitr::is_html_output()) {</span></span>
<span id="cb46-966"><a href="#cb46-966" aria-hidden="true" tabindex="-1"></a><span class="co"># </span></span>
<span id="cb46-967"><a href="#cb46-967" aria-hidden="true" tabindex="-1"></a><span class="co">#   modstats |&gt; </span></span>
<span id="cb46-968"><a href="#cb46-968" aria-hidden="true" tabindex="-1"></a><span class="co">#   kable(digits=2,</span></span>
<span id="cb46-969"><a href="#cb46-969" aria-hidden="true" tabindex="-1"></a><span class="co">#         table.attr = 'data-quarto-disable-processing="true"'</span></span>
<span id="cb46-970"><a href="#cb46-970" aria-hidden="true" tabindex="-1"></a><span class="co">#         ) |&gt; </span></span>
<span id="cb46-971"><a href="#cb46-971" aria-hidden="true" tabindex="-1"></a><span class="co">#   kable_classic(full_width=F)</span></span>
<span id="cb46-972"><a href="#cb46-972" aria-hidden="true" tabindex="-1"></a><span class="co">#     </span></span>
<span id="cb46-973"><a href="#cb46-973" aria-hidden="true" tabindex="-1"></a><span class="co"># } else {</span></span>
<span id="cb46-974"><a href="#cb46-974" aria-hidden="true" tabindex="-1"></a><span class="co">#   </span></span>
<span id="cb46-975"><a href="#cb46-975" aria-hidden="true" tabindex="-1"></a><span class="co">#   modstats |&gt; </span></span>
<span id="cb46-976"><a href="#cb46-976" aria-hidden="true" tabindex="-1"></a><span class="co">#   kable(digits=2) |&gt; </span></span>
<span id="cb46-977"><a href="#cb46-977" aria-hidden="true" tabindex="-1"></a><span class="co">#   kable_classic(full_width=F)</span></span>
<span id="cb46-978"><a href="#cb46-978" aria-hidden="true" tabindex="-1"></a><span class="co">#   </span></span>
<span id="cb46-979"><a href="#cb46-979" aria-hidden="true" tabindex="-1"></a><span class="co"># }</span></span>
<span id="cb46-980"><a href="#cb46-980" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-981"><a href="#cb46-981" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb46-982"><a href="#cb46-982" aria-hidden="true" tabindex="-1"></a>modstats <span class="sc">|&gt;</span> </span>
<span id="cb46-983"><a href="#cb46-983" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits=</span><span class="dv">2</span>)</span>
<span id="cb46-984"><a href="#cb46-984" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-985"><a href="#cb46-985" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-986"><a href="#cb46-986" aria-hidden="true" tabindex="-1"></a>It is desirable to keep the coefficients the same when higher order polynomial terms are added. This can be done using orthogonal polynomial coefficients (we will skip the theory) for which we will avoid the argument <span class="in">`raw`</span> within the function <span class="in">`poly()`</span>. Try-</span>
<span id="cb46-987"><a href="#cb46-987" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-988"><a href="#cb46-988" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, results='hide'}</span></span>
<span id="cb46-989"><a href="#cb46-989" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(Top <span class="sc">~</span> <span class="fu">poly</span>(First,<span class="dv">1</span>), <span class="at">data=</span>pinetree)</span>
<span id="cb46-990"><a href="#cb46-990" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(Top <span class="sc">~</span> <span class="fu">poly</span>(First,<span class="dv">2</span>), <span class="at">data=</span>pinetree)</span>
<span id="cb46-991"><a href="#cb46-991" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(Top <span class="sc">~</span> <span class="fu">poly</span>(First,<span class="dv">3</span>), <span class="at">data=</span>pinetree)</span>
<span id="cb46-992"><a href="#cb46-992" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-993"><a href="#cb46-993" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-994"><a href="#cb46-994" aria-hidden="true" tabindex="-1"></a>Stepwise methods are not employed for developing polynomial models as it would not be appropriate (say) to have the linear and cubic terms but drop the quadratic one. The coefficient terms for the higher order terms become very small. It is also possible that the coefficient estimation may be incorrect due to ill conditioning of the data matrix which is used obtain the model coefficients. Some authors recommend appropriate rescaling of the polynomial terms (such as subtracting the mean etc) to avoid such problems.</span>
<span id="cb46-995"><a href="#cb46-995" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-996"><a href="#cb46-996" aria-hidden="true" tabindex="-1"></a>The use of polynomials greater than second-order is discouraged. Higher-order polynomials are known to be extremely volatile; they have high variance, and make bad predictions. If you need a more flexible model, then it is generally better to use some sort of smoother than a high-order polynomial.</span>
<span id="cb46-997"><a href="#cb46-997" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-998"><a href="#cb46-998" aria-hidden="true" tabindex="-1"></a>In fact, a popular method of smoothing is known as "local polynomial fitting", or **spline smoothing**. Local polynomials are sometimes preferred to a single polynomial regression model for the whole data set. An example based on the <span class="in">`pinetree`</span> data is shown in @fig-spline which uses the <span class="in">`bs()`</span> function from the *splines* package.</span>
<span id="cb46-999"><a href="#cb46-999" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-1002"><a href="#cb46-1002" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-1003"><a href="#cb46-1003" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb46-1004"><a href="#cb46-1004" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-spline</span></span>
<span id="cb46-1005"><a href="#cb46-1005" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Polynomial Spline smoothing"</span></span>
<span id="cb46-1006"><a href="#cb46-1006" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-1007"><a href="#cb46-1007" aria-hidden="true" tabindex="-1"></a>pinetree <span class="sc">|&gt;</span> </span>
<span id="cb46-1008"><a href="#cb46-1008" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb46-1009"><a href="#cb46-1009" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aes</span>(First, Top) <span class="sc">+</span></span>
<span id="cb46-1010"><a href="#cb46-1010" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb46-1011"><a href="#cb46-1011" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> lm, </span>
<span id="cb46-1012"><a href="#cb46-1012" aria-hidden="true" tabindex="-1"></a>              <span class="at">formula =</span> y <span class="sc">~</span> splines<span class="sc">::</span><span class="fu">bs</span>(x, <span class="dv">3</span>))</span>
<span id="cb46-1013"><a href="#cb46-1013" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-1014"><a href="#cb46-1014" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-1015"><a href="#cb46-1015" aria-hidden="true" tabindex="-1"></a><span class="fu"># Model structure and other issues</span></span>
<span id="cb46-1016"><a href="#cb46-1016" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-1017"><a href="#cb46-1017" aria-hidden="true" tabindex="-1"></a>The difficult task in statistical modelling is the assessment of the underlying model structure or alternatively knowing the true form of the relationship. For example, the true relationship between $Y$ and $X$ variables may be nonlinear. If we incorrectly assume a multiple linear relationship instead, a good model may not result. The interaction between the explanatory variables is also important and this topic is covered in a different section. We may also fit a robust linear model in order to validate the ordinary least squares fit. For the horses heart data, OUTERSYS and EXTDIA were short-listed as the predictors of WEIGHT using the AIC criterion. This least squares regression model can be compared to the robust versions as shown in @fig-mcompare1.</span>
<span id="cb46-1018"><a href="#cb46-1018" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-1021"><a href="#cb46-1021" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-1022"><a href="#cb46-1022" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb46-1023"><a href="#cb46-1023" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-mcompare1</span></span>
<span id="cb46-1024"><a href="#cb46-1024" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Comparison of predictions"</span></span>
<span id="cb46-1025"><a href="#cb46-1025" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-1026"><a href="#cb46-1026" aria-hidden="true" tabindex="-1"></a>hh_lm <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT <span class="sc">~</span> OUTERSYS <span class="sc">+</span> EXTDIA, <span class="at">data=</span>horsehearts)</span>
<span id="cb46-1027"><a href="#cb46-1027" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-1028"><a href="#cb46-1028" aria-hidden="true" tabindex="-1"></a>hh_rlm <span class="ot">&lt;-</span> MASS<span class="sc">::</span><span class="fu">rlm</span>(WEIGHT <span class="sc">~</span> OUTERSYS <span class="sc">+</span> EXTDIA, <span class="at">data=</span>horsehearts)</span>
<span id="cb46-1029"><a href="#cb46-1029" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-1030"><a href="#cb46-1030" aria-hidden="true" tabindex="-1"></a>hh_lmrob <span class="ot">&lt;-</span> robustbase<span class="sc">::</span><span class="fu">lmrob</span>(WEIGHT <span class="sc">~</span> OUTERSYS <span class="sc">+</span> EXTDIA, <span class="at">data=</span>horsehearts)</span>
<span id="cb46-1031"><a href="#cb46-1031" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-1032"><a href="#cb46-1032" aria-hidden="true" tabindex="-1"></a>horsehearts <span class="sc">|&gt;</span> </span>
<span id="cb46-1033"><a href="#cb46-1033" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gather_predictions</span>(hh_lm, hh_rlm, hh_lmrob) <span class="sc">%&gt;%</span> </span>
<span id="cb46-1034"><a href="#cb46-1034" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>WEIGHT, <span class="at">y=</span>pred, <span class="at">colour=</span>model)) <span class="sc">+</span> </span>
<span id="cb46-1035"><a href="#cb46-1035" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb46-1036"><a href="#cb46-1036" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">slope=</span><span class="dv">1</span>, <span class="at">intercept =</span> <span class="dv">0</span>) <span class="sc">+</span> </span>
<span id="cb46-1037"><a href="#cb46-1037" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Predicted WEIGHT"</span>) <span class="sc">+</span> <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb46-1038"><a href="#cb46-1038" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Comparison of model predictions"</span>)</span>
<span id="cb46-1039"><a href="#cb46-1039" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-1040"><a href="#cb46-1040" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-1041"><a href="#cb46-1041" aria-hidden="true" tabindex="-1"></a>@fig-mcompare1 shows that the scatter plot of predicted versus actual $Y$ values for the three fitted models which confirms that these models perform very similarly. We may also extract measures such as mean absolute percentage error (MAPE) or residual SD or root mean square error (RMSE) for the three models using <span class="in">`modelr`</span> package; see the code shown below:</span>
<span id="cb46-1042"><a href="#cb46-1042" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-1045"><a href="#cb46-1045" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-1046"><a href="#cb46-1046" aria-hidden="true" tabindex="-1"></a><span class="fu">list</span>(<span class="at">hh_lm =</span> hh_lm, </span>
<span id="cb46-1047"><a href="#cb46-1047" aria-hidden="true" tabindex="-1"></a>     <span class="at">hh_rlm =</span> hh_rlm, </span>
<span id="cb46-1048"><a href="#cb46-1048" aria-hidden="true" tabindex="-1"></a>     <span class="at">hh_lmrob =</span> hh_lmrob) <span class="sc">|&gt;</span> </span>
<span id="cb46-1049"><a href="#cb46-1049" aria-hidden="true" tabindex="-1"></a>  <span class="fu">enframe</span>(<span class="st">"method"</span>, <span class="st">"fit"</span>) <span class="sc">|&gt;</span> </span>
<span id="cb46-1050"><a href="#cb46-1050" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb46-1051"><a href="#cb46-1051" aria-hidden="true" tabindex="-1"></a>    <span class="at">MAPE =</span> <span class="fu">map_dbl</span>(fit, \(x){<span class="fu">mape</span>(x, horsehearts)}),</span>
<span id="cb46-1052"><a href="#cb46-1052" aria-hidden="true" tabindex="-1"></a>    <span class="at">RMSE =</span> <span class="fu">map_dbl</span>(fit, \(x){<span class="fu">rmse</span>(x, horsehearts)})</span>
<span id="cb46-1053"><a href="#cb46-1053" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb46-1054"><a href="#cb46-1054" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-1055"><a href="#cb46-1055" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-1056"><a href="#cb46-1056" aria-hidden="true" tabindex="-1"></a>Measures such as AIC or BIC need corrections when the normality assumption does not hold but the above summary measures do not require such a distributional assumption to hold.</span>
<span id="cb46-1057"><a href="#cb46-1057" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-1058"><a href="#cb46-1058" aria-hidden="true" tabindex="-1"></a>If a large dataset is in hand, a part of the data (training data) can be used to fit the model and then we can see how well the fitted model works for the remaining data.</span>
<span id="cb46-1059"><a href="#cb46-1059" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-1060"><a href="#cb46-1060" aria-hidden="true" tabindex="-1"></a><span class="fu"># Summary</span></span>
<span id="cb46-1061"><a href="#cb46-1061" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-1062"><a href="#cb46-1062" aria-hidden="true" tabindex="-1"></a>Regression methods are the most commonly used of statistics techniques. The main aim is to fit a model by least squares to explain the variation in the response variable $Y$ by using one or more explanatory variables $X_1$, $X_2$, ... , $X_k$. The correlation coefficient $r_{xy}$ measures the strength of the linear relationship between $Y$ and $X$; $R^{2}$ measures the strength of the linear relationship between $Y$ and $X_1$, $X_2$, ... , $X_k$. When $k$=1, then $r_{xy}^{2} =R^{2}$. Scatter plots and correlation coefficients provide important clues to the inter-relationships between the variables.</span>
<span id="cb46-1063"><a href="#cb46-1063" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-1064"><a href="#cb46-1064" aria-hidden="true" tabindex="-1"></a>In building up a model by adding new variables, the correlation (or overlap) with $y$ is important but the correlations between a new explanatory variable and each of the existing explanatory variables also determine how effective the addition of the variable will be.</span>
<span id="cb46-1065"><a href="#cb46-1065" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-1066"><a href="#cb46-1066" aria-hidden="true" tabindex="-1"></a>Stepwise regression procedures identify potentially good regression models by repeatedly comparing an existing model with other models in which an explanatory variable has been either deleted or added, using some criterion such as significance of the deleted or added term (as measured by the $p$-value of the relevant $t$ or $F$ statistic) or the AIC of the model. Polynomial regression models employ the square, cube etc terms of the original variables as additional predictors.</span>
<span id="cb46-1067"><a href="#cb46-1067" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-1068"><a href="#cb46-1068" aria-hidden="true" tabindex="-1"></a>When at least two explanatory variables are highly correlated, we have multicollinear data. The effect is that the variance of least square estimators will be inflated rendering the coefficients insignificant and hence we may need to discard one or more of the highly correlated variables.</span>
<span id="cb46-1069"><a href="#cb46-1069" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-1070"><a href="#cb46-1070" aria-hidden="true" tabindex="-1"></a>EDA plots of residuals help to answer the question as to whether the fit is good or whether a transformation may help or whether other variables (including square, cubic etc) should be added. If residuals are plotted against fitted $Y$ or $X$ variables no discernible pattern should be observed. Estimated regression coefficients may be affected by leverage points, and hence influence diagnostics are performed.</span>
<span id="cb46-1071"><a href="#cb46-1071" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-1072"><a href="#cb46-1072" aria-hidden="true" tabindex="-1"></a><span class="fu"># What you should know</span></span>
<span id="cb46-1073"><a href="#cb46-1073" aria-hidden="true" tabindex="-1"></a>By the end of this chapter you should be able to:</span>
<span id="cb46-1074"><a href="#cb46-1074" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-1075"><a href="#cb46-1075" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Fit and display a multiple regression (2 or more predictor variables).</span>
<span id="cb46-1076"><a href="#cb46-1076" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Check the assumptions of a multiple regression using residual diagnostic plots, tests for assumptions, and examine multicollinearity.</span>
<span id="cb46-1077"><a href="#cb46-1077" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Measure variability explained by the model and predictors.</span>
<span id="cb46-1078"><a href="#cb46-1078" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Use a fitted regression to predict new data.</span>
<span id="cb46-1079"><a href="#cb46-1079" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Explain the significance of your model and interpret findings in context of the data and hypotheses.</span>
<span id="cb46-1080"><a href="#cb46-1080" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Describe model comparison/selection and polynomial terms. </span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>